{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ Nepali Grammar Error Correction Training\n",
      "============================================================\n",
      "Model: google/mt5-small\n",
      "LoRA: True\n",
      "Samples: 15\n",
      "============================================================\n",
      "‚úÖ Seeds set to 42\n",
      "Memory cleared\n",
      "Directories created in c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlsumit008\u001b[0m (\u001b[33mlsumit008-khwopa-college-of-engineering\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\logging\\__init__.py\", line 1153, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 187-191: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 678, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py\", line 2033, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\events.py\", line 89, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30948\\1384428038.py\", line 116, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_30948\\1384428038.py\", line 43, in main\n",
      "    wandb.init(\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 1582, in init\n",
      "    run = wi.init(run_settings, run_config, run_printer)\n",
      "  File \"c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 837, in init\n",
      "    self._logger.info(\n",
      "Message: \"wandb.init called with sweep_config: {}\\nconfig: {'model_id': 'google/mt5-small', 'max_length': 64, 'prefix': '‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡§ö‡•ç‡§Ø‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç: ', 'dataset_name': 'sumitaryal/nepali_grammatical_error_correction', 'num_samples': 15, 'valid_size': 0.1, 'use_lora': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'lora_target_modules': ['q', 'k', 'v', 'o'], 'batch_size': 16, 'num_epochs': 3, 'gradient_accumulation_steps': 2, 'learning_rate': 0.0001, 'weight_decay': 0.01, 'warmup_ratio': 0.05, 'use_8bit': True, 'use_fp16': False, 'gradient_checkpointing': True, 'output_dir': 'c:\\\\\\\\Users\\\\\\\\Lenovo\\\\\\\\Desktop\\\\\\\\Nepali_GEC\\\\\\\\nepali_gec\\\\\\\\outputs', 'logging_steps': 1, 'save_total_limit': 2, 'early_stopping_patience': 3, 'wandb_project': 'nepali-grammar-correction', 'seed': 42, 'bleu': True, 'chrf': True, 'gleu': True, 'correction_accuracy': True, 'bertscore': False, 'use_sample_prediction_callback': True, 'sample_prediction_num_samples': 5, 'use_memory_cleanup_callback': True, 'resume_from_checkpoint': False, '_wandb': {}}\"\n",
      "Arguments: ()\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\src\\wandb_runs\\wandb\\run-20251120_003144-ivs9kle5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/ivs9kle5' target=\"_blank\">brisk-water-75</a></strong> to <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/ivs9kle5' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/ivs9kle5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Loading dataset: sumitaryal/nepali_grammatical_error_correction\n",
      "  Using 15 samples\n",
      "  Train: 13 samples\n",
      "  Valid: 2 samples\n",
      "\n",
      " Lodaing model: google/mt5-small\n",
      " Using LoRA + 8-bit quantization\n",
      "trainable params: 1,376,256 || all params: 301,553,024 || trainable%: 0.4564\n",
      "\n",
      "‚öôÔ∏è  Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 277.89 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 89.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Preprocessing complete\n",
      "\n",
      "üìä Training plan:\n",
      "  Steps per epoch: 1\n",
      "  Total steps: 3\n",
      "  Warmup steps: 0\n",
      "Enabled metrics:bleu, chrf, gleu, correction_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added EarlyStoppingCallback (patience=3)\n",
      "‚úÖ Added SamplePredictionCallback (num_samples=5)\n",
      "‚úÖ Added MemoryCleanupCallback\n",
      "\n",
      " Running pre-training safety checks...\n",
      "Model device: cuda:0\n",
      "Train dataset size: 13\n",
      "Eval dataset size: 2\n",
      " Data loading works\n",
      " Performing evaluation check...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False\n",
      "üìä Logged 5 sample predictions to W&B\n",
      " Evaluation successful\n",
      "Initial metrics: {'eval_loss': 10.18242073059082, 'eval_model_preparation_time': 0.0025, 'eval_bleu': 0.0, 'eval_gleu': 0.0, 'eval_chrf': 0.0, 'eval_correction_accuracy': 0.0, 'eval_runtime': 6.2777, 'eval_samples_per_second': 0.319, 'eval_steps_per_second': 0.159}\n",
      "\n",
      "============================================================\n",
      "üèãÔ∏è  Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>Correction Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21.034600</td>\n",
       "      <td>9.093679</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24.705000</td>\n",
       "      <td>8.171597</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>25.778200</td>\n",
       "      <td>8.344097</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False\n",
      "üìä Logged 5 sample predictions to W&B\n",
      "üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False\n",
      "üìä Logged 5 sample predictions to W&B\n",
      "üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False\n",
      "üìä Logged 5 sample predictions to W&B\n",
      "\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üíæ Saving model to c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\outputs/best_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ LoRA adapter saved\n",
      "  ‚úÖ Tokenizer saved\n",
      "\n",
      "üéâ All done! Model saved to c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\outputs/best_model\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÖ‚ñà</td></tr><tr><td>eval/bleu</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/chrf</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/correction_accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/gleu</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÑ‚ñÅ‚ñÇ</td></tr><tr><td>eval/model_preparation_time</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÇ‚ñà‚ñÖ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñá‚ñÅ‚ñÑ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñá‚ñÅ‚ñÑ</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>eval/bleu</td><td>0</td></tr><tr><td>eval/chrf</td><td>0</td></tr><tr><td>eval/correction_accuracy</td><td>0</td></tr><tr><td>eval/gleu</td><td>0</td></tr><tr><td>eval/loss</td><td>8.3441</td></tr><tr><td>eval/model_preparation_time</td><td>0.0025</td></tr><tr><td>eval/runtime</td><td>6.8666</td></tr><tr><td>eval/samples_per_second</td><td>0.291</td></tr><tr><td>eval/steps_per_second</td><td>0.146</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-water-75</strong> at: <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/ivs9kle5' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/ivs9kle5</a><br> View project at: <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction</a><br>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb_runs\\wandb\\run-20251120_003144-ivs9kle5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "from math import ceil\n",
    "from transformers import (\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "\n",
    "# wandb_dir = os.path.join(os.getcwd(), 'wandb_runs')\n",
    "# os.makedirs(wandb_dir, exist_ok=True)\n",
    "\n",
    "# Import our custom modules\n",
    "from config import Config\n",
    "from metrics import create_compute_metrics\n",
    "from data_utils import set_seeds, load_and_prepare_dataset, preprocess_dataset\n",
    "from utils import clear_memory, create_directories, safe_training_check, save_model_safe\n",
    "from train import setup_model, create_training_args, create_callbacks\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    \n",
    "    # Load config\n",
    "    config = Config()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üöÄ Nepali Grammar Error Correction Training\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Model: {config.model_id}\")\n",
    "    print(f\"LoRA: {config.use_lora}\")\n",
    "    print(f\"Samples: {config.num_samples or 'Full dataset'}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Setup\n",
    "    set_seeds(config.seed)\n",
    "    clear_memory()\n",
    "    create_directories(config.output_dir)\n",
    "    \n",
    "    # Initialize wandb\n",
    "    wandb.finish()\n",
    "    wandb.init(\n",
    "        project=config.wandb_project,\n",
    "        config=vars(config),\n",
    "        # dir=wandb_dir\n",
    "    )\n",
    "    run_id = wandb.run.id\n",
    "    \n",
    "    # Load data\n",
    "    dataset = load_and_prepare_dataset(config)\n",
    "    \n",
    "    # Setup model\n",
    "    model, tokenizer = setup_model(config)\n",
    "    \n",
    "    # Preprocess\n",
    "    dataset_encoded = preprocess_dataset(dataset, tokenizer, config)\n",
    "    \n",
    "    # Create training args\n",
    "    training_args = create_training_args(config, dataset_encoded, run_id)\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Create metrics\n",
    "    compute_metrics = create_compute_metrics(tokenizer, config)\n",
    "    \n",
    "    # Create callbacks\n",
    "    callbacks = create_callbacks(config, tokenizer, dataset)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset_encoded[\"train\"],\n",
    "        eval_dataset=dataset_encoded[\"valid\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "        # Safety check\n",
    "    if not safe_training_check(trainer):\n",
    "        print(\"\\n‚ùå Safety checks failed! Fix issues before training.\")\n",
    "        return\n",
    "    \n",
    "    # Train!\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üèãÔ∏è  Starting training...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        if config.resume_from_checkpoint:\n",
    "            print(\"continuing training from latest checkpoint.....\")\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        else:\n",
    "            trainer.train()\n",
    "        print(\"\\n‚úÖ Training complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Training failed: {e}\")\n",
    "        wandb.finish()\n",
    "        return\n",
    "    \n",
    "    # Save model\n",
    "    best_model_path = f\"{config.output_dir}/best_model\"\n",
    "    save_model_safe(model, tokenizer, best_model_path, use_lora=config.use_lora)\n",
    "    \n",
    "    print(f\"\\nüéâ All done! Model saved to {best_model_path}\")\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b226c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
