{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3025d85f",
   "metadata": {},
   "source": [
    "Lets see whether simple mt5 model overfits in small data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b854e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSeq2SeqLM,\n",
    "                          Seq2SeqTrainer,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          DataCollatorForSeq2Seq\n",
    "                          )\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "# Set all seeds for reproducibility\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "torch.manual_seed(100)\n",
    "torch.cuda.manual_seed_all(100)\n",
    "# Load aryal's dataset from hf\n",
    "ds = load_dataset(\"sumitaryal/nepali_grammatical_error_correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472e6739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 7723971\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 406525\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a99e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 90\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select randomly few samples from train \n",
    "# split further into train and valid dataset\n",
    "small_dataset = ds[\"train\"].shuffle(seed=42).select(range(100))\n",
    "small_dataset = small_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "small_dataset[\"valid\"] = small_dataset[\"test\"] # Rename the split in the DatasetDict\n",
    "del small_dataset[\"test\"]\n",
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c3090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebb360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [00:00<00:00, 1331.52 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 427.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "prefix = \"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡§ö‡•ç‡§Ø‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç: \"\n",
    "\n",
    "def preprocess(batch):\n",
    "    \n",
    "    inputs = [prefix + inp for inp in batch[\"incorrect_sentence\"]]\n",
    "\n",
    "    # tokenize input (incorrect)\n",
    "    input_encodings = tokenizer(\n",
    "        inputs, \n",
    "        max_length=128,\n",
    "        truncation=True \n",
    "    )\n",
    "    # tokenize target (correct)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(\n",
    "            batch[\"correct_sentence\"], \n",
    "            max_length=128,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    # set labels for seq2seq training                           # for seq2deq models, the \"labels\" are the token IDs of the target sequence\n",
    "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]   \n",
    "\n",
    "    return input_encodings\n",
    "\n",
    "dataset_encoded = small_dataset.map(preprocess, batched=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47d6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch model expects in tensor format\n",
    "dataset_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf332a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§...' | Ref: '‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§...' | Match: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 100.00000000000004,\n",
       " 'chrf': 100.0,\n",
       " 'correction_accuracy': np.float64(1.0),\n",
       " 'gleu': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def tokenize_nepali(text):\n",
    "    \"\"\"Tokenizes Nepali text: splits on spaces and removes punctuation.\"\"\"\n",
    "    # Remove punctuation commonly used in Nepali\n",
    "    text = re.sub(r\"[‡•§,!?]\", \"\", text)\n",
    "    return text.strip().split()\n",
    "\n",
    "def gleu_sentence(reference, prediction, max_n=4):\n",
    "    \"\"\"\n",
    "    Compute sentence-level GEC-GLEU.\n",
    "    Returns a score between 0 and 1.\n",
    "    \"\"\"\n",
    "    ref_tokens = tokenize_nepali(reference)\n",
    "    hyp_tokens = tokenize_nepali(prediction)\n",
    "    \n",
    "    # Adjust max_n for short sentences\n",
    "    max_n = min(max_n, len(ref_tokens), len(hyp_tokens))\n",
    "    if max_n == 0:\n",
    "        return 0.0  # empty sentence\n",
    "    \n",
    "    scores = []\n",
    "    for n in range(1, max_n+1):\n",
    "        ref_ngrams = Counter([tuple(ref_tokens[i:i+n]) for i in range(len(ref_tokens)-n+1)])\n",
    "        hyp_ngrams = Counter([tuple(hyp_tokens[i:i+n]) for i in range(len(hyp_tokens)-n+1)])\n",
    "        overlap = sum((ref_ngrams & hyp_ngrams).values())\n",
    "        precision = overlap / max(1, sum(hyp_ngrams.values()))\n",
    "        recall = overlap / max(1, sum(ref_ngrams.values()))\n",
    "        scores.append(min(precision, recall))\n",
    "    return sum(scores) / max_n\n",
    "\n",
    "def corpus_gec_gleu(references, predictions):\n",
    "    \"\"\"\n",
    "    Compute corpus-level GEC-GLEU.\n",
    "    `references` can be a list of strings or a list of single-item lists.\n",
    "    \"\"\"\n",
    "    # Flatten single-reference lists\n",
    "    refs_flat = [r[0] if isinstance(r, list) else r for r in references]\n",
    "    \n",
    "    scores = [gleu_sentence(r, p) for r, p in zip(refs_flat, predictions)]\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# Load metrics once\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute BLEU, chrF, Correction Accuracy, and BERTScore for Nepali GEC.\n",
    "    Handles both token IDs and plain text predictions.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # --- Handle tuple outputs (e.g., logits + labels) ---\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # --- If preds/labels are lists of strings, skip decoding ---\n",
    "    if isinstance(predictions[0], str) and isinstance(labels[0], str):\n",
    "        preds_clean = [p.strip() for p in predictions]\n",
    "        refs_clean = [r.strip() for r in labels]\n",
    "    else:\n",
    "        # Convert to numpy arrays\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Handle logits (vocab dimension)\n",
    "        if predictions.ndim == 3:\n",
    "            predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "        # Replace -100 with pad_token_id\n",
    "        predictions = np.where(predictions == -100, tokenizer.pad_token_id, predictions)\n",
    "        labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "        # Decode\n",
    "        preds = tokenizer.batch_decode(predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        refs = tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        preds_clean = [p.strip() for p in preds]\n",
    "        refs_clean = [r.strip() for r in refs]\n",
    "\n",
    "    # --- Format for metrics ---\n",
    "    references = [[r] for r in refs_clean]\n",
    "    metrics = {}\n",
    "\n",
    "    # --- BLEU ---\n",
    "    try:\n",
    "        non_empty_indices = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "        if non_empty_indices:\n",
    "            preds_bleu = [preds_clean[i] for i in non_empty_indices]\n",
    "            refs_bleu = [[refs_clean[i]] for i in non_empty_indices]\n",
    "            bleu_result = bleu_metric.compute(predictions=preds_bleu, references=refs_bleu)\n",
    "            metrics[\"bleu\"] = bleu_result[\"score\"]\n",
    "        else:\n",
    "            metrics[\"bleu\"] = 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU computation failed: {e}\")\n",
    "        metrics[\"bleu\"] = 0.0\n",
    "\n",
    "    # --- chrF ---\n",
    "    try:\n",
    "        chrf_result = chrf_metric.compute(predictions=preds_clean, references=refs_clean)\n",
    "        metrics[\"chrf\"] = chrf_result[\"score\"]\n",
    "    except Exception as e:\n",
    "        print(f\"chrF computation failed: {e}\")\n",
    "        metrics[\"chrf\"] = 0.0\n",
    "\n",
    "    # --- Correction Accuracy ---\n",
    "    try:\n",
    "        exact_matches = np.mean([p == r for p, r in zip(preds_clean, refs_clean)])\n",
    "        metrics[\"correction_accuracy\"] = exact_matches\n",
    "    except Exception as e:\n",
    "        print(f\"Correction accuracy computation failed: {e}\")\n",
    "        metrics[\"correction_accuracy\"] = 0.0\n",
    "\n",
    "    # # --- BERTScore ---\n",
    "    # try:\n",
    "    #     non_empty_indices_bert = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "    #     if non_empty_indices_bert:\n",
    "    #         preds_bert = [preds_clean[i] for i in non_empty_indices_bert]\n",
    "    #         refs_bert = [refs_clean[i] for i in non_empty_indices_bert]\n",
    "    #         bertscore_result = bertscore_metric.compute(\n",
    "    #             predictions=preds_bert,\n",
    "    #             references=refs_bert,\n",
    "    #             lang=\"ne\",\n",
    "    #             model_type=\"microsoft/mdeberta-v3-base\"\n",
    "    #         )\n",
    "    #         metrics[\"bertscore_f1\"] = float(np.mean(bertscore_result[\"f1\"]))\n",
    "    #     else:\n",
    "    #         metrics[\"bertscore_f1\"] = 0.0\n",
    "    # except Exception as e:\n",
    "    #     print(f\"BERTScore computation failed: {e}\")\n",
    "    #     metrics[\"bertscore_f1\"] = 0.0\n",
    "        \n",
    "    # --- GLEU (SacreBLEU) ---\n",
    "    try:\n",
    "\n",
    "\n",
    "        gleu_score = corpus_gec_gleu(refs_clean, preds_clean)\n",
    "\n",
    "\n",
    "        metrics[\"gleu\"] = gleu_score\n",
    "    except Exception as e:\n",
    "        print(\"GLEU failed:\", e)\n",
    "        metrics[\"gleu\"] = 0.0\n",
    "\n",
    "    # --- Print one sample for sanity ---\n",
    "    if len(preds_clean) > 0:\n",
    "        print(f\"üîç Sample - Pred: '{preds_clean[0][:50]}...' | Ref: '{refs_clean[0][:50]}...' | Match: {preds_clean[0] == refs_clean[0]}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "preds = [\"‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§\", \"‡§Æ ‡§∏‡•ç‡§ï‡•Å‡§≤ ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\", \"‡§Æ ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\"]\n",
    "refs  = [\"‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§\", \"‡§Æ ‡§∏‡•ç‡§ï‡•Å‡§≤ ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\", \"‡§Æ ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\"]\n",
    "compute_metrics((preds, refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2519bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37886e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True,\n",
    "                                        llm_int8_threshold=6.0,  \n",
    "                                        llm_int8_has_fp16_weight=False )\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id,\n",
    "                                              quantization_config=quantization_config,\n",
    "                                              device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,376,256 || all params: 301,553,024 || trainable%: 0.4564\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "# from peft import unload\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"k\", \"v\", \"o\"],\n",
    "    lora_dropout=0.05, # disable for overfit test\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "# model.gradient_checkpointing_enable()\n",
    "# model = unload(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "# model.config.use_cache = False  # Required for gradient checkpointing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f600bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, \n",
    "    # model=model,\n",
    "    pad_to_multiple_of=8,  # Optional: for better performance\n",
    "    return_tensors=\"pt\", \n",
    "    padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e052827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlsumit008\u001b[0m (\u001b[33mlsumit008-khwopa-college-of-engineering\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\notebooks\\wandb\\run-20251119_200830-h6poyln6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/h6poyln6' target=\"_blank\">mt5-nepali</a></strong> to <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/h6poyln6' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/h6poyln6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback, TrainerCallback\n",
    "from math import ceil\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandb.finish()\n",
    "wandb.init(project=\"nepali-grammar-correction\", name=\"mt5-nepali\")\n",
    "run_id = wandb.run.id\n",
    "\n",
    "batch_size = 4\n",
    "num_train_epochs = 3\n",
    "gradient_accumulation_steps = 2\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.01\n",
    "lr_scheduler_type = \"linear\"\n",
    "steps_per_epoch = ceil(len(dataset_encoded[\"train\"]) // (batch_size * gradient_accumulation_steps))    # no. of steps per epoch # log once per epoch\n",
    "\n",
    "eval_steps = max(1, steps_per_epoch) // 2           # Log 2 times per epoch\n",
    "num_training_steps = steps_per_epoch * num_train_epochs\n",
    "warmup_steps = int(0.05 * num_training_steps)\n",
    "\n",
    "\n",
    "model_name = f\"{model_id}-finetuned-gec\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(f\"../outputs/checkpoints/{model_name}\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/best_model\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/logs\", exist_ok=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(output_dir=f\"../outputs/checkpoints/{model_name}\",\n",
    "                                         num_train_epochs=num_train_epochs,\n",
    "\n",
    "                                         # Memory Optimization:\n",
    "                                         per_device_train_batch_size=batch_size,\n",
    "                                         per_device_eval_batch_size= 2 * batch_size,\n",
    "                                         gradient_accumulation_steps=gradient_accumulation_steps,  # Simulate larger batch size eg: 8 * 2 = 16\n",
    "                                         fp16=False,                                                # Use mixed precision if GPU supports it\n",
    "                                         dataloader_pin_memory=True,                        # ‚úÖ Faster data loading\n",
    "                                         dataloader_num_workers=4,                          # ‚úÖ Parallel data loading\n",
    "\n",
    "                                         gradient_checkpointing=False,                      # ‚úÖ Disable for speed\n",
    "                                         \n",
    "                                         # Logging & Saving:\n",
    "                                         logging_steps=1,           # log the training loss and metrics every X steps\n",
    "                                         eval_strategy=\"epoch\",          # performs evaluation per epoch\n",
    "                                        #  eval_steps=eval_steps,\n",
    "                                         save_strategy=\"epoch\",          # saves model checkpoint per epoch\n",
    "                                        #  save_steps=230000,\n",
    "                                         save_total_limit=2,             # keep last 2 checkpoints for safety\n",
    "                                         overwrite_output_dir=True,      # Overwrite previous runs\n",
    "\n",
    "                                         # Best Model saving:\n",
    "                                         load_best_model_at_end=True,        # Load the best model at the end\n",
    "                                         metric_for_best_model=\"chrf\",   # Use chrf to determine best model\n",
    "                                         greater_is_better=True,            # larger chrf is better\n",
    "\n",
    "                                         # performance\n",
    "                                         warmup_steps=warmup_steps,             # Gradually increases LR at start\n",
    "                                         learning_rate=learning_rate,\n",
    "                                         weight_decay=weight_decay,             # L2 regularization\n",
    "                                         lr_scheduler_type=lr_scheduler_type,\n",
    "                                         max_grad_norm=1.0,                     # Prevent exploding gradients\n",
    "                                         optim=\"paged_adamw_8bit\",              # Better optimizer for quantized models\n",
    "\n",
    "                                         # Seq2seq specific:\n",
    "                                         predict_with_generate=True,    # essential for seq2seq , If not set then metrics will be computed on meaningless logits\n",
    "                                         generation_max_length=64,      # Max output length\n",
    "                                         generation_num_beams=4,        # 1=greedy, 4=beam search (slower but better)\n",
    "\n",
    "                                         report_to=\"wandb\",          # This enables automatic logging\n",
    "                                         run_name=f\"{run_id}\",\n",
    "                                         push_to_hub=True,                       # save the model to HF\n",
    "                                         hub_model_id=\"AIsumit123/Nepali_GEC_mt5_model\",\n",
    "                                         seed=42,\n",
    "                                         data_seed=42,\n",
    "                                         )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a651ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TrainerCallback\n",
    "import wandb\n",
    "\n",
    "class SamplePredictionCallback(TrainerCallback):\n",
    "    \"\"\"Generate predictions on a few validation samples and log to W&B.\"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, eval_dataset, num_samples=5, max_length=64):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.num_samples = num_samples\n",
    "        self.max_length = max_length\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        model.eval()\n",
    "        device = model.device\n",
    "\n",
    "        # Select sample rows\n",
    "        samples = self.eval_dataset.select(range(self.num_samples))\n",
    "\n",
    "        table = wandb.Table(columns=[\"Input\", \"Target\", \"Prediction\"])\n",
    "\n",
    "        for sample in samples:\n",
    "\n",
    "            # Use the original raw text fields, not token IDs\n",
    "            inp_text = sample[\"incorrect_sentence\"]\n",
    "            tgt_text = sample[\"correct_sentence\"]\n",
    "\n",
    "            # Tokenize individual sample\n",
    "            tokenized = self.tokenizer(\n",
    "                inp_text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=False\n",
    "            ).to(device)\n",
    "\n",
    "            # Safe generate (LoRA-friendly)\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                output_ids = model.generate(\n",
    "                    input_ids=tokenized[\"input_ids\"],\n",
    "                    attention_mask=tokenized[\"attention_mask\"],\n",
    "                    max_length=self.max_length,\n",
    "                    num_beams=1\n",
    "                )\n",
    "\n",
    "            pred_text = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "            table.add_data(inp_text, tgt_text, pred_text)\n",
    "\n",
    "            del tokenized, output_ids\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        wandb.log({\"sample_predictions\": table})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc006b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    SamplePredictionCallback(tokenizer, eval_dataset=small_dataset[\"valid\"], num_samples=5, max_length = 64)\n",
    "]\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"valid\"],  \n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=seq2seq_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=callbacks\n",
    "      \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a71b3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running pre-training safety checks...\n",
      "Model device: cuda:0\n",
      "Train dataset size: 90\n",
      "Eval dataset size: 10\n",
      " Data loading works\n",
      " Performing evaluation check...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0> ‡•§...' | Ref: '‡§Ö‡§π‡§ø‡§≤‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§µ‡§°‡§æ‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§Ö...' | Match: False\n",
      " Evaluation successful\n",
      "Initial metrics: {'eval_loss': 10.177413940429688, 'eval_model_preparation_time': 0.0019, 'eval_bleu': 0.4093082060797297, 'eval_chrf': 1.086395705048532, 'eval_correction_accuracy': 0.0, 'eval_gleu': 0.0020833333333333333, 'eval_runtime': 17.5206, 'eval_samples_per_second': 0.571, 'eval_steps_per_second': 0.114}\n",
      "\n",
      "============================================================\n",
      "‚úÖ All checks passed! Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 02:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>Correction Accuracy</th>\n",
       "      <th>Gleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31.635600</td>\n",
       "      <td>9.772861</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.415208</td>\n",
       "      <td>1.570373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.641400</td>\n",
       "      <td>8.902305</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.410058</td>\n",
       "      <td>2.723920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28.399900</td>\n",
       "      <td>9.016022</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.412558</td>\n",
       "      <td>2.592565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0> ‡•§...' | Ref: '‡§Ö‡§π‡§ø‡§≤‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§µ‡§°‡§æ‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§Ö...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0> ‡•§...' | Ref: '‡§Ö‡§π‡§ø‡§≤‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§µ‡§°‡§æ‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§Ö...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0> ‡•§...' | Ref: '‡§Ö‡§π‡§ø‡§≤‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§µ‡§°‡§æ‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§Ö...' | Match: False\n",
      "‚úÖ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Complete safety check\n",
    "def safe_training_check(trainer):\n",
    "    \"\"\"Comprehensive pre-training safety check\"\"\"\n",
    "    print(\" Running pre-training safety checks...\")\n",
    "\n",
    "    # 1. Check model is on correct device\n",
    "    print(f\"Model device: {next(trainer.model.parameters()).device}\")\n",
    "\n",
    "    # 2. Check dataset sizes\n",
    "    print(f\"Train dataset size: {len(trainer.train_dataset)}\")\n",
    "    print(f\"Eval dataset size: {len(trainer.eval_dataset)}\")\n",
    "\n",
    "    # 3. Test data loading\n",
    "    try:\n",
    "        sample_batch = next(iter(trainer.get_train_dataloader()))\n",
    "        print(\" Data loading works\")\n",
    "        # print(f\"Batch keys: {sample_batch.keys()}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Data loading failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # 4. Test evaluation\n",
    "    try:\n",
    "        trainer.model.eval()    # Set to evaluation mode\n",
    "        print(\" Performing evaluation check...\")\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(\" Evaluation successful\")\n",
    "        print(f\"Initial metrics: {eval_results}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\" Evaluation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "if safe_training_check(trainer):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ All checks passed! Starting training...\")\n",
    "    print(\"=\"*60)\n",
    "    trainer.train()\n",
    "    print(\"‚úÖ Training complete!\")\n",
    "\n",
    "else:\n",
    "    print(\" Fix issues before training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e402d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will pick the latest checkpoint and train\n",
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff205b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# del model       # or del comet_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d0507",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f608f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ‡•á \n",
      "Corrected: <extra_id_0> ?\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "base = \"google/mt5-small\"\n",
    "lora = \"../outputs/best_model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base)\n",
    "\n",
    "# Load base + LoRA\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import PeftModel\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(base)\n",
    "model = PeftModel.from_pretrained(model, lora)\n",
    "model.eval()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "def predict(text):\n",
    "    input_text = f\"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: {text}\"\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=64,\n",
    "            num_beams=4\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "test_sentence = \"‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ‡•á \"\n",
    "corrected = predict(test_sentence)\n",
    "print(f\"Original: {test_sentence}\")\n",
    "print(f\"Corrected: {corrected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d645f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0> ‡§π‡•ã ‡•§\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"‡§Ø‡•ã ‡§è‡§ï ‡§ó‡§≤‡§§ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§π‡•ã ‡•§\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0dff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§â‡§ö‡•ç‡§ö ‡§∏‡§§‡§∞‡•ç‡§ï‡§§‡§æ ‡§Ö‡§™‡§®‡§æ‡§â‡§® ‡§∞ ‡§Æ‡§æ‡§§‡§π‡§§‡§ï‡§æ ‡§®‡§ø‡§ï‡§æ‡§Ø‡§ï‡•ã ‡§¨‡§´‡§æ‡§¶‡§æ‡§∞‡•Ä‡§ï‡•ã ‡§ñ‡§æ‡§Å‡§ö‡•ã ‡§∞‡§π‡•á‡§ï‡•ã ‡§µ‡§ø‡§ú‡•ç‡§û‡§π‡§∞‡•Å ‡§î‡§≤‡•ç‡§Ø‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§â‡§ö‡•ç‡§ö ‡§∏‡§§‡§∞‡•ç‡§ï‡§§‡§æ ‡§Ö‡§™‡§®‡§æ‡§â‡§® ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§∞ ‡§Æ‡§æ‡§§‡§π‡§§‡§ï‡§æ ‡§®‡§ø‡§ï‡§æ‡§Ø‡§ï‡•ã ‡§¨‡§´‡§æ‡§¶‡§æ‡§∞‡•Ä‡§ï‡•ã ‡§ñ‡§æ‡§Å‡§ö‡•ã ‡§∞‡§π‡•á‡§ï‡•ã ‡§µ‡§ø‡§ú‡•ç‡§û‡§π‡§∞‡•Å ‡§î‡§≤‡•ç‡§Ø‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§ó‡•ç‡§∞‡§ø‡§® ‡§µ‡§ø‡§® (‡§µ‡§ø‡§¶‡•á‡§∂ ‡§®‡§ø‡§∞‡•ç‡§Ø‡§æ‡§§ ‡§ó‡§∞‡•ç‡§®‡•á) ‡§ï‡§´‡•Ä ‡§µ‡§ø‡§¶‡•á‡§∂‡§Æ‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡§ø‡§≤‡•ã ‡•ß‡•¶ ‡§¶‡•á‡§ñ‡•Ä ‡•ß‡•´ ‡§°‡§≤‡§∞‡§∏‡§Æ‡•ç‡§Æ‡§Æ‡§æ ‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä ‡§π‡•Å‡§®‡•ç‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ó‡•ç‡§∞‡§ø‡§® ‡§µ‡§ø‡§® (‡§µ‡§ø‡§¶‡•á‡§∂ ‡§®‡§ø‡§∞‡•ç‡§Ø‡§æ‡§§ ‡§ó‡§∞‡•ç‡§®‡•á) ‡§ï‡§´‡•Ä ‡§µ‡§ø‡§¶‡•á‡§∂‡§Æ‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡§ø‡§≤‡•ã ‡•ß‡•¶ ‡§¶‡•á‡§ñ‡§ø ‡•ß‡•´ ‡§°‡§≤‡§∞‡§∏‡§Æ‡•ç‡§Æ‡§Æ‡§æ ‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä ‡§π‡•Å‡§®‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§™‡§§‡•ç‡§Ø‡§ï‡§æ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§Æ‡•á‡§°‡§ø‡§ï‡§≤ ‡§ï‡§≤‡•á‡§ú ‡§ñ‡•ã‡§≤‡•ç‡§® ‡§∞ ‡§∞‡§æ‡§ú‡§ß‡§æ‡§®‡•Ä‡§¨‡§æ‡§π‡§ø‡§∞‡§ï‡§æ ‡§Æ‡§®‡§∏‡§æ‡§Ø‡§™‡§§‡•ç‡§∞ (‡§è‡§≤‡§ì‡§Ü‡§à) ‡§™‡§æ‡§è‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§ß‡§æ‡§∞ ‡§™‡•Å‡§∞‡§æ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§Æ‡•á‡§°‡§ø‡§ï‡§≤ ‡§ï‡§≤‡•á‡§ú‡§≤‡§æ‡§à ‡§∞‡•ã‡§ï‡•ç‡§® ‡§®‡§π‡•Å‡§®‡•á ‡§â‡§®‡§ï‡•ã ‡§ß‡§æ‡§∞‡§£‡§æ ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§õ ‡•§\n",
      "label:     ‡§â‡§™‡§§‡•ç‡§Ø‡§ï‡§æ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§Æ‡•á‡§°‡§ø‡§ï‡§≤ ‡§ï‡§≤‡•á‡§ú ‡§ñ‡•ã‡§≤‡•ç‡§® ‡§∞ ‡§∞‡§æ‡§ú‡§ß‡§æ‡§®‡•Ä‡§¨‡§æ‡§π‡§ø‡§∞‡§ï‡§æ ‡§Æ‡§®‡§∏‡§æ‡§Ø‡§™‡§§‡•ç‡§∞ (‡§è‡§≤‡§ì‡§Ü‡§à) ‡§™‡§æ‡§è‡§∞ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§ß‡§æ‡§∞ ‡§™‡•Ç‡§∞‡§æ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§Æ‡•á‡§°‡§ø‡§ï‡§≤ ‡§ï‡§≤‡•á‡§ú‡§≤‡§æ‡§à ‡§∞‡•ã‡§ï‡•ç‡§® ‡§®‡§π‡•Å‡§®‡•á ‡§â‡§®‡§ï‡•ã ‡§ß‡§æ‡§∞‡§£‡§æ ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§§‡§∞, ‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£‡§≤‡•á ‡§°‡•á‡§¢ ‡§Ö‡§∞‡•ç‡§¨ ‡§Æ‡§æ‡§§‡•ç‡§∞‡•à ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§™‡•ç‡§∞‡§§‡§ø‡§¨‡§¶‡•ç‡§ß‡§§‡§æ ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡§â‡§®‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§§‡§∞, ‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£‡§≤‡•á ‡§°‡•á‡§¢ ‡§Ö‡§∞‡•ç‡§¨ ‡§Æ‡§æ‡§§‡•ç‡§∞‡•à ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ó‡§∞‡§æ‡§â‡§®‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§¨‡§¶‡•ç‡§ß‡§§‡§æ ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡§â‡§®‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§∂‡§∏‡•ç‡§§‡•ç‡§∞ ‡§¶‡•ç‡§µ‡§®‡•ç‡§¶‡•ç‡§µ ‡§∞ ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§®‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§Ö‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ö‡•ã‡§ü‡§≤‡§æ‡§à ‡§Æ‡§≤‡§Æ‡§™‡§ü‡•ç‡§ü‡•Ä ‡§≤‡§ó‡§æ‡•á ‡§∏‡•Å‡§µ‡§ø‡§ö‡§æ‡§∞‡§≤‡•á ‡§Ö‡§¨ ‡§™‡•ç‡§∞‡§∂‡•ç‡§∞‡§Ø ‡§™‡§æ‡§â‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§¨‡§¢‡•ç‡§¶‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§∏‡§∂‡§∏‡•ç‡§§‡•ç‡§∞ ‡§¶‡•ç‡§µ‡§®‡•ç‡§¶‡•ç‡§µ ‡§∞ ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§®‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§Ö‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ö‡•ã‡§ü‡§≤‡§æ‡§à ‡§Æ‡§≤‡§Æ‡§™‡§ü‡•ç‡§ü‡•Ä ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡•Å‡§µ‡§ø‡§ö‡§æ‡§∞‡§≤‡•á ‡§Ö‡§¨ ‡§™‡•ç‡§∞‡§∂‡•ç‡§∞‡§Ø ‡§™‡§æ‡§â‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§¨‡§¢‡•ç‡§¶‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§ú‡§ü‡§ø‡§≤ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§¶‡•á‡§ñ‡•ç‡§¶ ‡§™‡§®‡§ø ‡§®‡•á‡§™‡§æ‡§≤ ‡§™‡§§‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§Æ‡§π‡§æ‡§∏‡§Ç‡§ò ‡§ï‡•á‡§π‡•Ä ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á ‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Æ‡§æ ‡§õ‡•à‡§® ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§ú‡§ü‡§ø‡§≤ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§¶‡•á‡§ñ‡•ç‡§¶‡§æ‡§¶‡•á‡§ñ‡•ç‡§¶‡•à ‡§™‡§®‡§ø ‡§®‡•á‡§™‡§æ‡§≤ ‡§™‡§§‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§Æ‡§π‡§æ‡§∏‡§Ç‡§ò ‡§ï‡•á‡§π‡•Ä ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á ‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Æ‡§æ ‡§õ‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§∞ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§ö‡§æ‡§∏‡•ã ‡§∞ ‡§∏‡§∞‡•ã‡§ï‡§æ‡§∞‡§ï‡§æ ‡§µ‡§ø‡§∑‡§Ø ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡§§‡•ç‡§∞‡§™‡§§‡•ç‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§® ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§¶‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§∞ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç:\n",
      "label:     ‡§Ø‡§∏‡•à‡§ó‡§∞‡•Ä ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§ö‡§æ‡§∏‡•ã ‡§∞ ‡§∏‡§∞‡•ã‡§ï‡§æ‡§∞‡§ï‡§æ ‡§µ‡§ø‡§∑‡§Ø ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡§§‡•ç‡§∞‡§™‡§§‡•ç‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§® ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§¶‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡•®‡•¶ ‡§∞ ‡•®‡•´ ‡§≤‡§æ‡§ñ‡§∏‡§Æ‡•ç‡§Æ‡§ï‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§≠‡§è‡§® ‡•®‡•¶ ‡§®‡•à ‡§¨‡§®‡§® ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡•®‡•¶ ‡§∞ ‡•®‡•´ ‡§≤‡§æ‡§ñ‡§∏‡§Æ‡•ç‡§Æ‡§ï‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§≠‡§è‡§® ‡•®‡•¶ ‡§®‡•à ‡§¨‡§®‡§æ‡§â‡§®‡•á ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ü‡§á‡§∏‡§ï‡•á‡§™‡§õ‡§ø ‡§≠‡§®‡•ç‡§¶‡§æ ‡§™‡§®‡§ø ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§®‡•á ‡§≠‡§®‡•á‡§∞ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•Ä‡§Ø ‡§¨‡•à‡§Ç‡§ï‡§≤‡•á ‡§Ø‡•ã ‡§µ‡§ø‡§∑‡§Ø‡§≤‡§æ‡§à ‡§¨‡§®‡•ç‡§ß ‡§ó‡§∞‡•ç‡§®‡•á ‡§ï‡§¶‡§Æ ‡§ö‡§æ‡§≤‡•á‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§ï‡§æ ‡§¨‡•à‡§Ç‡§ï‡§∞‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ü‡§á‡§∏‡§ï‡•á‡§™‡§õ‡§ø ‡§≠‡§®‡•ç‡§¶‡§æ ‡§™‡§®‡§ø ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§®‡•á ‡§≠‡§®‡•á‡§∞ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•Ä‡§Ø ‡§¨‡•à‡§Ç‡§ï‡§≤‡•á ‡§Ø‡•ã ‡§µ‡§ø‡§∑‡§Ø‡§≤‡§æ‡§à ‡§¨‡§®‡•ç‡§¶ ‡§ó‡§∞‡•ç‡§®‡•á ‡§ï‡§¶‡§Æ ‡§ö‡§æ‡§≤‡•á‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§ï‡§æ ‡§¨‡•à‡§Ç‡§ï‡§∞‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§è‡§â‡§ü‡•à ‡§µ‡§°‡§æ‡§¨‡§æ‡§ü ‡§ï‡§∞‡§ø‡§¨ ‡•¨‡•¶ ‡§¶‡•á‡§ñ‡•Ä ‡•Æ‡•¶ ‡§ï‡§ø‡§≤‡•ã ‡§Æ‡§æ‡§∏‡•Å‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§°‡§∞ ‡§Ü‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§∏‡§Æ‡§æ‡§®‡•Ä‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "Corrected: <extra_id_0>‡•§\n",
      "label:     ‡§è‡§â‡§ü‡•à ‡§µ‡§°‡§æ‡§¨‡§æ‡§ü ‡§ï‡§∞‡§ø‡§¨ ‡•¨‡•¶ ‡§¶‡•á‡§ñ‡§ø ‡•Æ‡•¶ ‡§ï‡§ø‡§≤‡•ã ‡§Æ‡§æ‡§∏‡•Å‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§°‡§∞ ‡§Ü‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§∏‡§Æ‡§æ‡§®‡•Ä‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•à ‡§µ‡§∞‡•ç‡§∑ ‡§•‡§™ ‡§ó‡§∞‡§ø‡§è‡§ï‡§æ ‡•©‡•Æ ‡§µ‡§ü‡§æ ‡§∏‡§°‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§≠‡§®‡•á ‡§Ø‡§π‡•Ä ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡•ç‡§™ ‡§∞‡§π‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: <extra_id_0> ‡§Ø‡•ã‡§ú‡§®‡§æ\n",
      "label:     ‡§Ø‡§∏‡•à ‡§µ‡§∞‡•ç‡§∑ ‡§•‡§™ ‡§ó‡§∞‡§ø‡§è‡§ï‡§æ ‡•©‡•Æ ‡§µ‡§ü‡§æ ‡§∏‡§°‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§≠‡§®‡•á ‡§Ø‡§π‡•Ä ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§∞‡§π‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§®‡•ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø ‡§ó‡•à‡§∏‡§∏‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ ‡§∏‡§Æ‡•ç‡§ù‡•å‡§§‡§æ ‡§ó‡§∞‡•ç‡§¶‡§æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã‡§¨‡§Æ‡•ã‡§ú‡§ø‡§Æ ‡§∞‡§ï‡§Æ ‡§ï‡•ã‡§∑‡§Æ‡§æ ‡§ú‡§Æ‡•ç‡§Æ‡§æ ‡§ó‡§∞‡•ç‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§ <extra_id_12>\n",
      "label:     ‡§Ö‡§®‡•ç‡§§‡§∞‡•ç‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø ‡§ó‡•à‡§∏‡§∏‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ ‡§∏‡§Æ‡•ç‡§ù‡•å‡§§‡§æ ‡§ó‡§∞‡•ç‡§¶‡§æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã‡§¨‡§Æ‡•ã‡§ú‡§ø‡§Æ ‡§∞‡§ï‡§Æ ‡§ï‡•ã‡§∑‡§Æ‡§æ ‡§ú‡§Æ‡•ç‡§Æ‡§æ ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§®‡§ï‡•ã ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞‡§∏‡§Å‡§ó ‡•ß‡•¶/‡•ß‡•® ‡§¨‡§ø‡§ò‡§æ ‡§ú‡§Æ‡§ø‡§® ‡§∞‡§π‡•á‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡§π‡§∞‡•Å ‡§¨‡§§‡§æ‡§â‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§â‡§®‡§ï‡•ã ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞‡§∏‡§Å‡§ó ‡•ß‡•¶/‡•ß‡•® ‡§¨‡§ø‡§ò‡§æ ‡§ú‡§Æ‡§ø‡§® ‡§∞‡§π‡•á‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡§π‡§∞‡•Å ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç ‡§ï‡§§‡§æ‡§∞‡§Æ‡§æ : ‡§π‡•Å‡§®‡•á ‡§Ü‡§†‡•å‡§Ç ‡§®‡•á‡§´‡•ç‡§ü‡§æ ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§Ö‡§µ‡§æ‡§∞‡•ç‡§°‡§ï‡§æ ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§™‡§æ‡§Å‡§ö ‡§Æ‡§®‡•ã‡§®‡§Ø‡§® ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§≠‡§è‡§ï‡•ã ‡§õ‡•§\n",
      "Corrected: <extra_id_0> !–ª–æ–≤–Ω–∞\n",
      "label:     ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç : ‡§ï‡§§‡§æ‡§∞‡§Æ‡§æ ‡§π‡•Å‡§®‡•á ‡§Ü‡§†‡•å‡§Ç ‡§®‡•á‡§´‡•ç‡§ü‡§æ ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§Ö‡§µ‡§æ‡§∞‡•ç‡§°‡§ï‡§æ ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§™‡§æ‡§Å‡§ö ‡§Æ‡§®‡•ã‡§®‡§Ø‡§® ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§≠‡§è‡§ï‡•ã ‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§æ‡§≤‡•Ä‡§ï‡•ã‡§ü ‚Äî ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§ó‡§§ ‡§µ‡•à‡§∂‡§æ‡§ñ‡§Æ‡§æ ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä‚Äì‡§∞‡§æ‡§∞‡§æ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§® ‡§µ‡§∞‡•ç‡§∑‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≠‡§ø‡§§‡•ç‡§∞‡•Å ‡§∏‡§°‡§ï ‡§¨‡§æ‡§ß‡§ï ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ï‡§æ‡§≤‡•Ä‡§ï‡•ã‡§ü ‚Äî ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§ó‡§§ ‡§µ‡•à‡§∂‡§æ‡§ñ‡§Æ‡§æ ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä‚Äì‡§∞‡§æ‡§∞‡§æ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§® ‡§µ‡§∞‡•ç‡§∑‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≠‡§ø‡§§‡•ç‡§∞‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§°‡§ï ‡§¨‡§æ‡§ß‡§ï ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§µ‡§ø‡§ó‡§§ ‡•©‡•¶ ‡§µ‡§∞‡•ç‡§∑‡§∏‡§Æ‡•ç‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§¶‡§ø‡§è‡§™‡§õ‡§ø ‡§ï‡•á‡§è‡§≤‡§è‡§Æ‡§ï‡•ã ‡§Ø‡•ã ‡§µ‡§ø‡§Æ‡§æ‡§®‡§≤‡•á ‡§™‡§Ç‡§ñ‡§æ‡§≤‡§æ‡§à ‡§Ü‡§∞‡§æ‡§Æ ‡§¶‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§µ‡§ø‡§ó‡§§ ‡•©‡•¶ ‡§µ‡§∞‡•ç‡§∑‡§∏‡§Æ‡•ç‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§¶‡§ø‡§è‡§™‡§õ‡§ø ‡§ï‡•á‡§è‡§≤‡§è‡§Æ‡§ï‡•ã ‡§Ø‡•ã ‡§µ‡§ø‡§Æ‡§æ‡§®‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§™‡§Ç‡§ñ‡§æ‡§≤‡§æ‡§à ‡§Ü‡§∞‡§æ‡§Æ ‡§¶‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ö‡•Ä‡§® ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§≤‡§æ‡§à ‡§π‡§∞‡•á‡§ï ‡§¢‡§Ç‡§ó‡§≤‡•á ‡§∏‡§ò‡§æ‡§â‡§®‡•á ‡§≠‡§®‡•á‡§ï‡•ã ‡§õ ‡§Ø‡•ã ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§π‡•ã ‡§Ø‡§∏‡§ï‡•ã ‡§ñ‡•Å‡§≤‡•á‡§∞ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ó‡§∞‡•ç‡•à ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ö‡•Ä‡§® ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§≤‡§æ‡§à ‡§π‡§∞‡•á‡§ï ‡§¢‡§Ç‡§ó‡§≤‡•á ‡§∏‡§ò‡§æ‡§â‡§®‡•á ‡§≠‡§®‡•á‡§ï‡•ã ‡§õ ‡§Ø‡•ã ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§π‡•ã ‡§Ø‡§∏‡§ï‡•ã ‡§ñ‡•Å‡§≤‡•á‡§∞ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ó‡§∞‡•ç‡§õ‡•å‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§¶‡§∞‡•ç‡§∂‡§® ‡§≠‡•ç‡§∞‡§Æ‡§£ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§™‡§ü‡§®‡§æ‡§ï‡•ã ‡§∏‡§∞‡•ç‡§ï‡§ø‡§ü ‡§π‡§æ‡§â‡§∏‡§Æ‡§æ ‡§∞‡§æ‡§§ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§¶‡§∞‡•ç‡§∂‡§® ‡§≠‡•ç‡§∞‡§Æ‡§£ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§™‡§ü‡§®‡§æ‡§ï‡•ã ‡§∏‡§∞‡•ç‡§ï‡§ø‡§ü ‡§π‡§æ‡§â‡§∏‡§Æ‡§æ ‡§∞‡§æ‡§§ ‡§¨‡§ø‡§§‡§æ‡§Ø‡•å‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§¨‡•ç‡§∞‡•ã‡§ï‡§∞‡§≤‡•á ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡•Å‡§∞‡•Å ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•á‡§Æ‡•Ä‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§®‡§≠‡§è‡§ï‡•ã ‡§®‡•á‡§™‡•ç‡§∏‡•á‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§ö‡§®‡•ç‡§¶‡•ç‡§∞‡§∏‡§ø‡§Ç‡§π ‡§∏‡§æ‡§â‡§¶‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§¨‡•ç‡§∞‡•ã‡§ï‡§∞‡§≤‡•á ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•á‡§Æ‡•Ä‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§®‡§≠‡§è‡§ï‡•ã ‡§®‡•á‡§™‡•ç‡§∏‡•á‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§ö‡§®‡•ç‡§¶‡•ç‡§∞‡§∏‡§ø‡§Ç‡§π ‡§∏‡§æ‡§â‡§¶‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§®‡§Æ‡§æ ‡§µ‡§ø‡§Æ‡§æ‡§®‡§∏‡•ç‡§•‡§≤ ‡§µ‡§∞‡§™‡§∞‡§ï‡§æ ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§§‡§•‡§æ ‡§ó‡§æ‡§â‡§Å‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡§æ‡§à ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§è‡§µ‡§Ç ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§∂‡§π‡§∞ ‡§¨‡§®‡§® ‡§≤‡§ó‡§æ‡§è‡§Æ‡§æ ‡§è‡§Ø‡§∞‡§™‡•ã‡§∞‡•ç‡§ü ‡§∏‡§ø‡§ü‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Å‡§®‡•á ‡§†‡§π‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§õ ‡•§\n",
      "label:     ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§®‡§Æ‡§æ ‡§µ‡§ø‡§Æ‡§æ‡§®‡§∏‡•ç‡§•‡§≤ ‡§µ‡§∞‡§™‡§∞‡§ï‡§æ ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§§‡§•‡§æ ‡§ó‡§æ‡§â‡§Å‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡§æ‡§à ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§è‡§µ‡§Ç ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§∂‡§π‡§∞ ‡§¨‡§®‡§æ‡§â‡§® ‡§≤‡§ó‡§æ‡§è‡§Æ‡§æ ‡§è‡§Ø‡§∞‡§™‡•ã‡§∞‡•ç‡§ü ‡§∏‡§ø‡§ü‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Å‡§®‡•á ‡§†‡§π‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§§‡§∞ ‡§µ‡§ø‡§°‡§Æ‡•ç‡§¨‡§®‡§æ ‡§ï‡•á ‡§õ ‡§≠‡§®‡•á, ‡§Ø‡§∏‡•ç‡§§‡§æ ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä‡§Æ‡§æ ‡§≠‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§õ‡§®‡•ç, ‡§Æ‡§æ‡§≤‡§ø‡§ï ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§¶‡•à‡§®‡§®‡•ç, ‡§™‡§§‡•ç‡§§‡§æ ‡§®‡•à ‡§≤‡§æ‡§ó‡•ç‡§® ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§§‡§∞ ‡§µ‡§ø‡§°‡§Æ‡•ç‡§¨‡§®‡§æ ‡§ï‡•á ‡§õ ‡§≠‡§®‡•á, ‡§Ø‡§∏‡•ç‡§§‡§æ ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä‡§Æ‡§æ ‡§≠‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§õ‡§®‡•ç, ‡§Æ‡§æ‡§≤‡§ø‡§ï ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§¶‡•à‡§®‡§®‡•ç, ‡§™‡§§‡•ç‡§§‡§æ ‡§®‡•à ‡§≤‡§æ‡§ó‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡•ã‡§π‡•Ä ‡§∞‡§ø‡§ü‡§Æ‡§æ ‡§∏‡§∞‡•ç‡§µ‡•ã‡§ö‡•ç‡§ö‡§≤‡•á ‡§¢‡•Å‡§Ç‡§ó‡•á‡§≤‡§≤‡§æ‡§à ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§ó‡§∞‡•Ä ‡§ï‡§æ‡§∞‡§ó‡§æ‡§∞‡§Æ‡§æ ‡§¨‡•Å‡§ù‡§æ‡§â‡§® ‡§Ü‡§¶‡•á‡§∂ ‡§¶‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§∏‡•ã‡§π‡•Ä ‡§∞‡§ø‡§ü‡§Æ‡§æ ‡§∏‡§∞‡•ç‡§µ‡•ã‡§ö‡•ç‡§ö‡§≤‡•á ‡§¢‡•Å‡§Ç‡§ó‡•á‡§≤‡§≤‡§æ‡§à ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§ó‡§∞‡•Ä ‡§ï‡§æ‡§∞‡§ó‡§æ‡§∞‡§Æ‡§æ ‡§¨‡•Å‡§ù‡§æ‡§â‡§® ‡§Ü‡§¶‡•á‡§∂ ‡§¶‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡§∞ ‡§™‡•Å‡§Å‡§ú‡•Ä‡§ó‡§§ ‡§≤‡§æ‡§≠‡§ï‡§∞‡§ï‡•ã ‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§Æ‡§æ ‡§™‡§®‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§Ç‡§ó‡§≤‡§¨‡§æ‡§∞‡§Æ‡§æ‡§§‡•ç‡§∞ ‡•≠‡•¶ ‡§≤‡§æ‡§ñ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•à ‡§ó‡•Å‡§Æ‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡•à‡§ó‡§∞‡•Ä ‡§™‡•Å‡§Å‡§ú‡•Ä‡§ó‡§§ ‡§≤‡§æ‡§≠‡§ï‡§∞‡§ï‡•ã ‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§Æ‡§æ ‡§™‡§®‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§Ç‡§ó‡§≤‡§¨‡§æ‡§∞‡§Æ‡§æ‡§§‡•ç‡§∞ ‡•≠‡•¶ ‡§≤‡§æ‡§ñ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•à ‡§ó‡•Å‡§Æ‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡§õ‡§ø‡§≤‡•ç‡§≤‡§æ ‡§ï‡•á‡§π‡•Ä ‡§Æ‡•à‡§®‡§æ ‡§∞‡•á‡§Æ‡§ø‡§ü‡§Ø‡§æ‡§®‡•ç‡§∏ ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø‡§¶‡§∞ ‡§¨‡§¢‡•ç‡§¶‡•à ‡§ó‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø‡§¶‡§∞\n",
      "label:     ‡§™‡§õ‡§ø‡§≤‡•ç‡§≤‡§æ ‡§ï‡•á‡§π‡•Ä ‡§Æ‡§π‡§ø‡§®‡§æ ‡§∞‡•á‡§Æ‡§ø‡§ü‡§Ø‡§æ‡§®‡•ç‡§∏ ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø‡§¶‡§∞ ‡§¨‡§¢‡•ç‡§¶‡•à ‡§ó‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§á‡§Ç‡§ó‡•ç‡§≤‡•ç‡§Ø‡§æ‡§®‡•ç‡§° ‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏‡§Æ‡§æ ‡§≠‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡§™‡§Æ‡§æ ‡§¨‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§´‡•ç‡§≤‡•ç‡§Ø‡§æ‡§ü ‡§™‡§ø‡§ö‡§≤‡•á ‡§¨‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡§Æ‡•ç‡§Ø‡§æ‡§®‡§≤‡§æ‡§à ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡•Å‡§ó‡•ç‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ó‡§∞‡§ø‡§è ‡§™‡§®‡§ø ‡§Ö‡§≤‡•Ä ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§ö‡§ø‡§®‡•ç‡§§‡§ø‡§§ ‡§õ‡§® ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§á‡§Ç‡§ó‡•ç‡§≤‡•ç‡§Ø‡§æ‡§®‡•ç‡§° ‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏‡§Æ‡§æ ‡§≠‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡§™‡§Æ‡§æ ‡§¨‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§´‡•ç‡§≤‡•ç‡§Ø‡§æ‡§ü ‡§™‡§ø‡§ö‡§≤‡•á ‡§¨‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡§Æ‡•ç‡§Ø‡§æ‡§®‡§≤‡§æ‡§à ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡•Å‡§ó‡•ç‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ó‡§∞‡§ø‡§è ‡§™‡§®‡§ø ‡§Ö‡§≤‡•Ä ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§ö‡§ø‡§®‡•ç‡§§‡§ø‡§§ ‡§õ‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•à ‡§®‡•Ä‡§§‡§ø‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£‡•Ä ‡§ö‡§ø‡§®‡§ø‡§Ø‡§æ‡§Å‡§π‡§∞‡•Ç ‡§≤‡§ó‡§æ‡§®‡•Ä‡§ï‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ ‡§¨‡•ã‡§ï‡•á‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§∏‡§Æ‡•ç‡§Æ‡•à ‡§™‡•Å‡§ó‡§ø‡§∏‡§ï‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ?\n",
      "Corrected: <extra_id_0> ?\n",
      "label:     ‡§Ø‡§∏‡•à ‡§®‡•Ä‡§§‡§ø‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£‡•Ä ‡§ö‡§ø‡§®‡§ø‡§Ø‡§æ‡§Å‡§π‡§∞‡•Ç ‡§≤‡§ó‡§æ‡§®‡•Ä‡§ï‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ ‡§¨‡•ã‡§ï‡•á‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§∏‡§Æ‡•ç‡§Æ‡•à ‡§™‡•Å‡§ó‡§ø‡§∏‡§ï‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∞‡§µ‡•Ä‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§ï‡•ã ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø‡§≤‡•á ‡§ï‡§∞ ‡§â‡§®‡•ç‡§Æ‡•Å‡§ï‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§®‡•à ‡§∏‡§ò‡§æ‡§â ‡§™‡•Å‡§∞‡•ç‚Äç‡§Ø‡§æ‡§â‡§®‡•á ‡§ó‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡•§\n",
      "Corrected: <extra_id_0>‡§≤‡§æ‡§à ‡§®‡•à ‡§∏‡§ò‡§æ‡§â ‡§™‡•Å‡§∞‡•ç ‡§Ø‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
      "label:     ‡§∞‡§µ‡•Ä‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§ï‡•ã ‡§§‡§§‡•ç‡§ï‡§æ‡§≤‡•Ä‡§® ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø‡§≤‡•á ‡§ï‡§∞ ‡§â‡§®‡•ç‡§Æ‡•Å‡§ï‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§®‡•à ‡§∏‡§ò‡§æ‡§â ‡§™‡•Å‡§∞‡•ç‚Äç‡§Ø‡§æ‡§â‡§®‡•á ‡§ó‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§∏‡§ï‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§ß‡•á‡§∞‡•à ‡§õ‡§®‡•ç ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§â‡§∏‡§ï‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§ß‡•á‡§∞‡•à ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§®‡•ç‡§Ø ‡§™‡§∞‡§ø‡§ö‡§Ø‡§™‡§§‡•ç‡§∞‡§ß‡§æ‡§∞‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§ï‡•ç‡§∞‡§Æ‡§∂‡§É ‡§∏‡§π‡•Å‡§≤‡§ø‡§Ø‡§§‡§Æ‡§æ ‡§∏‡•á‡§µ‡§æ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§™‡§æ‡§â‡§®‡•á ‡§ú‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§õ\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ ?\n",
      "label:     ‡§Ö‡§®‡•ç‡§Ø ‡§™‡§∞‡§ø‡§ö‡§Ø‡§™‡§§‡•ç‡§∞‡§ß‡§æ‡§∞‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§ï‡•ç‡§∞‡§Æ‡§∂‡§É ‡§∏‡§π‡•Å‡§≤‡§ø‡§Ø‡§§‡§Æ‡§æ ‡§∏‡•á‡§µ‡§æ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§™‡§æ‡§â‡§®‡•á ‡§ú‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ó‡•ã‡§ö‡§∞‡§≤‡•á ‡§è‡§ï ‡§∏‡§§‡§§‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ‡§ó‡§∞‡•ç‡§®‡•á ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§‡§§‡§æ‡§≤‡§æ‡§à ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ï‡•ã ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ó‡§∞‡•ç‡§® ‡§â‡§§‡•ç‡§™‡•ç‡§∞‡•á‡§∞‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ó‡•ã‡§ö‡§∞‡§≤‡•á ‡§è‡§ï ‡§∏‡§§‡§§‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ‡§ó‡§∞‡•ç‡§®‡•á ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§‡§§‡§æ‡§≤‡§æ‡§à ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ó‡§∞‡•ç‡§® ‡§â‡§§‡•ç‡§™‡•ç‡§∞‡•á‡§∞‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§ñ‡§æ‡§®‡§™‡§ø‡§® ‡§π‡•Å‡§®‡•ç‡§• ‡•§\n",
      "Corrected: <extra_id_0>\n",
      "label:     ‡§ñ‡§æ‡§®‡§™‡§ø‡§® ‡§π‡•Å‡§®‡•ç‡§•‡•ç‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡•Ä‡§Æ‡§æ‡§∏‡•ç‡§§‡§Æ‡•ç‡§≠ ‡§ó‡§æ‡§°‡•ç‡§®‡•Å‡§Ö‡§ò‡§ø ‡§§‡•ç‡§Ø‡§∏ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§∏‡§Å‡§ó ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§®‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•á ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§ó‡§æ‡§°‡•ç‡§®‡•Å‡§Ö‡§ò‡§ø\n",
      "label:     ‡§∏‡•Ä‡§Æ‡§æ‡§∏‡•ç‡§§‡§Æ‡•ç‡§≠ ‡§ó‡§æ‡§°‡•ç‡§®‡•Å‡§Ö‡§ò‡§ø ‡§§‡•ç‡§Ø‡§∏ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§∏‡§Å‡§ó ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§®‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•á ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§¨‡•Å‡§ù‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∞‡§Æ‡§æ‡§à ‡§∞‡§Æ‡§æ‡§à ‡§Æ ‡§§‡§ø‡§®‡•à ‡§õ‡§æ‡§≤ ‡§π‡•á‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•ç‡§¶‡•ã ‡§∞‡§π‡§¶ ‡•§\n",
      "Corrected: <extra_id_0> ‡§∞‡§Æ‡§æ‡§à ‡§∞‡§Æ‡§æ‡§à\n",
      "label:     ‡§∞‡§Æ‡§æ‡§à ‡§∞‡§Æ‡§æ‡§à ‡§Æ ‡§§‡§ø‡§®‡•à ‡§õ‡§æ‡§≤ ‡§π‡•á‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•ç‡§¶‡•ã ‡§∞‡§π‡•á‡§õ‡•Å ‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§µ‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å ‡§µ‡§ø‡§ú‡•ç‡§û‡§≤‡•á ‡§ï‡•Å‡§® ‡§¨‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å‡§ï‡•ã ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§®‡•ã‡§ü‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•á, ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§µ‡§ø‡§¶‡•ç‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§ï‡•Å‡§® ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§µ‡§¶‡•ç‡§∞‡•ç‡§ß‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡§ø‡§®‡•ç ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§µ‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å ‡§µ‡§ø‡§ú‡•ç‡§û‡§≤‡•á ‡§ï‡•Å‡§® ‡§¨‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å‡§ï‡•ã ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§®‡•ã‡§ü‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•á, ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§µ‡§ø‡§¶‡•ç‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§ï‡•Å‡§® ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§µ‡§¶‡•ç‡§∞‡•ç‡§ß‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡§ø‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§§‡§ø‡§∏‡§Æ‡•ç‡§Æ ‡§ï‡§ø ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∂‡•à‡§∂‡§µ‡§ï‡§æ‡§≤‡§¶‡•á‡§ñ‡§ø ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§π‡§∞‡•á‡§ï ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ò‡§ü‡§®‡§æ, ‡§§‡§ø‡§•‡§ø‚Äì‡§Æ‡§ø‡§§‡§ø‡§∏‡§π‡§ø‡§§ ‡§∏‡§µ‡§æ‡§≤‚Äì‡§ú‡§µ‡§æ‡§´ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ ‡§â‡§®‡•Ä ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§Ø‡§§‡§ø‡§∏‡§Æ‡•ç‡§Æ ‡§ï‡§ø ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∂‡•à‡§∂‡§µ‡§ï‡§æ‡§≤‡§¶‡•á‡§ñ‡§ø ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§π‡§∞‡•á‡§ï ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ò‡§ü‡§®‡§æ, ‡§§‡§ø‡§•‡§ø‚Äì‡§Æ‡§ø‡§§‡§ø‡§∏‡§π‡§ø‡§§ ‡§∏‡§µ‡§æ‡§≤‚Äì‡§ú‡§µ‡§æ‡§´ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ‡§®‡•ç ‡§â‡§®‡•Ä ‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡•à‡§≤‡•á ‡§π‡§æ‡§Æ‡•Ä ‡§≠‡§æ‡§∞‡§§‡§ï‡•ã ‡§≤‡§¶‡§æ‡§ñ ‡§™‡•Å‡§ó‡•ç‡•å ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡•à‡§≤‡•á ‡§π‡§æ‡§Æ‡•Ä ‡§≠‡§æ‡§∞‡§§‡§ï‡•ã ‡§≤‡§¶‡§æ‡§ñ ‡§™‡•Å‡§ó‡•ç‡§Ø‡•å‡§Å ‡•§\n",
      "---\n",
      "Original:  ‡§ñ‡§æ‡§∏‡§ó ‡§Æ‡§π‡§ø‡§≤‡§æ‡§Æ‡§æ‡§•‡§ø‡§ï‡•ã ‡§µ‡§ø‡§≠‡•á‡§¶ ‡§∞ ‡§™‡§ø‡§§‡•É‡§∏‡§§‡•ç‡§§‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∏‡•ã‡§ö‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§õ‡§ø‡§®‡•ç ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ñ‡§æ‡§∏‡§ó‡§∞‡•Ä ‡§Æ‡§π‡§ø‡§≤‡§æ‡§Æ‡§æ‡§•‡§ø‡§ï‡•ã ‡§µ‡§ø‡§≠‡•á‡§¶ ‡§∞ ‡§™‡§ø‡§§‡•É‡§∏‡§§‡•ç‡§§‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∏‡•ã‡§ö‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§π‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§õ‡§ø‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§π‡§ø‡§≤‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§§‡§π‡§Æ‡§æ ‡§ï‡§∞‡•ç‡§Æ‡§ö‡§æ‡§∞‡•Ä ‡§ñ‡§ü‡§æ‡§â‡§Å‡§¶‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡•ã ‡§µ‡§ø‡§µ‡§æ‡§¶‡§ï‡•ã ‡§ö‡•Ç‡§∞‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§™‡§• ‡§π‡•ã ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§Ö‡§π‡§ø‡§≤‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§§‡§π‡§Æ‡§æ ‡§ï‡§∞‡•ç‡§Æ‡§ö‡§æ‡§∞‡•Ä ‡§ñ‡§ü‡§æ‡§â‡§Å‡§¶‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡•ã ‡§µ‡§ø‡§µ‡§æ‡§¶‡§ï‡•ã ‡§ö‡•Ç‡§∞‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§™‡§¶ ‡§π‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•á‡§∞‡•á‡§ï‡•ã ‡§∞ ‡§ï‡•ã‡§ü‡•ç‡§Ø‡§æ‡§è‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§Æ‡§æ ‡§∏‡§æ‡§Æ‡§æ‡§® ‡§∞ ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡•ç ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§®‡•á‡§™‡§æ‡§≤ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§ï‡§æ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§ï ‡§ß‡•ç‡§∞‡•Å‡§µ ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§†‡§≤‡•á ‡§ó‡•Å‡§®‡§æ‡§∏‡•ã ‡§ó‡§∞‡•á‡•§\n",
      "Corrected: <extra_id_0> ‡§∏‡§π‡§ø‡§§\n",
      "label:     ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•á‡§∞‡•á‡§ï‡•ã ‡§∞ ‡§ï‡•ã‡§ü‡•ç‡§Ø‡§æ‡§è‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§Æ‡§æ ‡§∏‡§æ‡§Æ‡§æ‡§® ‡§∞ ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§®‡•á‡§™‡§æ‡§≤ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§ï‡§æ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§ï ‡§ß‡•ç‡§∞‡•Å‡§µ ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§†‡§≤‡•á ‡§ó‡•Å‡§®‡§æ‡§∏‡•ã ‡§ó‡§∞‡•á‡•§\n",
      "---\n",
      "Original:  ‡§≤‡•ç‡§µ‡§æ‡§ô‡§ò‡§≤‡•á‡§≤‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§™‡•ã‡§ñ‡§∞‡§æ ‡§ï‡•ç‡§Ø‡§æ‡§®‡•ã‡§á‡§®‡§ø‡§ô ‡§∞ ‡§°‡•ç‡§∞‡§ø‡§Æ‡§≤‡•ç‡§Ø‡§æ‡§®‡•ç‡§° ‡§ï‡•ç‡§Ø‡§æ‡§®‡•ã‡§á‡§®‡§ø‡§ô ‡§∞ ‡§µ‡•Ä‡§∞‡•á‡§†‡§æ‡§Å‡§ü‡•Ä ‡§ï‡•ç‡§Ø‡§æ‡§®‡•ã‡§á‡§®‡§ø‡§ô‡§≤‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§≤‡•ç‡§µ‡§æ‡§ô‡§ò‡§≤‡•á‡§≤‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§™‡•ã‡§ñ‡§∞‡§æ ‡§ï‡•ç‡§Ø‡§æ‡§®‡•ã‡§á‡§®‡§ø‡§ô ‡§∞ ‡§°‡•ç‡§∞‡§ø‡§Æ‡§≤‡•ç‡§Ø‡§æ‡§®‡•ç‡§° ‡§ï‡•ç‡§Ø‡§æ‡§®‡•ã‡§á‡§®‡§ø‡§ô ‡§∞ ‡§µ‡•Ä‡§∞‡•á‡§†‡§æ‡§Å‡§ü‡•Ä ‡§ï‡•ç‡§Ø‡§æ‡§®‡•ã‡§á‡§®‡§ø‡§ô‡§≤‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡•ã ‡§ï‡§æ‡§Æ ‡§∏‡§ï‡§ø‡§è‡§™‡§õ‡§ø ‡§µ‡•à‡§∂‡§æ‡§ñ ‡§§‡•á‡§∏‡•ç‡§∞‡•ã ‡§∏‡§æ‡§§‡§æ‡§¨‡§æ‡§ü ‡§∏‡•ç‡§§‡§∞‡•ã‡§®‡•ç‡§®‡§§‡§ø ‡§∏‡•Å‡§∞‡•Å ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡•Å‡§¨‡•ã‡§ß‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§¶‡•á‡§µ‡§ï‡•ã‡§ü‡§æ‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "Corrected: <extra_id_0> -\n",
      "label:     ‡§Ø‡•ã ‡§ï‡§æ‡§Æ ‡§∏‡§ï‡§ø‡§è‡§™‡§õ‡§ø ‡§µ‡•à‡§∂‡§æ‡§ñ ‡§§‡•á‡§∏‡•ç‡§∞‡•ã ‡§∏‡§æ‡§§‡§æ‡§¨‡§æ‡§ü ‡§∏‡•ç‡§§‡§∞‡•ã‡§®‡•ç‡§®‡§§‡§ø ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡§ø‡§®‡•á ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡•Å‡§¨‡•ã‡§ß‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§¶‡•á‡§µ‡§ï‡•ã‡§ü‡§æ‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "---\n",
      "Original:  ‡§è‡§ï‡§§‡§æ ‡§≠‡§§‡•ç‡§ï‡§® ‡§ú‡§∏‡•ç‡§§‡•ã‡§∏‡•Å‡§ï‡•à ‡§∑‡§°‡•ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§ñ‡§§‡§∞‡§æ : ‡§™‡•ç‡§∞‡§ö‡§£‡•ç‡§° ‡§ï‡•ã ‡§≤‡§æ‡§ó‡•Ä ‡§ï‡•Å‡§®‡•à ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§õ‡•à‡§® ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§è‡§ï‡§§‡§æ ‡§≠‡§§‡•ç‡§ï‡§æ‡§â‡§® ‡§ú‡§∏‡•ç‡§§‡•ã‡§∏‡•Å‡§ï‡•à ‡§∑‡§°‡•ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§ñ‡§§‡§∞‡§æ : ‡§™‡•ç‡§∞‡§ö‡§£‡•ç‡§° ‡§ï‡•ã ‡§≤‡§æ‡§ó‡•Ä ‡§ï‡•Å‡§®‡•à ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§õ‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§®‡•Ä ‡§π‡§∞‡§ï‡•ç‡§∑‡§£ ‡§Ø‡•Å‡§µ‡§§‡•Ä‡§ï‡•ã ‡§∏‡§æ‡§• ‡§ñ‡•ã‡§ú‡•ç‡§® ‡§•‡§æ‡§≤‡•ç‡§Ç ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§â‡§®‡•Ä ‡§π‡§∞‡§ï‡•ç‡§∑‡§£ ‡§Ø‡•Å‡§µ‡§§‡•Ä‡§ï‡•ã ‡§∏‡§æ‡§• ‡§ñ‡•ã‡§ú‡•ç‡§® ‡§•‡§æ‡§≤‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§∞‡•ç‡§µ‡•ã‡§ö‡•ç‡§ö ‡§Ö‡§¶‡§æ‡§≤‡§§‡§ï‡•ã ‡§Ü‡§¶‡•á‡§∂‡§™‡§õ‡§ø ‡§¨‡§®‡•á‡§ï‡•ã ‡§µ‡§ø‡§ú‡•ç‡§û ‡§ü‡•ã‡§≤‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§≤‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•á‡§∞ ‡§ú‡•ã‡§ó‡§æ‡§â‡§® ‡§≠‡§®‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡•á‡§∞ ‡§ú‡•ã‡§ó‡§æ‡§â‡§® ‡§≠‡§®‡•á‡§∞\n",
      "label:     ‡§∏‡§∞‡•ç‡§µ‡•ã‡§ö‡•ç‡§ö ‡§Ö‡§¶‡§æ‡§≤‡§§‡§ï‡•ã ‡§Ü‡§¶‡•á‡§∂‡§™‡§õ‡§ø ‡§¨‡§®‡•á‡§ï‡•ã ‡§µ‡§ø‡§ú‡•ç‡§û ‡§ü‡•ã‡§≤‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§≤‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•á‡§∞ ‡§ú‡•ã‡§ó‡§æ‡§â‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§≠‡§®‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§è‡§®‡§™‡§ø‡§è‡§≤‡§Æ‡§æ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä‡§ï‡•ã ‡§Æ‡•ç‡§Ø‡§æ‡§ö ‡§´‡§ø‡§Æ‡§æ ‡§ö‡§æ‡§∞ ‡§ó‡•Å‡§£‡§æ‡§≤‡•á ‡§¨‡•É‡§¶‡•ç‡§ß‡§ø ‡§≠‡§è‡§ï‡•ã ‡§ú‡•ã‡§π‡§∞‡§æ‡§≤‡•á ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ó‡§∞‡•á‡§ï‡•ã ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§è‡§®‡§™‡§ø‡§è‡§≤‡§Æ‡§æ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä‡§ï‡•ã ‡§Æ‡•ç‡§Ø‡§æ‡§ö ‡§´‡§ø‡§Æ‡§æ ‡§ö‡§æ‡§∞ ‡§ó‡•Å‡§£‡§æ‡§≤‡•á ‡§¨‡•É‡§¶‡•ç‡§ß‡§ø ‡§≠‡§è‡§ï‡•ã ‡§ú‡•ã‡§π‡§∞‡§æ‡§≤‡•á ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡•ç‡§§‡•à ‡§ï‡§™‡•ç‡§§‡§æ‡§® ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ‡•ç‡§∏‡§®‡§≤‡•á ‡•ß‡•® ‡§∞‡§® ‡§≠‡§®‡•á ‡§¨‡•ç‡§∞‡•Å‡§∏ ‡§Ö‡§µ‡§ø‡§ú‡§ø‡§§ ‡•ß‡•Æ ‡§∞‡§®‡§Æ‡§æ ‡§∞‡§π‡•á ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡•ç‡§§‡•à ‡§ï‡§™‡•ç‡§§‡§æ‡§® ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ‡•ç‡§∏‡§®‡§≤‡•á ‡•ß‡•® ‡§∞‡§® ‡§ú‡•ã‡§°‡•á ‡§≠‡§®‡•á ‡§¨‡•ç‡§∞‡•Å‡§∏ ‡§Ö‡§µ‡§ø‡§ú‡§ø‡§§ ‡•ß‡•Æ ‡§∞‡§®‡§Æ‡§æ ‡§∞‡§π‡•á ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Æ‡§ó‡•ç‡§∞‡§Æ‡§æ, ‡§π‡•ã‡§≤‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ ‡§∞ ‡§Ü‡§®‡§®‡•ç‡§¶‡§ï‡•ã ‡§â‡§§‡•ç‡§∏‡§µ ‡§π‡•ã\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§∏‡§Æ‡§ó‡•ç‡§∞‡§Æ‡§æ, ‡§π‡•ã‡§≤‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ ‡§∞ ‡§Ü‡§®‡§®‡•ç‡§¶‡§ï‡•ã ‡§â‡§§‡•ç‡§∏‡§µ ‡§π‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§≤‡•á ‡§¨‡§ö‡•ç‡§ö‡§æ‡§π‡§∞‡•Å‡§≤‡§æ‡§à ‡§π‡§ø‡§Ç‡§∏‡•ç‡§∞‡§ï, ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§ï ‡§¨‡§®‡§õ ‡•§\n",
      "Corrected: <extra_id_0>\n",
      "label:     ‡§Ø‡§∏‡§≤‡•á ‡§¨‡§ö‡•ç‡§ö‡§æ‡§π‡§∞‡•Å‡§≤‡§æ‡§à ‡§π‡§ø‡§Ç‡§∏‡•ç‡§∞‡§ï, ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§ï ‡§¨‡§®‡§æ‡§â‡§Å‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä‡§ï‡•ã ‡§Ø‡§∏‡§™‡§ü‡§ï‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§®‡§ø‡§Ø‡§æ‡§≤‡•ç‡§®‡•Å ‡§≠‡§è‡§ï‡•ã ?\n",
      "Corrected: <extra_id_0> ?\n",
      "label:     ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä‡§ï‡•ã ‡§Ø‡§∏‡§™‡§ü‡§ï‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§®‡§ø‡§Ø‡§æ‡§≤‡•ç‡§®‡•Å ‡§≠‡§è‡§ï‡•ã ‡§õ ?\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§®‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ ‡•§\n",
      "Corrected: <extra_id_0>\n",
      "label:     ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§®‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•Ä‡§°‡§ø‡§§‡§ï‡•ã ‡§Ö‡§®‡•ç‡§® ‡§∏‡•ç‡§•‡§æ‡§®‡§Æ‡§æ ‡§™‡§®‡§ø ‡§ú‡§ó‡•ç‡§ó‡§æ ‡§≠‡§è‡§ï‡•ã ‡§π‡•Å‡§®‡§∏‡§ï‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§¶‡•à ‡§Ö‡§®‡•ç‡§Ø ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ‡§ï‡•ã ‡§Æ‡§æ‡§≤‡§™‡•ã‡§§ ‡§§‡§•‡§æ ‡§®‡§æ‡§™‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø‡§ï‡•ã ‡§¢‡§°‡•ç‡§°‡§æ ‡§™‡§≤‡•ç‡§ü‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§¶‡§æ ‡§¢‡§ø‡§≤‡§æ‡§á ‡§≠‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "Corrected: <extra_id_0> ‡§µ‡§ø‡§§‡§∞‡§£\n",
      "label:     ‡§™‡•Ä‡§°‡§ø‡§§‡§ï‡•ã ‡§Ö‡§®‡•ç‡§Ø ‡§∏‡•ç‡§•‡§æ‡§®‡§Æ‡§æ ‡§™‡§®‡§ø ‡§ú‡§ó‡•ç‡§ó‡§æ ‡§≠‡§è‡§ï‡•ã ‡§π‡•Å‡§®‡§∏‡§ï‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§¶‡•à ‡§Ö‡§®‡•ç‡§Ø ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ‡§ï‡•ã ‡§Æ‡§æ‡§≤‡§™‡•ã‡§§ ‡§§‡§•‡§æ ‡§®‡§æ‡§™‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø‡§ï‡•ã ‡§¢‡§°‡•ç‡§°‡§æ ‡§™‡§≤‡•ç‡§ü‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§¶‡§æ ‡§¢‡§ø‡§≤‡§æ‡§á ‡§≠‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡•Å‡§∞‡§æ ‡§∞ ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§Ø‡§π‡§ø ‡§¨‡§ø‡§ö‡§æ‡§∞, ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£, ‡§§‡§∞‡§ø‡§ï‡§æ ‡§∞ ‡§§‡§Ø‡§æ‡§∞‡•Ä‡§≤‡•á ‡§∏‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§Ü‡§Ø‡§æ‡§§ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§Ü‡§∏‡•á‡§™‡§æ‡§∏‡•á‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§¨‡§æ‡§Å‡§°‡•á‡§∞ ‡§ñ‡§æ‡§®‡•á ‡§¶‡•á‡§ñ‡§ø‡§®‡•ç‡§õ‡•§\n",
      "Corrected: <extra_id_0>‡•§\n",
      "label:     ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§∞ ‡§ï‡•Å‡§∞‡§æ ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§Ø‡§π‡§ø ‡§¨‡§ø‡§ö‡§æ‡§∞, ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£, ‡§§‡§∞‡§ø‡§ï‡§æ ‡§∞ ‡§§‡§Ø‡§æ‡§∞‡•Ä‡§≤‡•á ‡§∏‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§Ü‡§Ø‡§æ‡§§ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§Ü‡§∏‡•á‡§™‡§æ‡§∏‡•á‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§¨‡§æ‡§Å‡§°‡•á‡§∞ ‡§ñ‡§æ‡§®‡•á ‡§¶‡•á‡§ñ‡§ø‡§®‡•ç‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡•ç‡§∞‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡§æ‡§∞‡•Ä, ‡§Ö‡§ó‡•ç‡§∞‡§ó‡§æ‡§Æ‡•Ä ‡§®‡•á‡§§‡§æ ‡§Æ‡§æ‡§®‡•ç‡§® ‡§≠‡§®‡•Ä ‡§π‡§æ‡§Æ‡•Ä‡§≤‡§æ‡§à ‡§∏‡§ø‡§ï‡§æ‡§á‡§®‡•ç‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ï‡•ç‡§∞‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡§æ‡§∞‡•Ä, ‡§Ö‡§ó‡•ç‡§∞‡§ó‡§æ‡§Æ‡•Ä ‡§®‡•á‡§§‡§æ ‡§Æ‡§æ‡§®‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•Ä ‡§π‡§æ‡§Æ‡•Ä‡§≤‡§æ‡§à ‡§∏‡§ø‡§ï‡§æ‡§á‡§®‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§ï‡§æ ‡§Ø‡§ø‡§®‡•à ‡§ó‡•Å‡§£‡§≤‡•á ‡§ï‡§æ‡§Æ‡§¶‡§æ‡§∞‡§ï‡•ã ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§Æ‡§æ‡§ó ‡§ï‡§æ‡§Ø‡§Æ‡•à ‡§∞‡§π‡§®‡•á‡§õ ‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡§æ ‡§Æ‡•ç‡§Ø‡§æ‡§®‡§™‡§æ‡§µ‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§™‡§æ‡§â‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "Corrected: <extra_id_0> ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ‡•§\n",
      "label:     ‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§ï‡§æ ‡§Ø‡§ø‡§®‡•à ‡§ó‡•Å‡§£‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§ï‡§æ‡§Æ‡§¶‡§æ‡§∞‡§ï‡•ã ‡§Æ‡§æ‡§ó ‡§ï‡§æ‡§Ø‡§Æ‡•à ‡§∞‡§π‡§®‡•á‡§õ ‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡§æ ‡§Æ‡•ç‡§Ø‡§æ‡§®‡§™‡§æ‡§µ‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§™‡§æ‡§â‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§¨‡•á‡§™‡§§‡•ç‡§§‡§æ ‡§π‡•Å‡§®‡•Å‡§Æ‡§æ ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ‡§ï‡•ã ‡§™‡§®‡§ø ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§¨‡•Å‡§ù‡§æ‡§á‡§≤‡§æ‡§à ‡§ï‡•á‡§π‡•Ä ‡§™‡•ç‡§∞‡§∑‡•ç‡§ü ‡§™‡§æ‡§∞‡§ø‡§ø ‡§®‡•§\n",
      "Corrected: <extra_id_0> ! <extra_id_10> !\n",
      "label:     ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§¨‡•á‡§™‡§§‡•ç‡§§‡§æ ‡§π‡•Å‡§®‡•Å‡§Æ‡§æ ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ‡§ï‡•ã ‡§™‡§®‡§ø ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§¨‡•Å‡§ù‡§æ‡§á‡§≤‡§æ‡§à ‡§ï‡•á‡§π‡•Ä ‡§™‡•ç‡§∞‡§∑‡•ç‡§ü ‡§™‡§æ‡§∞‡§ø‡§¶‡§ø‡§®‡•Å ‡§®‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ‡§ø‡§§ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§®‡•Ä‡§§‡§ø‡§Æ‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§∏‡§Å‡§ó ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§ó‡§∞‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§§‡§π‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ ‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡§ø‡§®‡•á‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§∞ ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç:\n",
      "label:     ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ‡§ø‡§§ ‡§®‡•Ä‡§§‡§ø‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§∏‡§Å‡§ó ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§ó‡§∞‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§§‡§π‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ ‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡§ø‡§®‡•á‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§π‡§Æ‡•á‡§Ç ‡§§‡•ã ‡§Ö‡§™‡§®‡•ã‡§Ç ‡§®‡•á ‡§π‡•Ä ‡§≤‡•Å‡§ü‡§æ, ‡§ó‡•à‡§∞‡•ã‡§Ç ‡§ï‡§π‡§æ‡§Å ‡§¶‡§Æ ‡§•‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§ï‡§∂‡•ç‡§§‡•Ä ‡§≠‡•Ä ‡§µ‡§π‡•Ä‡§Å ‡§°‡•Å‡§¨‡•Ä, ‡§ú‡§π‡§æ‡§Å ‡§™‡§æ‡§®‡•Ä ‡§ï‡§Æ ‡§•‡§æ‡•§\n",
      "Corrected: <extra_id_0>‡•§\n",
      "label:     ‡§π‡§Æ‡•á‡§Ç ‡§§‡•ã ‡§Ö‡§™‡§®‡•ã‡§Ç ‡§®‡•á ‡§π‡•Ä ‡§≤‡•Å‡§ü‡§æ, ‡§ó‡•à‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§π‡§æ‡§Å ‡§¶‡§Æ ‡§•‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§ï‡§∂‡•ç‡§§‡•Ä ‡§≠‡•Ä ‡§µ‡§π‡•Ä‡§Å ‡§°‡•Å‡§¨‡•Ä, ‡§ú‡§π‡§æ‡§Å ‡§™‡§æ‡§®‡•Ä ‡§ï‡§Æ ‡§•‡§æ‡•§\n",
      "---\n",
      "Original:  ‡§ñ‡§æ‡§∏ ‡§¶‡§æ‡§®‡§µ ‡§§‡§ø‡§®‡•Ä‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç, ‡§ú‡§∏‡§≤‡•á ‡§â‡§®‡§≤‡§æ‡§à ‡§¶‡•á‡§µ‡§§‡§æ ‡§µ‡§æ ‡§¶‡§æ‡§®‡§µ ‡§ú‡§∏‡§∞‡•Ä ‡§π‡•á‡§∞‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: <extra_id_0>‡•§\n",
      "label:     ‡§ñ‡§æ‡§∏ ‡§¶‡§æ‡§®‡§µ ‡§§ ‡§§‡§ø‡§®‡•Ä‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç, ‡§ú‡§∏‡§≤‡•á ‡§â‡§®‡§≤‡§æ‡§à ‡§¶‡•á‡§µ‡§§‡§æ ‡§µ‡§æ ‡§¶‡§æ‡§®‡§µ ‡§ú‡§∏‡§∞‡•Ä ‡§π‡•á‡§∞‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§ï‡•ç‡§§ ‡§´‡•á‡§∏‡•ç‡§ü‡§ø‡§µ‡§≤ ‡§ü‡•Ä‡§≠‡•Ä‡§è‡§∏ ‡§Æ‡•ã‡§ü‡§∞ ‡§∞ ‡§ú‡§ó‡§¶‡§Æ‡•ç‡§¨‡§æ ‡§Æ‡•ã‡§ü‡§∞‡•ç‡§∏‡§ï‡•ã ‡§§‡•Ä‡§® ‡§µ‡§∞‡•ç‡§∑‡§ï‡•ã ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§≠‡§è‡§ï‡•ã ‡§â‡§™‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø‡§Æ‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã ‡•§\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã ‡•§\n",
      "label:     ‡§â‡§ï‡•ç‡§§ ‡§´‡•á‡§∏‡•ç‡§ü‡§ø‡§µ‡§≤ ‡§ü‡•Ä‡§≠‡•Ä‡§è‡§∏ ‡§Æ‡•ã‡§ü‡§∞ ‡§∞ ‡§ú‡§ó‡§¶‡§Æ‡•ç‡§¨‡§æ ‡§Æ‡•ã‡§ü‡§∞‡•ç‡§∏‡§ï‡•ã ‡§§‡•Ä‡§® ‡§µ‡§∞‡•ç‡§∑‡§ï‡•ã ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§≠‡§è‡§ï‡•ã ‡§â‡§™‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø‡§Æ‡§æ ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§Æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡•Å‡§ñ ‡§π‡•Å‡§¶ ‡§Æ‡•à‡§≤‡•á ‡§™‡•Ç‡§∞‡•à ‡§™‡§æ‡§†‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§Å ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§Æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡•Å‡§ñ ‡§π‡•Å‡•Å‡§Å‡§¶‡§æ ‡§Æ‡•à‡§≤‡•á ‡§™‡•Ç‡§∞‡•à ‡§™‡§æ‡§†‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§Å ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§æ‡§´‡§æ‡§Æ‡§æ ‡§ö‡§≤‡•ç‡§®‡•á, ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ß‡•á‡§∞‡•à ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§®‡§ø ‡§ï‡§Æ ‡§π‡•Å‡§®‡•á ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡•á‡§ü‡•ç‡§∞‡•ã‡§∞‡•á‡§≤ ‡§∏‡§û‡•ç‡§ö‡§æ‡§≤‡§® ‡§ó‡§∞‡•ç‡§® ‡§ï‡§§‡•ç‡§§‡§ø ‡§™‡§®‡§ø ‡§¢‡§ø‡§≤‡§æ‡§á ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§®‡§æ‡§´‡§æ‡§Æ‡§æ ‡§ö‡§≤‡•ç‡§®‡•á, ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ß‡•á‡§∞‡•à ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§®‡§ø ‡§ï‡§Æ ‡§π‡•Å‡§®‡•á ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡•á‡§ü‡•ç‡§∞‡•ã‡§∞‡•á‡§≤ ‡§∏‡§û‡•ç‡§ö‡§æ‡§≤‡§® ‡§ó‡§∞‡•ç‡§® ‡§ï‡§§‡•ç‡§§‡§ø ‡§™‡§®‡§ø ‡§¢‡§ø‡§≤‡§æ‡§á ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•Å‡§Å‡§¶‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏ ‡§ï‡§æ‡§∞‡§£‡§≤‡•á ‡§Ö‡§®‡§ß‡§ø‡§ï‡•É‡§§ ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§§‡•ã‡§∞‡•Ä‡§ï‡•ã ‡§§‡•á‡§≤ ‡§≠‡§ø‡§§‡•ç‡§∞‡§ø‡§®‡•á ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§Ö‡§§‡•ç‡§Ø‡§®‡•ç‡§§ ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§≠‡§è‡§ï‡•ã ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§Ø‡§∏ ‡§ï‡§æ‡§∞‡§£‡§≤‡•á ‡§Ö‡§®‡§ß‡§ø‡§ï‡•É‡§§ ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§§‡•ã‡§∞‡•Ä‡§ï‡•ã ‡§§‡•á‡§≤ ‡§≠‡§ø‡§§‡•ç‡§∞‡§ø‡§®‡•á ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§Ö‡§§‡•ç‡§Ø‡§®‡•ç‡§§ ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§°‡•á‡§¢ ‡§á‡§®‡•ç‡§ö ‡§≠‡§®‡•ç‡§¶‡§æ ‡§Ö‡§ó‡•ç‡§≤‡•ã ‡§π‡§æ‡§á ‡§π‡§ø‡§≤ ‡§≤‡§ó‡§æ‡•Å ‡§π‡•Å‡§®‡•ç‡§® ‡•§\n",
      "Corrected: <extra_id_0>\n",
      "label:     ‡§°‡•á‡§¢ ‡§á‡§®‡•ç‡§ö ‡§≠‡§®‡•ç‡§¶‡§æ ‡§Ö‡§ó‡•ç‡§≤‡•ã ‡§π‡§æ‡§á ‡§π‡§ø‡§≤ ‡§≤‡§ó‡§æ‡§â‡§®‡•Å ‡§π‡•Å‡§®‡•ç‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§ï‡•ç‡§§ ‡§ù‡§°‡§™ ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¶‡§∞‡•ç‡§ú‡§®‡•å‡§Ç ‡§∞‡§æ‡§â‡§®‡•ç‡§° ‡§Ö‡§∂‡•ç‡§∞‡•Å‡§ó‡•ç‡§Ø‡§æ‡§∏ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•á‡§ï‡•ã ‡§á‡§≤‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡•á‡§≤‡•ç‡§ü‡§æ‡§∞‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§≠‡•Ä‡§Æ‡§ï‡§æ‡§®‡•ç‡§§ ‡§∏‡§ø‡§≤‡§µ‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§è?\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ‡•§\n",
      "label:     ‡§â‡§ï‡•ç‡§§ ‡§ù‡§°‡§™ ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¶‡§∞‡•ç‡§ú‡§®‡•å‡§Ç ‡§∞‡§æ‡§â‡§®‡•ç‡§° ‡§Ö‡§∂‡•ç‡§∞‡•Å‡§ó‡•ç‡§Ø‡§æ‡§∏ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•á‡§ï‡•ã ‡§á‡§≤‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡•á‡§≤‡•ç‡§ü‡§æ‡§∞‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§≠‡•Ä‡§Æ‡§ï‡§æ‡§®‡•ç‡§§ ‡§∏‡§ø‡§≤‡§µ‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§®‡§ø ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø ‡§∏‡§≠‡§æ‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§µ‡§æ‡§ö‡§® ‡§™‡§π‡§ø‡§≤‡§æ ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§â‡§§‡•ç‡§§‡§ø‡§ï‡•à‡•§\n",
      "Corrected: <extra_id_0>‡•§\n",
      "label:     ‡§Ö‡§®‡§ø ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø ‡§∏‡§≠‡§æ‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§µ‡§æ‡§ö‡§® ‡§™‡§π‡§ø‡§≤‡§æ ‡§π‡•Å‡§®‡§∏‡§ï‡•ç‡§®‡•á ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§â‡§§‡•ç‡§§‡§ø‡§ï‡•à‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§°‡§ï ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§ï‡•ã ‡§ï‡§æ‡§Æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§∏‡§ï‡§ø‡§è‡§ï‡•ã ‡§Ø‡•ã‡§ú‡§®‡§æ‡§Æ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∞‡§§ ‡§á‡§û‡•ç‡§ú‡§ø‡§®‡•Ä‡§Ø‡§∞ ‡§®‡•Ä‡§∞‡§û‡•ç‡§ú‡§® ‡§∂‡§∞‡•ç‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§â‡•Å ‡•§\n",
      "Corrected: <extra_id_0> ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§ï‡•ã ‡§ï‡§æ‡§Æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§∏‡§ï‡§ø‡§è‡§ï‡•ã\n",
      "label:     ‡§∏‡§°‡§ï ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§ï‡•ã ‡§ï‡§æ‡§Æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§∏‡§ï‡§ø‡§è‡§ï‡•ã ‡§Ø‡•ã‡§ú‡§®‡§æ‡§Æ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∞‡§§ ‡§á‡§û‡•ç‡§ú‡§ø‡§®‡•Ä‡§Ø‡§∞ ‡§®‡•Ä‡§∞‡§û‡•ç‡§ú‡§® ‡§∂‡§∞‡•ç‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§â‡§®‡•Å‡§≠‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§°‡•Ä‡§™‡•Ä‡§Ü‡§∞ ‡§§‡§Ø‡§æ‡§∞ ‡§≠‡§è‡§™‡§õ‡§ø ‡§¨‡•Å‡§ü ‡§Æ‡•ã‡§°‡•á‡§≤‡§Æ‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡•ã ‡§†‡•á‡§ï‡•ç‡§ï‡§æ ‡§¶‡§ø‡§®‡•á ‡§∏‡•ã‡§ö ‡§∞‡§π‡•á‡§ï‡•ã ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç‡§ï‡§æ ‡§Æ‡•á‡§Ø‡§∞ ‡§∂‡§æ‡§ï‡•ç‡§Ø ‡§¨‡§§‡§æ‡§â‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ?\n",
      "label:     ‡§°‡•Ä‡§™‡•Ä‡§Ü‡§∞ ‡§§‡§Ø‡§æ‡§∞ ‡§≠‡§è‡§™‡§õ‡§ø ‡§¨‡•Å‡§ü ‡§Æ‡•ã‡§°‡•á‡§≤‡§Æ‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡•ã ‡§†‡•á‡§ï‡•ç‡§ï‡§æ ‡§¶‡§ø‡§®‡•á ‡§∏‡•ã‡§ö ‡§∞‡§π‡•á‡§ï‡•ã ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç‡§ï‡§æ ‡§Æ‡•á‡§Ø‡§∞ ‡§∂‡§æ‡§ï‡•ç‡§Ø ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§Æ‡•á‡§ï‡§æ‡§®‡§ø‡§ú‡•ç‡§Æ ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§õ ‡•§\n",
      "label:     ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§Æ‡•á‡§ï‡§æ‡§®‡§ø‡§ú‡•ç‡§Æ ‡§§ ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡•ã ‡§µ‡§∞‡•ç‡§∑ ‡§ú‡§®‡•ç‡§Æ ‡§≤‡§ø‡§®‡•á ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§∂‡•Å‡§≠ ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§≤‡§ø‡§è‡§∞ ‡§ú‡§®‡•ç‡§Æ‡•ç ‡•§\n",
      "Corrected: <extra_id_0>‡•§\n",
      "label:     ‡§Ø‡•ã ‡§µ‡§∞‡•ç‡§∑ ‡§ú‡§®‡•ç‡§Æ ‡§≤‡§ø‡§®‡•á ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§∂‡•Å‡§≠ ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§≤‡§ø‡§è‡§∞ ‡§ú‡§®‡•ç‡§Æ‡§®‡•á‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§™‡§æ‡§≤‡§≤‡•á ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§£ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡§ø‡§è‡§∏‡§Å‡§ó‡•à ‡§∞‡§æ‡§§‡§ø ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§®‡•à ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "label:     ‡§™‡§æ‡§≤‡§≤‡•á ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§£ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡§ø‡§è‡§∏‡§Å‡§ó‡•à ‡§∞‡§æ‡§§‡§ø ‡§®‡•à ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§Æ‡•ç‡§Ø‡•Å‡§®‡§ø‡§∏‡•ç‡§ü‡§ú‡§∏‡•ç‡§§‡•ã ‡§∏‡§§‡•ç‡§§‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§¨‡§∏‡•ç‡§¶‡§æ ‡§Ü‡§§‡§Ç‡§ï ‡§Æ‡§ö‡•ç‡§ö‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§∞ ‡§∞‡•á‡§≤‡§ø‡§ô ‡§≠‡§æ‡§Å‡§ö‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§æ ‡§∞‡§æ‡§ñ‡•ç‡•ç ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ï‡§Æ‡•ç‡§Ø‡•Å‡§®‡§ø‡§∏‡•ç‡§ü‡§ú‡§∏‡•ç‡§§‡•ã ‡§∏‡§§‡•ç‡§§‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§¨‡§∏‡•ç‡§¶‡§æ ‡§Ü‡§§‡§Ç‡§ï ‡§Æ‡§ö‡•ç‡§ö‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§∞ ‡§∞‡•á‡§≤‡§ø‡§ô ‡§≠‡§æ‡§Å‡§ö‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•Å‡§π‡•Å‡§Å‡§¶‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à !\n",
      "Corrected: <extra_id_0>\n",
      "label:     ‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à ?\n",
      "---\n",
      "Original:  ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§Ü‡§è‡§ï‡•ã ‡§≤‡§ø‡§® ‡§∏‡§≠‡§æ‡§∏‡§¶ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§≠‡§è‡§∞ ‡§¶‡§Æ‡§®‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§® ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§®‡•Å ‡§≤‡§æ‡§ú‡§Æ‡§∞‡•ç‡§¶‡•ã ‡§π‡•ã‡•§\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡•ç‡§®‡•Å ‡§≤‡§æ‡§ú‡§Æ‡§∞‡•ç‡§¶‡•ã ‡§π‡•ã‡•§\n",
      "label:     ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§≤‡§ø‡§® ‡§Ü‡§è‡§ï‡•ã ‡§∏‡§≠‡§æ‡§∏‡§¶ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§≠‡§è‡§∞ ‡§¶‡§Æ‡§®‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§® ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§®‡•Å ‡§≤‡§æ‡§ú‡§Æ‡§∞‡•ç‡§¶‡•ã ‡§π‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§§‡•ç‡§§‡§æ‡§ß‡§æ‡§∞‡•Ä‡§π‡§∞‡•Ç ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡•Ä‡§°‡§æ‡§Æ‡§æ ‡§ö‡§ø‡§§‡•ç‡§§ ‡§®‡§¶‡•Å:‡§ñ‡§æ‡§â‡§®‡•á ‡§∞ ‡§∂‡§æ‡§∏‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞‡§¶‡§æ‡§Ø‡•Ä ‡§≠‡§®‡•á ‡§Ö‡§µ‡§ø‡§ï‡§æ‡§∏‡§ï‡•ã ‡§Ö‡§π‡§Æ‡•ç ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ï‡§æ‡§∞‡§£ ‡§§‡§ø‡§®‡•à ‡§¨‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: <extra_id_0> ‡§®‡§¶‡•á‡§ñ‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç\n",
      "label:     ‡§∏‡§§‡•ç‡§§‡§æ‡§ß‡§æ‡§∞‡•Ä‡§π‡§∞‡•Ç ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡•Ä‡§°‡§æ‡§Æ‡§æ ‡§ö‡§ø‡§§‡•ç‡§§ ‡§®‡§¶‡•Å:‡§ñ‡§æ‡§â‡§®‡•á ‡§∞ ‡§∂‡§æ‡§∏‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞‡§¶‡§æ‡§Ø‡•Ä ‡§≠‡§á‡§¶‡§ø‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Ö‡§µ‡§ø‡§ï‡§æ‡§∏‡§ï‡•ã ‡§Ö‡§π‡§Æ‡•ç ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ï‡§æ‡§∞‡§£ ‡§§‡§ø‡§®‡•à ‡§¨‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§Ö‡§ò‡§ø ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•á‡§∞ ‡§ü‡§æ‡§≤‡§ü‡•Å‡§≤ ‡§™‡§æ‡§∞‡§ø‡§è‡§ï‡•ã ‡§∞‡§æ‡§ú‡§æ‡§™‡•Å‡§∞‡§§‡§∞‡•ç‡§´ ‡§¶‡•Ä‡§∞‡•ç‡§ò‡§ï‡§æ‡§≤‡•Ä‡§® ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§®‡§ø‡§ï‡§æ‡§∏ ‡§®‡§ñ‡•ã‡§ú‡§ø‡§Å‡§¶‡§æ ‡§™‡•Å‡§≤ ‡§ï‡§ø‡§®‡§æ‡§∞‡§æ‡§Æ‡§æ ‡§™‡•Å‡§®‡§É ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•ç‡§® ‡§∏‡•Å‡§∞‡•Å ‡§≠‡§è‡§ï‡•ã ‡•§\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§Ö‡§ò‡§ø ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•á‡§∞ ‡§ü‡§æ‡§≤‡§ü‡•Å‡§≤ ‡§™‡§æ‡§∞‡§ø‡§è‡§ï‡•ã ‡§∞‡§æ‡§ú‡§æ‡§™‡•Å‡§∞‡§§‡§∞‡•ç‡§´ ‡§¶‡•Ä‡§∞‡•ç‡§ò‡§ï‡§æ‡§≤‡•Ä‡§® ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§®‡§ø‡§ï‡§æ‡§∏ ‡§®‡§ñ‡•ã‡§ú‡§ø‡§Å‡§¶‡§æ ‡§™‡•Å‡§≤ ‡§ï‡§ø‡§®‡§æ‡§∞‡§æ‡§Æ‡§æ ‡§™‡•Å‡§®‡§É ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•ç‡§® ‡§∏‡•Å‡§∞‡•Å ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§®‡•ç‡§ú‡•Å‡§Æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Æ‡§π‡§Ç‡§ó‡•ã ‡§≠‡§è‡§™‡§õ‡§ø ‡§ß‡•á‡§∞‡•à‡§≤‡•á ‡§§ ‡§ï‡§ø‡§®‡•ç‡§® ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ï‡§®‡•ç‡§ú‡•Å‡§Æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Æ‡§π‡§Ç‡§ó‡•ã ‡§≠‡§è‡§™‡§õ‡§ø ‡§ß‡•á‡§∞‡•à‡§≤‡•á ‡§§ ‡§ï‡§ø‡§®‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§π‡§ø‡§≤‡•á‡§ï‡•ã ‡§Ü‡§â‡§Å‡§õ ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§≠‡§®‡•ç‡§®‡•á ‡§Ü‡§∂‡§æ ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§Ö‡§π‡§ø‡§≤‡•á‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§Ü‡§â‡§Å‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Ü‡§∂‡§æ ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç, (‡§®‡•á‡§∏) ‡§è‡§®‡§∏‡•á‡§≤‡§ï‡§æ ‡§®‡•á‡§™‡§æ‡§≤‡§¨‡§æ‡§π‡§ø‡§∞ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡§≤‡•á ‡§∞‡§π‡•á‡§ï‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§§‡§•‡§æ ‡§∏‡§æ‡§•‡•Ä‡§≠‡§æ‡§à‡§∏‡§Å‡§ó ‡§Ö‡§¨ ‡§Ö‡§ù ‡§∏‡•Å‡§≤‡§≠ ‡§¶‡§∞‡§Æ‡§æ ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç, (‡§®‡•á‡§∏) ‡§è‡§®‡§∏‡•á‡§≤‡§ï‡§æ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§¨‡§æ‡§π‡§ø‡§∞ ‡§∞‡§π‡•á‡§ï‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§§‡§•‡§æ ‡§∏‡§æ‡§•‡•Ä‡§≠‡§æ‡§à‡§∏‡§Å‡§ó ‡§Ö‡§¨ ‡§Ö‡§ù ‡§∏‡•Å‡§≤‡§≠ ‡§¶‡§∞‡§Æ‡§æ ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡§æ‡§®‡§ø‡§∏‡§ï‡•ã ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§≤‡§æ‡§à ‡§ß‡•ç‡§Ø‡§æ‡§®‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•á‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§¶‡§ø‡§∞‡§æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§∞ ‡§â‡§™‡§≠‡•ã‡§ó‡§≤‡§æ‡§à ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¨‡•á‡§≤‡§æ ‡§¨‡•á‡§≤‡§æ‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§®‡§ø‡§Ø‡§Æ‡§π‡§∞‡•Å ‡§Ü‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§Æ‡§æ‡§®‡§ø‡§∏‡§ï‡•ã ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§≤‡§æ‡§à ‡§ß‡•ç‡§Ø‡§æ‡§®‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•á‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§¶‡§ø‡§∞‡§æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§∞ ‡§â‡§™‡§≠‡•ã‡§ó‡§≤‡§æ‡§à ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¨‡•á‡§≤‡§æ ‡§¨‡•á‡§≤‡§æ‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§®‡§ø‡§Ø‡§Æ‡§π‡§∞‡•Å ‡§≤‡§ó‡§æ‡§â‡§Å‡§¶‡•à ‡§Ü‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§∏‡§≠‡§æ‡§Æ‡§æ ‡§π‡§æ‡§Æ‡•Ä ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§≤‡•á‡§ñ‡§®‡§ï‡§æ ‡§è‡§ú‡•á‡§£‡•ç‡§°‡§æ‡§Æ‡•à ‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§∏‡§≠‡§æ‡§Æ‡§æ ‡§π‡§æ‡§Æ‡•Ä ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§≤‡•á‡§ñ‡§®‡§ï‡§æ ‡§è‡§ú‡•á‡§£‡•ç‡§°‡§æ‡§Æ‡•à ‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§ ‡§π‡•Å‡§®‡•ç‡§•‡•ç‡§Ø‡•å‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§π‡§ø‡§∞‡§æ‡§¶‡•á‡§µ‡•Ä ‡§™‡•å‡§°‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§ó‡•ç‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§≠‡§æ‡§â ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï ‡§¨‡§®‡§™ ‡§™‡§ü‡§ï ‡§™‡§ü‡§ï ‡§™‡§π‡§≤ ‡§ó‡§∞‡•á ‡§™‡§®‡§ø ‡§¨‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä‡§≤‡•á ‡§Ö‡§ü‡•á‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§á‡§®‡•ç ‡•§\n",
      "Corrected: <extra_id_0> ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç:\n",
      "label:     ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§π‡§ø‡§∞‡§æ‡§¶‡•á‡§µ‡•Ä ‡§™‡•å‡§°‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§ó‡•ç‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§≠‡§æ‡§â ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï ‡§¨‡§®‡§æ‡§â‡§® ‡§™‡§ü‡§ï ‡§™‡§ü‡§ï ‡§™‡§π‡§≤ ‡§ó‡§∞‡•á ‡§™‡§®‡§ø ‡§¨‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä‡§≤‡•á ‡§Ö‡§ü‡•á‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§á‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§∏‡§Ç‡§ò ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡§∞‡§ø‡§∑‡§¶‡§Æ‡§æ ‡§Ø‡•ã ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§â‡§†‡§æ‡§â‡§® ‡§Ö‡§µ‡§∂‡•ç‡§Ø ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§§‡§∞ ‡§ö‡•Ä‡§®‡§≤‡•á ‡§≠‡§ø‡§ü‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡§ø‡§¶‡§ø‡§®‡•á ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§∏‡§Ç‡§ò ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡§∞‡§ø‡§∑‡§¶‡§Æ‡§æ ‡§Ø‡•ã ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§â‡§†‡§æ‡§â‡§® ‡§Ö‡§µ‡§∂‡•ç‡§Ø ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§§‡§∞ ‡§ö‡•Ä‡§®‡§≤‡•á ‡§≠‡§ø‡§ü‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡§ø‡§¶‡§ø‡§®‡•á ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§ø‡§∞‡•ç‡§Æ‡§≤‡§æ ‡§™‡§®‡•ç‡§§‡§ï‡§æ ‡§¨‡§≤‡§æ‡§§‡•ç‡§ï‡§æ‡§∞‡•Ä‚Äì‡§π‡§§‡•ç‡§Ø‡§æ‡§∞‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§≤‡§æ‡§à ‡§Ø‡§∏‡•à ‡§∏‡•á‡§∞‡•ã‡§´‡•á‡§∞‡§æ‡§Æ‡§æ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•Ä‡§§ ‡§ó‡§∞‡•á‡§™‡§®‡§ø ‡§Ö‡§™‡§∞‡§æ‡§ß‡•Ä ‡§≠‡•á‡§ü‡§ø‡§®‡•á ‡§Ü‡§Æ‡§¨‡•Å‡§ù‡§æ‡§á ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0>‚Äì‡§π‡§§‡•ç‡§Ø‡§æ‡§∞‡§æ\n",
      "label:     ‡§®‡§ø‡§∞‡•ç‡§Æ‡§≤‡§æ ‡§™‡§®‡•ç‡§§‡§ï‡§æ ‡§¨‡§≤‡§æ‡§§‡•ç‡§ï‡§æ‡§∞‡•Ä‚Äì‡§π‡§§‡•ç‡§Ø‡§æ‡§∞‡§æ ‡§ñ‡•ã‡§ú‡•ç‡§®‡•á ‡§µ‡§ø‡§∑‡§Ø‡§≤‡§æ‡§à ‡§Ø‡§∏‡•à ‡§∏‡•á‡§∞‡•ã‡§´‡•á‡§∞‡§æ‡§Æ‡§æ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•Ä‡§§ ‡§ó‡§∞‡•á‡§™‡§®‡§ø ‡§Ö‡§™‡§∞‡§æ‡§ß‡•Ä ‡§≠‡•á‡§ü‡§ø‡§®‡•á ‡§Ü‡§Æ‡§¨‡•Å‡§ù‡§æ‡§á ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§≠‡§æ‡§∑‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§™‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•á‡§≤‡•á ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ‡§≤‡•á ‡§ö‡§Ø‡§® ‡§®‡§ó‡§∞‡•á ‡§™‡•Å‡§®‡§É ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§∏‡§π‡§≠‡§æ‡§ó‡•Ä ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ?\n",
      "Corrected: <extra_id_0> ‡§™‡§æ‡§∏\n",
      "label:     ‡§≠‡§æ‡§∑‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§™‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•á‡§≤‡•á ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ‡§≤‡•á ‡§ö‡§Ø‡§® ‡§®‡§ó‡§∞‡•á ‡§™‡•Å‡§®‡§É ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§∏‡§π‡§≠‡§æ‡§ó‡•Ä ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§æ‡§ó‡§æ‡§µ‡§≤‡•ç‡§∞‡•ç‡§°‡§∏‡§Å‡§ó ‡§•‡•ç‡§∞‡§ø‡§∏‡•ç‡§ü‡§æ‡§∞‡§≤‡•á ‡•ß‚Äì‡•ß ‡§ó‡•ã‡§≤‡§ï‡•ã ‡§¨‡§∞‡§æ‡§¨‡§∞‡•Ä ‡§ñ‡•á‡§≤‡•ç‡§¶‡§æ ‡§™‡§®‡§ø ‡§Æ‡§æ‡§∞‡•ç‡§ü‡§ø‡§®‡•ç‡§∏‡§≤‡•á ‡§®‡•à ‡§è‡§ï ‡§ó‡•ã‡§≤ ‡§´‡§∞‡•ç‡§ï‡§∞ ‡§π‡§æ‡§∞‡§¨‡§æ‡§ü ‡§ú‡•ã‡§ó‡§æ‡§è‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§®‡§æ‡§ó‡§æ‡§µ‡§≤‡•ç‡§∞‡•ç‡§°‡§∏‡§Å‡§ó ‡§•‡•ç‡§∞‡§ø‡§∏‡•ç‡§ü‡§æ‡§∞‡§≤‡•á ‡•ß‚Äì‡•ß ‡§ó‡•ã‡§≤‡§ï‡•ã ‡§¨‡§∞‡§æ‡§¨‡§∞‡•Ä ‡§ñ‡•á‡§≤‡•ç‡§¶‡§æ ‡§™‡§®‡§ø ‡§Æ‡§æ‡§∞‡•ç‡§ü‡§ø‡§®‡•ç‡§∏‡§≤‡•á ‡§®‡•à ‡§è‡§ï ‡§ó‡•ã‡§≤ ‡§´‡§∞‡•ç‡§ï‡§æ‡§è‡§∞ ‡§π‡§æ‡§∞‡§¨‡§æ‡§ü ‡§ú‡•ã‡§ó‡§æ‡§è‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡•Å‡§≤‡•Å‡§ï ‡§Ö‡§π‡§ø‡§≤‡•á ‡§è‡§ï‡§¶‡§Æ‡•à ‡§∏‡§Ç‡§ó‡•Ä‡§® ‡§ò‡§°‡•Ä‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§∞ ‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‚Äì‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‡§ï‡•ã ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡§õ ‡•§\n",
      "label:     ‡§Æ‡•Å‡§≤‡•Å‡§ï ‡§Ö‡§π‡§ø‡§≤‡•á ‡§è‡§ï‡§¶‡§Æ‡•à ‡§∏‡§Ç‡§ó‡•Ä‡§® ‡§ò‡§°‡•Ä‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡§∞ ‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‚Äì‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‡§ï‡•ã ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§∂‡§æ‡§≤‡•Ä ‡§Æ‡§æ‡§®‡§ø‡§®‡•á ‡§Ø‡•Å‡§µ‡§æ ‡§∞ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä ‡§∏‡§Ç‡§ó‡§†‡§®‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§è‡§Æ‡§æ‡§≤‡•á‡§≤‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§ï‡•ã ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ ‡§≤‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§∏‡§¨‡•à‡§≠‡§®‡•ç‡§¶‡§æ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§∂‡§æ‡§≤‡•Ä ‡§Æ‡§æ‡§®‡§ø‡§®‡•á ‡§Ø‡•Å‡§µ‡§æ ‡§∞ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä ‡§∏‡§Ç‡§ó‡§†‡§®‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§è‡§Æ‡§æ‡§≤‡•á‡§≤‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§ï‡•ã ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ ‡§≤‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§¨‡§≤‡§ø‡§ô‡§Æ‡§æ ‡§∏‡•Å‡§∂‡§® ‡§™‡•ã‡§ñ‡§∞‡§æ‡§ï‡§æ ‡§≠‡§æ‡§∞‡•Ä ‡§∞ ‡§™‡§â‡§≤ ‡§ï‡§ò‡§≤‡§ø‡§®‡§≤‡•á ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞‡§ï‡§æ ‡§∏‡§®‡•ç‡§¶‡•Ä‡§™ ‡§≤‡§æ‡§Æ‡§ø‡§õ‡§æ‡§®‡•á ‡§∏‡§Æ‡§æ‡§® ‡•´ ‡§µ‡§ø‡§ï‡•á‡§ü ‡§≤‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§¨‡§≤‡§ø‡§ô‡§Æ‡§æ ‡§™‡•ã‡§ñ‡§∞‡§æ‡§ï‡§æ ‡§∏‡•Å‡§∂‡§® ‡§≠‡§æ‡§∞‡•Ä ‡§∞ ‡§™‡§â‡§≤ ‡§ï‡§ò‡§≤‡§ø‡§®‡§≤‡•á ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞‡§ï‡§æ ‡§∏‡§®‡•ç‡§¶‡•Ä‡§™ ‡§≤‡§æ‡§Æ‡§ø‡§õ‡§æ‡§®‡•á ‡§∏‡§Æ‡§æ‡§® ‡•´ ‡§µ‡§ø‡§ï‡•á‡§ü ‡§≤‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§ò‡§ü‡§®‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑‡§¶‡§∞‡•ç‡§∂‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡•Å‡§Æ‡§æ‡§∞‡§ï‡§æ‡§∏‡§æ‡§•‡•Ä ‡§ú‡§Ø‡§ï‡§æ‡§®‡•ç‡§§ ‡§â‡§®‡•Ä ‡§®‡§Æ‡•ç‡§∞, ‡§¨‡§æ‡§Å‡§°‡•Ä‡§ö‡•Å‡§Å‡§°‡•Ä ‡§ñ‡§æ‡§®‡•á ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§®‡§¨‡•ã‡§≤‡•ç‡§®‡•á ‡§ñ‡§æ‡§≤‡§ï‡•ã ‡§≠‡§è‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ò‡§ü‡§®‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑‡§¶‡§∞‡•ç‡§∂‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡•Å‡§Æ‡§æ‡§∞‡§ï‡§æ‡§∏‡§æ‡§•‡•Ä ‡§ú‡§Ø‡§ï‡§æ‡§®‡•ç‡§§ ‡§â‡§®‡•Ä ‡§®‡§Æ‡•ç‡§∞, ‡§¨‡§æ‡§Å‡§°‡•Ä‡§ö‡•Å‡§Å‡§°‡•Ä ‡§ñ‡§æ‡§®‡•á ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§®‡§¨‡•ã‡§≤‡•ç‡§®‡•á ‡§ñ‡§æ‡§≤‡§ï‡•ã ‡§≠‡§è‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§ú‡§ø‡§™ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä ‡•© ‡§π‡§ú‡§æ‡§∞‡§≠‡§®‡•ç‡§¶‡§æ ‡§§‡§≤‡§ï‡•ã ‡§≠‡§æ‡§°‡§æ‡§Æ‡§æ ‡§ú‡§æ‡§®‡•à ‡§Æ‡§æ‡§®‡•ç‡§® ‡•§\n",
      "Corrected: <extra_id_0> ‡•§\n",
      "label:     ‡§ú‡§ø‡§™ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä ‡•© ‡§π‡§ú‡§æ‡§∞‡§≠‡§®‡•ç‡§¶‡§æ ‡§§‡§≤‡§ï‡•ã ‡§≠‡§æ‡§°‡§æ‡§Æ‡§æ ‡§ú‡§æ‡§®‡•à ‡§Æ‡§æ‡§®‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def correct_batch(texts, batch_size=8):\n",
    "    \"\"\"\n",
    "    Correct grammar for multiple sentences\n",
    "    \"\"\"\n",
    "    corrected_texts = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Add prefix to each text\n",
    "        input_texts = [f\"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: {text}\" for text in batch_texts]\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            input_texts,\n",
    "            return_tensors = \"pt\",\n",
    "            truncation = True,\n",
    "            padding=True\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generate correction\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs.input_ids,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                max_length=64,\n",
    "                num_beams=5,\n",
    "                repetition_penalty=2.5\n",
    "            )\n",
    "            \n",
    "        # Decode batch\n",
    "        batch_corrected = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        corrected_texts.extend(batch_corrected)\n",
    "        \n",
    "    return corrected_texts\n",
    "        \n",
    "    \n",
    "test_sentences = small_dataset[\"train\"][\"incorrect_sentence\"][:]\n",
    "labels = small_dataset[\"train\"][\"correct_sentence\"][:]\n",
    "corrected_sentences = correct_batch(test_sentences)\n",
    "for orig, corr, lab in zip(test_sentences, corrected_sentences, labels):\n",
    "    print(f\"Original:  {orig}\")\n",
    "    print(f\"Corrected: {corr}\")\n",
    "    print(f\"label:     {lab}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1593f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0> ‡•§...' | Ref: '‡§ó‡•ã‡§™‡§®‡•Ä‡§Ø‡§§‡§æ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§â‡§ö‡•ç‡§ö ‡§∏‡§§‡§∞‡•ç‡§ï‡§§‡§æ ‡§Ö‡§™‡§®‡§æ‡§â‡§® ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§∞ ‡§Æ‡§æ‡§§...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.8975998136046814,\n",
       " 'chrf': 2.607411569860353,\n",
       " 'correction_accuracy': np.float64(0.0),\n",
       " 'gleu': 0.013655577945223627}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics((corrected_sentences, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee918b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
