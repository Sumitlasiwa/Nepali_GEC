{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3025d85f",
   "metadata": {},
   "source": [
    "Lets see whether simple mt5 model overfits in small data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0b854e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSeq2SeqLM,\n",
    "                          Seq2SeqTrainer,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          DataCollatorForSeq2Seq\n",
    "                          )\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "# Set all seeds for reproducibility\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "torch.manual_seed(100)\n",
    "torch.cuda.manual_seed_all(100)\n",
    "# Load aryal's dataset from hf\n",
    "ds = load_dataset(\"sumitaryal/nepali_grammatical_error_correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "472e6739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 7723971\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 406525\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "14a99e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 11250\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['incorrect_sentence', 'correct_sentence'],\n",
       "        num_rows: 1250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select randomly few samples from train \n",
    "# split further into train and valid dataset\n",
    "small_dataset = ds[\"train\"].shuffle(seed=42).select(range(12500))\n",
    "small_dataset = small_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "small_dataset[\"valid\"] = small_dataset[\"test\"] # Rename the split in the DatasetDict\n",
    "del small_dataset[\"test\"]\n",
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "39c3090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5ebb360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11250/11250 [00:05<00:00, 2054.96 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1250/1250 [00:00<00:00, 2456.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "prefix = \"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡§ö‡•ç‡§Ø‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç: \"\n",
    "\n",
    "def preprocess(batch):\n",
    "    \n",
    "    inputs = [prefix + inp for inp in batch[\"incorrect_sentence\"]]\n",
    "\n",
    "    # tokenize input (incorrect)\n",
    "    input_encodings = tokenizer(\n",
    "        inputs, \n",
    "        max_length=128,\n",
    "        truncation=True \n",
    "    )\n",
    "    # tokenize target (correct)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(\n",
    "            batch[\"correct_sentence\"], \n",
    "            max_length=128,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    # set labels for seq2seq training                           # for seq2deq models, the \"labels\" are the token IDs of the target sequence\n",
    "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]   \n",
    "\n",
    "    return input_encodings\n",
    "\n",
    "dataset_encoded = small_dataset.map(preprocess, batched=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e47d6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch model expects in tensor format\n",
    "dataset_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "abf332a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§...' | Ref: '‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§...' | Match: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 100.00000000000004,\n",
       " 'chrf': 100.0,\n",
       " 'correction_accuracy': np.float64(1.0),\n",
       " 'gleu': 1.0}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def tokenize_nepali(text):\n",
    "    \"\"\"Tokenizes Nepali text: splits on spaces and removes punctuation.\"\"\"\n",
    "    # Remove punctuation commonly used in Nepali\n",
    "    text = re.sub(r\"[‡•§,!?]\", \"\", text)\n",
    "    return text.strip().split()\n",
    "\n",
    "def gleu_sentence(reference, prediction, max_n=4):\n",
    "    \"\"\"\n",
    "    Compute sentence-level GEC-GLEU.\n",
    "    Returns a score between 0 and 1.\n",
    "    \"\"\"\n",
    "    ref_tokens = tokenize_nepali(reference)\n",
    "    hyp_tokens = tokenize_nepali(prediction)\n",
    "    \n",
    "    # Adjust max_n for short sentences\n",
    "    max_n = min(max_n, len(ref_tokens), len(hyp_tokens))\n",
    "    if max_n == 0:\n",
    "        return 0.0  # empty sentence\n",
    "    \n",
    "    scores = []\n",
    "    for n in range(1, max_n+1):\n",
    "        ref_ngrams = Counter([tuple(ref_tokens[i:i+n]) for i in range(len(ref_tokens)-n+1)])\n",
    "        hyp_ngrams = Counter([tuple(hyp_tokens[i:i+n]) for i in range(len(hyp_tokens)-n+1)])\n",
    "        overlap = sum((ref_ngrams & hyp_ngrams).values())\n",
    "        precision = overlap / max(1, sum(hyp_ngrams.values()))\n",
    "        recall = overlap / max(1, sum(ref_ngrams.values()))\n",
    "        scores.append(min(precision, recall))\n",
    "    return sum(scores) / max_n\n",
    "\n",
    "def corpus_gec_gleu(references, predictions):\n",
    "    \"\"\"\n",
    "    Compute corpus-level GEC-GLEU.\n",
    "    `references` can be a list of strings or a list of single-item lists.\n",
    "    \"\"\"\n",
    "    # Flatten single-reference lists\n",
    "    refs_flat = [r[0] if isinstance(r, list) else r for r in references]\n",
    "    \n",
    "    scores = [gleu_sentence(r, p) for r, p in zip(refs_flat, predictions)]\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# Load metrics once\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute BLEU, chrF, Correction Accuracy, and BERTScore for Nepali GEC.\n",
    "    Handles both token IDs and plain text predictions.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # --- Handle tuple outputs (e.g., logits + labels) ---\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # --- If preds/labels are lists of strings, skip decoding ---\n",
    "    if isinstance(predictions[0], str) and isinstance(labels[0], str):\n",
    "        preds_clean = [p.strip() for p in predictions]\n",
    "        refs_clean = [r.strip() for r in labels]\n",
    "    else:\n",
    "        # Convert to numpy arrays\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Handle logits (vocab dimension)\n",
    "        if predictions.ndim == 3:\n",
    "            predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "        # Replace -100 with pad_token_id\n",
    "        predictions = np.where(predictions == -100, tokenizer.pad_token_id, predictions)\n",
    "        labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "        # Decode\n",
    "        preds = tokenizer.batch_decode(predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        refs = tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        preds_clean = [p.strip() for p in preds]\n",
    "        refs_clean = [r.strip() for r in refs]\n",
    "\n",
    "    # --- Format for metrics ---\n",
    "    references = [[r] for r in refs_clean]\n",
    "    metrics = {}\n",
    "\n",
    "    # --- BLEU ---\n",
    "    try:\n",
    "        non_empty_indices = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "        if non_empty_indices:\n",
    "            preds_bleu = [preds_clean[i] for i in non_empty_indices]\n",
    "            refs_bleu = [[refs_clean[i]] for i in non_empty_indices]\n",
    "            bleu_result = bleu_metric.compute(predictions=preds_bleu, references=refs_bleu)\n",
    "            metrics[\"bleu\"] = bleu_result[\"score\"]\n",
    "        else:\n",
    "            metrics[\"bleu\"] = 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU computation failed: {e}\")\n",
    "        metrics[\"bleu\"] = 0.0\n",
    "\n",
    "    # --- chrF ---\n",
    "    try:\n",
    "        chrf_result = chrf_metric.compute(predictions=preds_clean, references=refs_clean)\n",
    "        metrics[\"chrf\"] = chrf_result[\"score\"]\n",
    "    except Exception as e:\n",
    "        print(f\"chrF computation failed: {e}\")\n",
    "        metrics[\"chrf\"] = 0.0\n",
    "\n",
    "    # --- Correction Accuracy ---\n",
    "    try:\n",
    "        exact_matches = np.mean([p == r for p, r in zip(preds_clean, refs_clean)])\n",
    "        metrics[\"correction_accuracy\"] = exact_matches\n",
    "    except Exception as e:\n",
    "        print(f\"Correction accuracy computation failed: {e}\")\n",
    "        metrics[\"correction_accuracy\"] = 0.0\n",
    "\n",
    "    # # --- BERTScore ---\n",
    "    # try:\n",
    "    #     non_empty_indices_bert = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "    #     if non_empty_indices_bert:\n",
    "    #         preds_bert = [preds_clean[i] for i in non_empty_indices_bert]\n",
    "    #         refs_bert = [refs_clean[i] for i in non_empty_indices_bert]\n",
    "    #         bertscore_result = bertscore_metric.compute(\n",
    "    #             predictions=preds_bert,\n",
    "    #             references=refs_bert,\n",
    "    #             lang=\"ne\",\n",
    "    #             model_type=\"microsoft/mdeberta-v3-base\"\n",
    "    #         )\n",
    "    #         metrics[\"bertscore_f1\"] = float(np.mean(bertscore_result[\"f1\"]))\n",
    "    #     else:\n",
    "    #         metrics[\"bertscore_f1\"] = 0.0\n",
    "    # except Exception as e:\n",
    "    #     print(f\"BERTScore computation failed: {e}\")\n",
    "    #     metrics[\"bertscore_f1\"] = 0.0\n",
    "        \n",
    "    # --- GLEU (SacreBLEU) ---\n",
    "    try:\n",
    "\n",
    "\n",
    "        gleu_score = corpus_gec_gleu(refs_clean, preds_clean)\n",
    "\n",
    "\n",
    "        metrics[\"gleu\"] = gleu_score\n",
    "    except Exception as e:\n",
    "        print(\"GLEU failed:\", e)\n",
    "        metrics[\"gleu\"] = 0.0\n",
    "\n",
    "    # --- Print one sample for sanity ---\n",
    "    if len(preds_clean) > 0:\n",
    "        print(f\"üîç Sample - Pred: '{preds_clean[0][:50]}...' | Ref: '{refs_clean[0][:50]}...' | Match: {preds_clean[0] == refs_clean[0]}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "preds = [\"‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§\", \"‡§Æ ‡§∏‡•ç‡§ï‡•Å‡§≤ ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\", \"‡§Æ ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\"]\n",
    "refs  = [\"‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§\", \"‡§Æ ‡§∏‡•ç‡§ï‡•Å‡§≤ ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\", \"‡§Æ ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\"]\n",
    "compute_metrics((preds, refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f2519bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "37886e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True,\n",
    "                                        llm_int8_threshold=6.0,  \n",
    "                                        llm_int8_has_fp16_weight=False )\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id,\n",
    "                                              quantization_config=quantization_config,\n",
    "                                            #   torch_dtype=torch.float16, # disable if quantization used\n",
    "                                              device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dce0fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 301,946,240 || trainable%: 0.5860\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "# from peft import unload\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"k\", \"v\", \"o\", \"wi\", \"wo\"],\n",
    "    lora_dropout=0.05, # disable for overfit test\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "# model.gradient_checkpointing_enable()\n",
    "# model = unload(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "# model.config.use_cache = False  # Required for gradient checkpointing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f600bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, \n",
    "    # model=model,\n",
    "    pad_to_multiple_of=8,  # Optional: for better performance\n",
    "    return_tensors=\"pt\", \n",
    "    padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1e052827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà</td></tr><tr><td>eval/chrf</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà</td></tr><tr><td>eval/correction_accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/gleu</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/model_preparation_time</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñà</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bleu</td><td>9.83785</td></tr><tr><td>eval/chrf</td><td>44.45996</td></tr><tr><td>eval/correction_accuracy</td><td>0</td></tr><tr><td>eval/gleu</td><td>0.12065</td></tr><tr><td>eval/loss</td><td>1.41266</td></tr><tr><td>eval/model_preparation_time</td><td>0.0036</td></tr><tr><td>eval/runtime</td><td>239.1088</td></tr><tr><td>eval/samples_per_second</td><td>1.046</td></tr><tr><td>eval/steps_per_second</td><td>0.067</td></tr><tr><td>total_flos</td><td>317706831396864.0</td></tr><tr><td>+9</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mt5-nepali</strong> at: <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/bsas9ydj' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/bsas9ydj</a><br> View project at: <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251117_144829-bsas9ydj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\notebooks\\wandb\\run-20251117_152331-p3s0knsr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/p3s0knsr' target=\"_blank\">mt5-nepali</a></strong> to <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/p3s0knsr' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/p3s0knsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback, TrainerCallback\n",
    "from math import ceil\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandb.finish()\n",
    "wandb.init(project=\"nepali-grammar-correction\", name=\"mt5-nepali\")\n",
    "run_id = wandb.run.id\n",
    "\n",
    "batch_size = 32\n",
    "num_train_epochs = 5\n",
    "gradient_accumulation_steps = 2\n",
    "learning_rate = 3e-3\n",
    "weight_decay = 0.01\n",
    "lr_scheduler_type = \"linear\"\n",
    "steps_per_epoch = ceil(len(dataset_encoded[\"train\"]) // (batch_size * gradient_accumulation_steps))    # no. of steps per epoch # log once per epoch\n",
    "# logging_steps = max(1, steps_per_epoch // 20)                                                     # Log 20 times per epoch\n",
    "eval_steps = max(1, steps_per_epoch) // 2           # Log 2 times per epoch\n",
    "num_training_steps = steps_per_epoch * num_train_epochs\n",
    "warmup_steps = int(0.05 * num_training_steps)\n",
    "\n",
    "\n",
    "model_name = f\"{model_id}-finetuned-gec\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(f\"../outputs/checkpoints/{model_name}\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/best_model\", exist_ok=True)\n",
    "os.makedirs(\"../outputs/logs\", exist_ok=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(output_dir=f\"../outputs/checkpoints/{model_name}\",\n",
    "                                         num_train_epochs=num_train_epochs,\n",
    "\n",
    "                                         # Memory Optimization:\n",
    "                                         per_device_train_batch_size=batch_size,\n",
    "                                         per_device_eval_batch_size=batch_size,\n",
    "                                         gradient_accumulation_steps=gradient_accumulation_steps,  # Simulate larger batch size eg: 8 * 2 = 16\n",
    "                                         fp16=False,                                                # Use mixed precision if GPU supports it\n",
    "                                         dataloader_pin_memory=True,                        # ‚úÖ Faster data loading\n",
    "                                         dataloader_num_workers=4,                          # ‚úÖ Parallel data loading\n",
    "\n",
    "                                         gradient_checkpointing=False,                      # ‚úÖ Disable for speed\n",
    "                                         \n",
    "                                         # Logging & Saving:\n",
    "                                         logging_dir=\"../outputs/logs\",\n",
    "                                         logging_steps=1,    # log the training loss and metrics every X steps\n",
    "                                         eval_strategy=\"epoch\",          # performs evaluation per epoch\n",
    "                                        #  eval_steps=eval_steps,\n",
    "                                         save_strategy=\"epoch\",          # saves model checkpoint per epoch\n",
    "                                        #  save_steps=230000,\n",
    "                                         save_total_limit=2,             # keep last 2 checkpoints for safety\n",
    "                                         overwrite_output_dir=True,      # Overwrite previous runs\n",
    "\n",
    "                                         # Best Model saving:\n",
    "                                         load_best_model_at_end=True,        # Load the best model at the end\n",
    "                                         metric_for_best_model=\"eval_loss\",   # Use eval_loss to determine best model\n",
    "                                         greater_is_better=False,            # Lower eval_loss is better\n",
    "\n",
    "                                         # performance\n",
    "                                         warmup_steps=warmup_steps,             # Gradually increases LR at start\n",
    "                                         learning_rate=learning_rate,\n",
    "                                         weight_decay=weight_decay,             # L2 regularization\n",
    "                                         lr_scheduler_type=lr_scheduler_type,\n",
    "                                         max_grad_norm=1.0,                     # Prevent exploding gradients\n",
    "                                         optim=\"paged_adamw_8bit\",              # Better optimizer for quantized models\n",
    "\n",
    "\n",
    "                                         # Seq2seq specific:\n",
    "                                         predict_with_generate=True,    # essential for seq2seq , If not set then metrics will be computed on meaningless logits\n",
    "                                         generation_max_length=128,      # Max output length\n",
    "                                         generation_num_beams=1,        # 1=greedy, 4=beam search (slower but better)\n",
    "\n",
    "                                         report_to=\"wandb\",          # This enables automatic logging\n",
    "                                         run_name=\"mt5-nepali\",\n",
    "                                         push_to_hub=False,                       # save the model to HF\n",
    "                                         seed=42,\n",
    "                                         data_seed=42,\n",
    "                                         )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bc006b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"valid\"],  # same dataset for overfitting here\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=seq2seq_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "               EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "      \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a71b3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running pre-training safety checks...\n",
      "Model device: cuda:0\n",
      "Train dataset size: 11250\n",
      "Eval dataset size: 1250\n",
      " Data loading works\n",
      " Performing evaluation check...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0> ‡•§...' | Ref: '‡§Ø‡§§‡§æ‡§ï‡§æ ‡§¶‡§∂‡§ï‡§π‡§∞‡•Ç‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§ú‡§®‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§®‡§Æ‡§æ ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§ï‡§Æ...' | Match: False\n",
      " Evaluation successful\n",
      "Initial metrics: {'eval_loss': 14.842653274536133, 'eval_model_preparation_time': 0.0032, 'eval_bleu': 0.2091458306127584, 'eval_chrf': 1.1538016829513393, 'eval_correction_accuracy': 0.0, 'eval_gleu': 0.0062149767114550395, 'eval_runtime': 79.8617, 'eval_samples_per_second': 15.652, 'eval_steps_per_second': 0.501}\n",
      "\n",
      "============================================================\n",
      "‚úÖ All checks passed! Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 10.31 GiB is allocated by PyTorch, and 1007.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[174]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ All checks passed! Starting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Training complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\transformers\\trainer.py:2328\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\transformers\\trainer.py:2672\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2665\u001b[39m context = (\n\u001b[32m   2666\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2667\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2668\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2670\u001b[39m )\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2672\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2674\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2675\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2676\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2677\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2678\u001b[39m ):\n\u001b[32m   2679\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2680\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\transformers\\trainer.py:4060\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   4057\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   4058\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4060\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4062\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\accelerate\\accelerator.py:2734\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2732\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2734\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 10.31 GiB is allocated by PyTorch, and 1007.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Complete safety check\n",
    "def safe_training_check(trainer):\n",
    "    \"\"\"Comprehensive pre-training safety check\"\"\"\n",
    "    print(\" Running pre-training safety checks...\")\n",
    "\n",
    "    # 1. Check model is on correct device\n",
    "    print(f\"Model device: {next(trainer.model.parameters()).device}\")\n",
    "\n",
    "    # 2. Check dataset sizes\n",
    "    print(f\"Train dataset size: {len(trainer.train_dataset)}\")\n",
    "    print(f\"Eval dataset size: {len(trainer.eval_dataset)}\")\n",
    "\n",
    "    # 3. Test data loading\n",
    "    try:\n",
    "        sample_batch = next(iter(trainer.get_train_dataloader()))\n",
    "        print(\" Data loading works\")\n",
    "        # print(f\"Batch keys: {sample_batch.keys()}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Data loading failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # 4. Test evaluation\n",
    "    try:\n",
    "        trainer.model.eval()    # Set to evaluation mode\n",
    "        print(\" Performing evaluation check...\")\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(\" Evaluation successful\")\n",
    "        print(f\"Initial metrics: {eval_results}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\" Evaluation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "if safe_training_check(trainer):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ All checks passed! Starting training...\")\n",
    "    print(\"=\"*60)\n",
    "    trainer.train()\n",
    "    print(\"‚úÖ Training complete!\")\n",
    "\n",
    "else:\n",
    "    print(\" Fix issues before training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff205b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# del model       # or del comet_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d0507",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a032119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[32m     29\u001b[39m test_sentence = \u001b[33m\"\u001b[39m\u001b[33m‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ‡•á \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m corrected = \u001b[43mcorrect_grammar_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCorrected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mcorrect_grammar_simple\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      3\u001b[39m input_text = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Tokenize\u001b[39;00m\n\u001b[32m      6\u001b[39m inputs = tokenizer(\n\u001b[32m      7\u001b[39m     input_text,\n\u001b[32m      8\u001b[39m     return_tensors = \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     truncation = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     10\u001b[39m     padding=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m ).to(\u001b[43mdevice\u001b[49m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Generate correction\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "def correct_grammar_simple(text):\n",
    "    # Add task prefix (use the same format as during training)\n",
    "    input_text = f\"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: {text}\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors = \"pt\",\n",
    "        truncation = True,\n",
    "        padding=False\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate correction\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=128,\n",
    "            # num_beams=5,\n",
    "            # repetition_penalty=2.5,\n",
    "            # length_penalty=1.0,\n",
    "            # temperature=0.8\n",
    "        )\n",
    "        \n",
    "    # Decode output\n",
    "    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "\n",
    "# Test\n",
    "test_sentence = \"‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ‡•á \"\n",
    "corrected = correct_grammar_simple(test_sentence)\n",
    "print(f\"Original: {test_sentence}\")\n",
    "print(f\"Corrected: {corrected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45e1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ‡§ñ‡§æ‡§®‡§™‡§ø‡§® ‡§π‡•Å‡§®‡•ç‡§• ‡•§\n",
      "Corrected: ‡§ñ‡§æ‡§®‡§™‡§ø‡§® ‡§π‡•Å‡§®‡•ç‡§•‡•ç‡§Ø‡•ã ‡•§\n",
      "label:     ‡§ñ‡§æ‡§®‡§™‡§ø‡§® ‡§π‡•Å‡§®‡•ç‡§•‡•ç‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§Ü‡§´‡•ç‡§®‡•à ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§Æ‡§æ ‡§ê‡§§‡§ø‡§π‡§æ‡§∏‡§ø‡§ï ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§ú‡§æ‡§∞‡•Ä ‡§ó‡§∞‡•ç‡§¶‡•à ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§ï‡•ã ‡§∏‡§´‡§≤ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§∞ ‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞‡•ç‡§Ø‡§§‡§æ‡§ï‡•ã ‡§¶‡§æ‡§Ø‡§∞‡§æ‡§≤‡§æ‡§à ‡§´‡§∞‡§æ‡§ï‡§ø‡§≤‡•ã ‡§¨‡§®‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§Æ ‡§ö‡•Å‡§®‡•å‡§§‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£ ‡§•‡§ø‡§è‡§® ‡•§\n",
      "Corrected: ‡§Ü‡§´‡•ç‡§®‡•à ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§Æ‡§æ ‡§ê‡§§‡§ø‡§π‡§æ‡§∏‡§ø‡§ï ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§ú‡§æ‡§∞‡•Ä ‡§ó‡§∞‡•ç‡§¶‡•à ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§ï‡•ã ‡§∏‡§´‡§≤ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§∞ ‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞‡•ç‡§Ø‡§§‡§æ‡§ï‡•ã ‡§¶‡§æ‡§Ø‡§∞‡§æ‡§≤‡§æ‡§à ‡§´‡§∞‡§æ‡§ï‡§ø‡§≤‡•ã ‡§¨‡§®‡§æ‡§â‡§®‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§Æ ‡§ö‡•Å‡§®‡•å‡§§‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£ ‡§•‡§ø‡§è‡§® ‡•§\n",
      "label:     ‡§Ü‡§´‡•ç‡§®‡•à ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§Æ‡§æ ‡§ê‡§§‡§ø‡§π‡§æ‡§∏‡§ø‡§ï ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§ú‡§æ‡§∞‡•Ä ‡§ó‡§∞‡•ç‡§¶‡•à ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§ï‡•ã ‡§∏‡§´‡§≤ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§∞ ‡§∏‡§∞‡•ç‡§µ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞‡•ç‡§Ø‡§§‡§æ‡§ï‡•ã ‡§¶‡§æ‡§Ø‡§∞‡§æ‡§≤‡§æ‡§à ‡§´‡§∞‡§æ‡§ï‡§ø‡§≤‡•ã ‡§¨‡§®‡§æ‡§â‡§®‡•á ‡§ï‡§æ‡§Æ ‡§ï‡§Æ ‡§ö‡•Å‡§®‡•å‡§§‡•Ä‡§™‡•Ç‡§∞‡•ç‡§£ ‡§•‡§ø‡§è‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§®‡§Ø‡§æ‡§Å ‡§π‡§≤ ‡§®‡•à ‡§¨‡§®‡§õ ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§®‡§Ø‡§æ‡§Å ‡§π‡§≤ ‡§®‡•à ‡§¨‡§®‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "label:     ‡§Ø‡§∏‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§®‡§Ø‡§æ‡§Å ‡§π‡§≤ ‡§®‡•à ‡§¨‡§®‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§ó‡•ã‡§≤ ‡§ó‡§∞‡•ç‡§®‡•á ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§¨‡§®‡•ç‡§≠ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§Æ‡§π‡§∏‡•Å‡§∏ ‡§≠‡•à‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ?\n",
      "Corrected: ‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§ó‡•ã‡§≤ ‡§ó‡§∞‡•ç‡§®‡•á ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§¨‡§®‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§ï‡§∏‡•ç‡§§‡•ã ‡§Æ‡§π‡§∏‡•Å‡§∏ ‡§≠‡•à‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ?\n",
      "label:     ‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§ó‡•ã‡§≤ ‡§ó‡§∞‡•ç‡§®‡•á ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§¨‡§®‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§ï‡§∏‡•ç‡§§‡•ã ‡§Æ‡§π‡§∏‡•Å‡§∏ ‡§≠‡•à‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ?\n",
      "---\n",
      "Original:  ‡§∏‡§∂‡§∏‡•ç‡§§‡•ç‡§∞ ‡§¶‡•ç‡§µ‡§®‡•ç‡§¶‡•ç‡§µ ‡§∞ ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§®‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§Ö‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ö‡•ã‡§ü‡§≤‡§æ‡§à ‡§Æ‡§≤‡§Æ‡§™‡§ü‡•ç‡§ü‡•Ä ‡§≤‡§ó‡§æ‡•á ‡§∏‡•Å‡§µ‡§ø‡§ö‡§æ‡§∞‡§≤‡•á ‡§Ö‡§¨ ‡§™‡•ç‡§∞‡§∂‡•ç‡§∞‡§Ø ‡§™‡§æ‡§â‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§¨‡§¢‡•ç‡§¶‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§∏‡§∂‡§∏‡•ç‡§§‡•ç‡§∞ ‡§¶‡•ç‡§µ‡§®‡•ç‡§¶‡•ç‡§µ ‡§∞ ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§®‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§Ö‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ö‡•ã‡§ü‡§≤‡§æ‡§à ‡§Æ‡§≤‡§Æ‡§™‡§ü‡•ç‡§ü‡•Ä ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡•Å‡§µ‡§ø‡§ö‡§æ‡§∞‡§≤‡•á ‡§Ö‡§¨ ‡§™‡•ç‡§∞‡§∂‡•ç‡§∞‡§Ø ‡§™‡§æ‡§â‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§¨‡§¢‡•ç‡§¶‡•ã ‡§õ ‡•§\n",
      "label:     ‡§∏‡§∂‡§∏‡•ç‡§§‡•ç‡§∞ ‡§¶‡•ç‡§µ‡§®‡•ç‡§¶‡•ç‡§µ ‡§∞ ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§®‡§Æ‡§æ ‡§≠‡§è‡§ï‡§æ ‡§Ö‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ö‡•ã‡§ü‡§≤‡§æ‡§à ‡§Æ‡§≤‡§Æ‡§™‡§ü‡•ç‡§ü‡•Ä ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡•Å‡§µ‡§ø‡§ö‡§æ‡§∞‡§≤‡•á ‡§Ö‡§¨ ‡§™‡•ç‡§∞‡§∂‡•ç‡§∞‡§Ø ‡§™‡§æ‡§â‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§¨‡§¢‡•ç‡§¶‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§∞‡•ç‡§µ‡•ã‡§ö‡•ç‡§ö ‡§Ö‡§¶‡§æ‡§≤‡§§‡§ï‡•ã ‡§Ü‡§¶‡•á‡§∂‡§™‡§õ‡§ø ‡§¨‡§®‡•á‡§ï‡•ã ‡§µ‡§ø‡§ú‡•ç‡§û ‡§ü‡•ã‡§≤‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§≤‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•á‡§∞ ‡§ú‡•ã‡§ó‡§æ‡§â‡§® ‡§≠‡§®‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§∏‡§∞‡•ç‡§µ‡•ã‡§ö‡•ç‡§ö ‡§Ö‡§¶‡§æ‡§≤‡§§‡§ï‡•ã ‡§Ü‡§¶‡•á‡§∂‡§™‡§õ‡§ø ‡§¨‡§®‡•á‡§ï‡•ã ‡§µ‡§ø‡§ú‡•ç‡§û ‡§ü‡•ã‡§≤‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§≤‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•á‡§∞ ‡§ú‡•ã‡§ó‡§æ‡§â‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§≠‡§®‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§∏‡§∞‡•ç‡§µ‡•ã‡§ö‡•ç‡§ö ‡§Ö‡§¶‡§æ‡§≤‡§§‡§ï‡•ã ‡§Ü‡§¶‡•á‡§∂‡§™‡§õ‡§ø ‡§¨‡§®‡•á‡§ï‡•ã ‡§µ‡§ø‡§ú‡•ç‡§û ‡§ü‡•ã‡§≤‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¨‡§≤‡•Ä‡§ï‡§∞‡§£ ‡§ó‡§∞‡•á‡§∞ ‡§ú‡•ã‡§ó‡§æ‡§â‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§≠‡§®‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§®‡•Ä ‡§Ö‡§Ø‡•ã‡§ß‡•ç‡§Ø‡§æ ‡§µ‡§ø‡§µ‡§æ‡§¶‡§Æ‡§æ ‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞ ‡§®‡§ø‡§∞‡•ç‡§µ‡§æ‡§£ ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§™‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "Corrected: ‡§â‡§®‡•Ä ‡§Ö‡§Ø‡•ã‡§ß‡•ç‡§Ø‡§æ ‡§µ‡§ø‡§µ‡§æ‡§¶‡§Æ‡§æ ‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§™‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "label:     ‡§â‡§®‡•Ä ‡§Ö‡§Ø‡•ã‡§ß‡•ç‡§Ø‡§æ ‡§µ‡§ø‡§µ‡§æ‡§¶‡§Æ‡§æ ‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§™‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§®‡•á ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§∏‡§Ç‡§∏‡•ç‡§•‡§æ‡§∏‡§Æ‡•ç‡§Æ ‡§ú‡§æ‡§®‡•á ‡§ñ‡§∞‡•ç‡§ö‡§ï‡•ã ‡§Ö‡§≠‡§æ‡§µ‡§Æ‡§æ ‡§∞‡•ã‡§ó‡§≤‡§æ‡§à ‡§™‡§æ‡§≤‡•á‡§∞ ‡§¨‡§∏‡•ç‡•ç ‡§â‡§®‡•Ä‡§π‡§∞‡•Å‡§ï‡•ã ‡§¨‡§æ‡§ß‡•ç‡§Ø‡§§‡§æ ‡§õ ‡•§\n",
      "Corrected: ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§®‡•á ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§∏‡§Ç‡§∏‡•ç‡§•‡§æ‡§∏‡§Æ‡•ç‡§Æ ‡§ú‡§æ‡§®‡•á ‡§ñ‡§∞‡•ç‡§ö‡§ï‡•ã ‡§Ö‡§≠‡§æ‡§µ‡§Æ‡§æ ‡§∞‡•ã‡§ó‡§≤‡§æ‡§à ‡§™‡§æ‡§≤‡•á‡§∞ ‡§¨‡§∏‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§â‡§®‡•Ä‡§π‡§∞‡•Å‡§ï‡•ã ‡§¨‡§æ‡§ß‡•ç‡§Ø‡§§‡§æ ‡§õ ‡•§\n",
      "label:     ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ó‡§∞‡•ç‡§®‡•á ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§∏‡§Ç‡§∏‡•ç‡§•‡§æ‡§∏‡§Æ‡•ç‡§Æ ‡§ú‡§æ‡§®‡•á ‡§ñ‡§∞‡•ç‡§ö‡§ï‡•ã ‡§Ö‡§≠‡§æ‡§µ‡§Æ‡§æ ‡§∞‡•ã‡§ó‡§≤‡§æ‡§à ‡§™‡§æ‡§≤‡•á‡§∞ ‡§¨‡§∏‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§â‡§®‡•Ä‡§π‡§∞‡•Å‡§ï‡•ã ‡§¨‡§æ‡§ß‡•ç‡§Ø‡§§‡§æ ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡•ç‡§§‡•à ‡§ï‡§™‡•ç‡§§‡§æ‡§® ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ‡•ç‡§∏‡§®‡§≤‡•á ‡•ß‡•® ‡§∞‡§® ‡§≠‡§®‡•á ‡§¨‡•ç‡§∞‡•Å‡§∏ ‡§Ö‡§µ‡§ø‡§ú‡§ø‡§§ ‡•ß‡•Æ ‡§∞‡§®‡§Æ‡§æ ‡§∞‡§π‡•á ‡•§\n",
      "Corrected: ‡§§‡•ç‡§Ø‡§∏‡•ç‡§§‡•à ‡§ï‡§™‡•ç‡§§‡§æ‡§® ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ‡•ç‡§∏‡§®‡§≤‡•á ‡•ß‡•® ‡§∞‡§® ‡§ú‡•ã‡§°‡•á ‡§≠‡§®‡•á ‡§¨‡•ç‡§∞‡•Å‡§∏ ‡§Ö‡§µ‡§ø‡§ú‡§ø‡§§ ‡•ß‡•Æ ‡§∞‡§®‡§Æ‡§æ ‡§∞‡§π‡•á ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡•ç‡§§‡•à ‡§ï‡§™‡•ç‡§§‡§æ‡§® ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ‡•ç‡§∏‡§®‡§≤‡•á ‡•ß‡•® ‡§∞‡§® ‡§ú‡•ã‡§°‡•á ‡§≠‡§®‡•á ‡§¨‡•ç‡§∞‡•Å‡§∏ ‡§Ö‡§µ‡§ø‡§ú‡§ø‡§§ ‡•ß‡•Æ ‡§∞‡§®‡§Æ‡§æ ‡§∞‡§π‡•á ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§∞‡•Ä‡§¨ ‡§π‡§™‡•ç‡§§‡§æ‡§¶‡•á‡§ñ‡§ø ‡§è‡§ï ‡§ñ‡§æ‡§®‡•á‡§™‡§æ‡§®‡•Ä‡§ï‡•ã ‡§ö‡§∞‡§Æ ‡§Ö‡§≠‡§æ‡§µ ‡§≠‡§è‡§™‡§õ‡§ø ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡•á ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§∏‡§¶‡§∞‡§Æ‡•Å‡§ï‡§æ‡§Æ‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§≤‡§æ‡§à ‡§™‡§æ‡§®‡•Ä ‡§µ‡§ø‡§§‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•á‡§ï‡•ã ‡§õ‡•§\n",
      "Corrected: ‡§ï‡§∞‡•Ä‡§¨ ‡§è‡§ï ‡§π‡§™‡•ç‡§§‡§æ‡§¶‡•á‡§ñ‡§ø ‡§ñ‡§æ‡§®‡•á‡§™‡§æ‡§®‡•Ä‡§ï‡•ã ‡§ö‡§∞‡§Æ ‡§Ö‡§≠‡§æ‡§µ ‡§≠‡§è‡§™‡§õ‡§ø ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡•á ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§∏‡§¶‡§∞‡§Æ‡•Å‡§ï‡§æ‡§Æ‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§≤‡§æ‡§à ‡§™‡§æ‡§®‡•Ä ‡§µ‡§ø‡§§‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•á‡§ï‡•ã ‡§õ‡•§\n",
      "label:     ‡§ï‡§∞‡•Ä‡§¨ ‡§è‡§ï ‡§π‡§™‡•ç‡§§‡§æ‡§¶‡•á‡§ñ‡§ø ‡§ñ‡§æ‡§®‡•á‡§™‡§æ‡§®‡•Ä‡§ï‡•ã ‡§ö‡§∞‡§Æ ‡§Ö‡§≠‡§æ‡§µ ‡§≠‡§è‡§™‡§õ‡§ø ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡•á ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§∏‡§¶‡§∞‡§Æ‡•Å‡§ï‡§æ‡§Æ‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§≤‡§æ‡§à ‡§™‡§æ‡§®‡•Ä ‡§µ‡§ø‡§§‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•á‡§ï‡•ã ‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡§∞ ‡§™‡•Å‡§Å‡§ú‡•Ä‡§ó‡§§ ‡§≤‡§æ‡§≠‡§ï‡§∞‡§ï‡•ã ‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§Æ‡§æ ‡§™‡§®‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§Ç‡§ó‡§≤‡§¨‡§æ‡§∞‡§Æ‡§æ‡§§‡•ç‡§∞ ‡•≠‡•¶ ‡§≤‡§æ‡§ñ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•à ‡§ó‡•Å‡§Æ‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§§‡•ç‡§Ø‡§∏‡•à‡§ó‡§∞‡•Ä ‡§™‡•Å‡§Å‡§ú‡•Ä‡§ó‡§§ ‡§≤‡§æ‡§≠‡§ï‡§∞‡§ï‡•ã ‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§Æ‡§æ ‡§™‡§®‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§Ç‡§ó‡§≤‡§¨‡§æ‡§∞‡§Æ‡§æ‡§§‡•ç‡§∞ ‡•≠‡•¶ ‡§≤‡§æ‡§ñ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•à ‡§ó‡•Å‡§Æ‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡•à‡§ó‡§∞‡•Ä ‡§™‡•Å‡§Å‡§ú‡•Ä‡§ó‡§§ ‡§≤‡§æ‡§≠‡§ï‡§∞‡§ï‡•ã ‡§∏‡§®‡•ç‡§¶‡§∞‡•ç‡§≠‡§Æ‡§æ ‡§™‡§®‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§Ç‡§ó‡§≤‡§¨‡§æ‡§∞‡§Æ‡§æ‡§§‡•ç‡§∞ ‡•≠‡•¶ ‡§≤‡§æ‡§ñ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•à ‡§ó‡•Å‡§Æ‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§§‡§∞ ‡§µ‡§ø‡§°‡§Æ‡•ç‡§¨‡§®‡§æ ‡§ï‡•á ‡§õ ‡§≠‡§®‡•á, ‡§Ø‡§∏‡•ç‡§§‡§æ ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä‡§Æ‡§æ ‡§≠‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§õ‡§®‡•ç, ‡§Æ‡§æ‡§≤‡§ø‡§ï ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§¶‡•à‡§®‡§®‡•ç, ‡§™‡§§‡•ç‡§§‡§æ ‡§®‡•à ‡§≤‡§æ‡§ó‡•ç‡§® ‡•§\n",
      "Corrected: ‡§§‡§∞ ‡§µ‡§ø‡§°‡§Æ‡•ç‡§¨‡§®‡§æ ‡§ï‡•á ‡§õ ‡§≠‡§®‡•á, ‡§Ø‡§∏‡•ç‡§§‡§æ ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä‡§Æ‡§æ ‡§≠‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§õ‡§®‡•ç, ‡§Æ‡§æ‡§≤‡§ø‡§ï ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§¶‡•à‡§®‡§®‡•ç, ‡§™‡§§‡•ç‡§§‡§æ ‡§®‡•à ‡§≤‡§æ‡§ó‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "label:     ‡§§‡§∞ ‡§µ‡§ø‡§°‡§Æ‡•ç‡§¨‡§®‡§æ ‡§ï‡•á ‡§õ ‡§≠‡§®‡•á, ‡§Ø‡§∏‡•ç‡§§‡§æ ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä‡§Æ‡§æ ‡§≠‡§∞‡§ø‡§Ø‡§æ ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§õ‡§®‡•ç, ‡§Æ‡§æ‡§≤‡§ø‡§ï ‡§™‡§ï‡•ç‡§∞‡§æ‡§â ‡§™‡§∞‡•ç‡§¶‡•à‡§®‡§®‡•ç, ‡§™‡§§‡•ç‡§§‡§æ ‡§®‡•à ‡§≤‡§æ‡§ó‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•ç‡§§‡•ã‡§Æ‡§æ ‡§ï‡•á ‡§Æ‡•ã‡§¶‡•Ä‡§≤‡•á ‡§™‡•Ç‡§∞‡§æ ‡§π‡§æ‡§Æ‡•Ä‡§∏‡§Å‡§ó ‡§ó‡§Æ‡•ç‡§≠‡•Ä‡§∞‡§§‡§æ‡§∏‡§Å‡§ó ‡§∂‡§æ‡§®‡•ç‡§§‡•Ä ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ ‡§ó‡§∞‡•ç‡§≤‡§æ‡§®‡•ç ‡§≠‡§®‡•á‡§∞ ‡§Ü‡§∂‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ?\n",
      "Corrected: ‡§Ø‡§∏‡•ç‡§§‡•ã‡§Æ‡§æ ‡§ï‡•á ‡§Æ‡•ã‡§¶‡•Ä‡§≤‡•á ‡§π‡§æ‡§Æ‡•Ä‡§∏‡§Å‡§ó ‡§™‡•Ç‡§∞‡§æ ‡§ó‡§Æ‡•ç‡§≠‡•Ä‡§∞‡§§‡§æ‡§∏‡§Å‡§ó ‡§∂‡§æ‡§®‡•ç‡§§‡•Ä ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ ‡§ó‡§∞‡•ç‡§≤‡§æ‡§®‡•ç ‡§≠‡§®‡•á‡§∞ ‡§Ü‡§∂‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ?\n",
      "label:     ‡§Ø‡§∏‡•ç‡§§‡•ã‡§Æ‡§æ ‡§ï‡•á ‡§Æ‡•ã‡§¶‡•Ä‡§≤‡•á ‡§π‡§æ‡§Æ‡•Ä‡§∏‡§Å‡§ó ‡§™‡•Ç‡§∞‡§æ ‡§ó‡§Æ‡•ç‡§≠‡•Ä‡§∞‡§§‡§æ‡§∏‡§Å‡§ó ‡§∂‡§æ‡§®‡•ç‡§§‡•Ä ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ ‡§ó‡§∞‡•ç‡§≤‡§æ‡§®‡•ç ‡§≠‡§®‡•á‡§∞ ‡§Ü‡§∂‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ?\n",
      "---\n",
      "Original:  ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•á‡§∞‡•á‡§ï‡•ã ‡§∞ ‡§ï‡•ã‡§ü‡•ç‡§Ø‡§æ‡§è‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§Æ‡§æ ‡§∏‡§æ‡§Æ‡§æ‡§® ‡§∞ ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡•ç ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§®‡•á‡§™‡§æ‡§≤ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§ï‡§æ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§ï ‡§ß‡•ç‡§∞‡•Å‡§µ ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§†‡§≤‡•á ‡§ó‡•Å‡§®‡§æ‡§∏‡•ã ‡§ó‡§∞‡•á‡•§\n",
      "Corrected: ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•á‡§∞‡•á‡§ï‡•ã ‡§∞ ‡§ï‡•ã‡§ü‡•ç‡§Ø‡§æ‡§è‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§Æ‡§æ ‡§∏‡§æ‡§Æ‡§æ‡§® ‡§∞ ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§®‡•á‡§™‡§æ‡§≤ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§ï‡§æ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§ï ‡§ß‡•ç‡§∞‡•Å‡§µ ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§†‡§≤‡•á ‡§ó‡•Å‡§®‡§æ‡§∏‡•ã ‡§ó‡§∞‡•á‡•§\n",
      "label:     ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•á‡§∞‡•á‡§ï‡•ã ‡§∞ ‡§ï‡•ã‡§ü‡•ç‡§Ø‡§æ‡§è‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§Æ‡§æ ‡§∏‡§æ‡§Æ‡§æ‡§® ‡§∞ ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å ‡§ú‡§æ‡§Å‡§ö ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§®‡•á‡§™‡§æ‡§≤ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§ï‡§æ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§ï ‡§ß‡•ç‡§∞‡•Å‡§µ ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§†‡§≤‡•á ‡§ó‡•Å‡§®‡§æ‡§∏‡•ã ‡§ó‡§∞‡•á‡•§\n",
      "---\n",
      "Original:  ‡§ó‡•à‡§∞‡§Ü‡§µ‡§æ‡§∏‡•Ä‡§Ø ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§∏‡§Ç‡§ò (‡§è‡§®‡§Ü‡§∞‡§è‡§®‡§è) ‡§®‡§æ‡§á‡§ú‡•á‡§∞‡§ø‡§Ø‡§æ‡§ï‡•ã ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§™‡§∞‡§ø‡§∑‡§¶‡•ç (‡§è‡§®‡§∏‡•Ä‡§∏‡•Ä) ‡§ï‡•ã ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§™‡•å‡§°‡•á‡§≤ ‡§®‡§ø‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§≠‡§è‡§ï‡§æ ‡•§\n",
      "Corrected: ‡§ó‡•à‡§∞‡§Ü‡§µ‡§æ‡§∏‡•Ä‡§Ø ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§∏‡§Ç‡§ò (‡§è‡§®‡§Ü‡§∞‡§è‡§®‡§è) ‡§®‡§æ‡§á‡§ú‡•á‡§∞‡§ø‡§Ø‡§æ‡§ï‡•ã ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§™‡§∞‡§ø‡§∑‡§¶‡•ç (‡§è‡§®‡§∏‡•Ä‡§∏‡•Ä) ‡§ï‡•ã ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§™‡•å‡§°‡•á‡§≤ ‡§®‡§ø‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§≠‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§ó‡•à‡§∞‡§Ü‡§µ‡§æ‡§∏‡•Ä‡§Ø ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§∏‡§Ç‡§ò (‡§è‡§®‡§Ü‡§∞‡§è‡§®‡§è) ‡§®‡§æ‡§á‡§ú‡•á‡§∞‡§ø‡§Ø‡§æ‡§ï‡•ã ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ø ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§™‡§∞‡§ø‡§∑‡§¶‡•ç (‡§è‡§®‡§∏‡•Ä‡§∏‡•Ä) ‡§ï‡•ã ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§™‡•å‡§°‡•á‡§≤ ‡§®‡§ø‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§≠‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§Æ‡§æ ‡§ï‡•Å‡§®‡•à ‡§Ø‡•å‡§®‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡•Ä ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡§≤‡•á ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§® ‡§® ‡§§ ‡§∏‡•á‡§ï‡•ç‡§∏ ‡§∞‡•ã‡§¨‡•ã‡§ü‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§∞‡§æ‡§ñ‡§ø‡§è‡§ï‡•ã ‡§®‡•à ‡§•‡§ø‡§Ø‡•ã ?\n",
      "Corrected: ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§Æ‡§æ ‡§ï‡•Å‡§®‡•à ‡§Ø‡•å‡§®‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡•Ä ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡§≤‡•á ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§® ‡§® ‡§§ ‡§∏‡•á‡§ï‡•ç‡§∏ ‡§∞‡•ã‡§¨‡•ã‡§ü‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§∞‡§æ‡§ñ‡§ø‡§è‡§ï‡•ã ‡§®‡•à ‡§•‡§ø‡§Ø‡•ã ‡•§\n",
      "label:     ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§Æ‡§æ ‡§ï‡•Å‡§®‡•à ‡§Ø‡•å‡§®‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡•Ä ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡§≤‡•á ‡§≠‡§æ‡§ó ‡§≤‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§® ‡§® ‡§§ ‡§∏‡•á‡§ï‡•ç‡§∏ ‡§∞‡•ã‡§¨‡•ã‡§ü‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§®‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§∞‡§æ‡§ñ‡§ø‡§è‡§ï‡•ã ‡§®‡•à ‡§•‡§ø‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§∏‡§ï‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§ß‡•á‡§∞‡•à ‡§õ‡§®‡•ç ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡•§\n",
      "Corrected: ‡§â‡§∏‡§ï‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§ß‡•á‡§∞‡•à ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§â‡§∏‡§ï‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä ‡§ß‡•á‡§∞‡•à ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§Ö‡§ò‡§ø ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•á‡§∞ ‡§ü‡§æ‡§≤‡§ü‡•Å‡§≤ ‡§™‡§æ‡§∞‡§ø‡§è‡§ï‡•ã ‡§∞‡§æ‡§ú‡§æ‡§™‡•Å‡§∞‡§§‡§∞‡•ç‡§´ ‡§¶‡•Ä‡§∞‡•ç‡§ò‡§ï‡§æ‡§≤‡•Ä‡§® ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§®‡§ø‡§ï‡§æ‡§∏ ‡§®‡§ñ‡•ã‡§ú‡§ø‡§Å‡§¶‡§æ ‡§™‡•Å‡§≤ ‡§ï‡§ø‡§®‡§æ‡§∞‡§æ‡§Æ‡§æ ‡§™‡•Å‡§®‡§É ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•ç‡§® ‡§∏‡•Å‡§∞‡•Å ‡§≠‡§è‡§ï‡•ã ‡•§\n",
      "Corrected: ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§Ö‡§ò‡§ø ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•á‡§∞ ‡§ü‡§æ‡§≤‡§ü‡•Å‡§≤ ‡§™‡§æ‡§∞‡§ø‡§è‡§ï‡•ã ‡§∞‡§æ‡§ú‡§æ‡§™‡•Å‡§∞‡§§‡§∞‡•ç‡§´ ‡§¶‡•Ä‡§∞‡•ç‡§ò‡§ï‡§æ‡§≤‡•Ä‡§® ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§®‡§ø‡§ï‡§æ‡§∏ ‡§®‡§ñ‡•ã‡§ú‡§ø‡§Å‡§¶‡§æ ‡§™‡•Å‡§≤ ‡§ï‡§ø‡§®‡§æ‡§∞‡§æ‡§Æ‡§æ ‡§™‡•Å‡§®‡§É ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•ç‡§® ‡§∏‡•Å‡§∞‡•Å ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§Ö‡§ò‡§ø ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•á‡§∞ ‡§ü‡§æ‡§≤‡§ü‡•Å‡§≤ ‡§™‡§æ‡§∞‡§ø‡§è‡§ï‡•ã ‡§∞‡§æ‡§ú‡§æ‡§™‡•Å‡§∞‡§§‡§∞‡•ç‡§´ ‡§¶‡•Ä‡§∞‡•ç‡§ò‡§ï‡§æ‡§≤‡•Ä‡§® ‡§∞‡•Ç‡§™‡§Æ‡§æ ‡§®‡§ø‡§ï‡§æ‡§∏ ‡§®‡§ñ‡•ã‡§ú‡§ø‡§Å‡§¶‡§æ ‡§™‡•Å‡§≤ ‡§ï‡§ø‡§®‡§æ‡§∞‡§æ‡§Æ‡§æ ‡§™‡•Å‡§®‡§É ‡§≠‡•ç‡§µ‡§æ‡§ô ‡§™‡§∞‡•ç‡§® ‡§∏‡•Å‡§∞‡•Å ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡•ã ‡§µ‡§∞‡•ç‡§∑ ‡§ú‡§®‡•ç‡§Æ ‡§≤‡§ø‡§®‡•á ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§∂‡•Å‡§≠ ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§≤‡§ø‡§è‡§∞ ‡§ú‡§®‡•ç‡§Æ‡•ç ‡•§\n",
      "Corrected: ‡§Ø‡•ã ‡§µ‡§∞‡•ç‡§∑ ‡§ú‡§®‡•ç‡§Æ ‡§≤‡§ø‡§®‡•á ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§∂‡•Å‡§≠ ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§≤‡§ø‡§è‡§∞ ‡§ú‡§®‡•ç‡§Æ‡§®‡•á‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§Ø‡•ã ‡§µ‡§∞‡•ç‡§∑ ‡§ú‡§®‡•ç‡§Æ ‡§≤‡§ø‡§®‡•á ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§∂‡•Å‡§≠ ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§≤‡§ø‡§è‡§∞ ‡§ú‡§®‡•ç‡§Æ‡§®‡•á‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§æ‡§≤‡•Ä‡§ï‡•ã‡§ü ‚Äî ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§ó‡§§ ‡§µ‡•à‡§∂‡§æ‡§ñ‡§Æ‡§æ ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä‚Äì‡§∞‡§æ‡§∞‡§æ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§® ‡§µ‡§∞‡•ç‡§∑‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≠‡§ø‡§§‡•ç‡§∞‡•Å ‡§∏‡§°‡§ï ‡§¨‡§æ‡§ß‡§ï ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§ï‡§æ‡§≤‡•Ä‡§ï‡•ã‡§ü ‚Äî ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§ó‡§§ ‡§µ‡•à‡§∂‡§æ‡§ñ‡§Æ‡§æ ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä‚Äì‡§∞‡§æ‡§∞‡§æ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§® ‡§µ‡§∞‡•ç‡§∑‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≠‡§ø‡§§‡•ç‡§∞‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§°‡§ï ‡§¨‡§æ‡§ß‡§ï ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§ï‡§æ‡§≤‡•Ä‡§ï‡•ã‡§ü ‚Äî ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§ó‡§§ ‡§µ‡•à‡§∂‡§æ‡§ñ‡§Æ‡§æ ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§ï‡§∞‡•ç‡§£‡§æ‡§≤‡•Ä‚Äì‡§∞‡§æ‡§∞‡§æ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§® ‡§µ‡§∞‡•ç‡§∑‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≠‡§ø‡§§‡•ç‡§∞‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§°‡§ï ‡§¨‡§æ‡§ß‡§ï ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ö‡•Ä‡§® ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§≤‡§æ‡§à ‡§π‡§∞‡•á‡§ï ‡§¢‡§Ç‡§ó‡§≤‡•á ‡§∏‡§ò‡§æ‡§â‡§®‡•á ‡§≠‡§®‡•á‡§ï‡•ã ‡§õ ‡§Ø‡•ã ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§π‡•ã ‡§Ø‡§∏‡§ï‡•ã ‡§ñ‡•Å‡§≤‡•á‡§∞ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ó‡§∞‡•ç‡•à ‡•§\n",
      "Corrected: ‡§ö‡•Ä‡§® ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§≤‡§æ‡§à ‡§π‡§∞‡•á‡§ï ‡§¢‡§Ç‡§ó‡§≤‡•á ‡§∏‡§ò‡§æ‡§â‡§®‡•á ‡§≠‡§®‡•á‡§ï‡•ã ‡§õ ‡§Ø‡•ã ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§π‡•ã ‡§Ø‡§∏‡§ï‡•ã ‡§ñ‡•Å‡§≤‡•á‡§∞ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ó‡§∞‡•ç‡§õ‡•å‡§Ç ‡•§\n",
      "label:     ‡§ö‡•Ä‡§® ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§≤‡§æ‡§à ‡§π‡§∞‡•á‡§ï ‡§¢‡§Ç‡§ó‡§≤‡•á ‡§∏‡§ò‡§æ‡§â‡§®‡•á ‡§≠‡§®‡•á‡§ï‡•ã ‡§õ ‡§Ø‡•ã ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§π‡•ã ‡§Ø‡§∏‡§ï‡•ã ‡§ñ‡•Å‡§≤‡•á‡§∞ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ó‡§∞‡•ç‡§õ‡•å‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§µ‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å ‡§µ‡§ø‡§ú‡•ç‡§û‡§≤‡•á ‡§ï‡•Å‡§® ‡§¨‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å‡§ï‡•ã ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§®‡•ã‡§ü‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•á, ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§µ‡§ø‡§¶‡•ç‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§ï‡•Å‡§® ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§µ‡§¶‡•ç‡§∞‡•ç‡§ß‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡§ø‡§®‡•ç ‡•§\n",
      "Corrected: ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§µ‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å ‡§µ‡§ø‡§ú‡•ç‡§û‡§≤‡•á ‡§ï‡•Å‡§® ‡§¨‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å‡§ï‡•ã ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§®‡•ã‡§ü‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•á, ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§µ‡§ø‡§¶‡•ç‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§ï‡•Å‡§® ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§µ‡§¶‡•ç‡§∞‡•ç‡§ß‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡§ø‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§µ‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å ‡§µ‡§ø‡§ú‡•ç‡§û‡§≤‡•á ‡§ï‡•Å‡§® ‡§¨‡§®‡•ç‡§Ø‡§ú‡§®‡•ç‡§§‡•Å‡§ï‡•ã ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§®‡•ã‡§ü‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•á, ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§µ‡§ø‡§¶‡•ç‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡•ã ‡§ï‡•Å‡§® ‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§ø‡§≤‡§æ‡§à ‡§™‡•ç‡§∞‡§µ‡§¶‡•ç‡§∞‡•ç‡§ß‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡§ø‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§¶‡§∞‡•ç‡§∂‡§® ‡§≠‡•ç‡§∞‡§Æ‡§£ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§™‡§ü‡§®‡§æ‡§ï‡•ã ‡§∏‡§∞‡•ç‡§ï‡§ø‡§ü ‡§π‡§æ‡§â‡§∏‡§Æ‡§æ ‡§∞‡§æ‡§§ ‡•§\n",
      "Corrected: ‡§¶‡§∞‡•ç‡§∂‡§® ‡§≠‡•ç‡§∞‡§Æ‡§£ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§™‡§ü‡§®‡§æ‡§ï‡•ã ‡§∏‡§∞‡•ç‡§ï‡§ø‡§ü ‡§π‡§æ‡§â‡§∏‡§Æ‡§æ ‡§∞‡§æ‡§§ ‡§¨‡§ø‡§§‡§æ‡§Ø‡•å‡§Ç ‡•§\n",
      "label:     ‡§¶‡§∞‡•ç‡§∂‡§® ‡§≠‡•ç‡§∞‡§Æ‡§£ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§™‡§ü‡§®‡§æ‡§ï‡•ã ‡§∏‡§∞‡•ç‡§ï‡§ø‡§ü ‡§π‡§æ‡§â‡§∏‡§Æ‡§æ ‡§∞‡§æ‡§§ ‡§¨‡§ø‡§§‡§æ‡§Ø‡•å‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§¨‡•ç‡§∞‡•ã‡§ï‡§∞‡§≤‡•á ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡•Å‡§∞‡•Å ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•á‡§Æ‡•Ä‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§®‡§≠‡§è‡§ï‡•ã ‡§®‡•á‡§™‡•ç‡§∏‡•á‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§ö‡§®‡•ç‡§¶‡•ç‡§∞‡§∏‡§ø‡§Ç‡§π ‡§∏‡§æ‡§â‡§¶‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "Corrected: ‡§¨‡•ç‡§∞‡•ã‡§ï‡§∞‡§≤‡•á ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•á‡§Æ‡•Ä‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§®‡§≠‡§è‡§ï‡•ã ‡§®‡•á‡§™‡•ç‡§∏‡•á‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§ö‡§®‡•ç‡§¶‡•ç‡§∞‡§∏‡§ø‡§Ç‡§π ‡§∏‡§æ‡§â‡§¶‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "label:     ‡§¨‡•ç‡§∞‡•ã‡§ï‡§∞‡§≤‡•á ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡•á‡§Æ‡•Ä‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§®‡§≠‡§è‡§ï‡•ã ‡§®‡•á‡§™‡•ç‡§∏‡•á‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§ö‡§®‡•ç‡§¶‡•ç‡§∞‡§∏‡§ø‡§Ç‡§π ‡§∏‡§æ‡§â‡§¶‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§®‡§≤‡•á ‡§≠‡§®‡•á ‡§Ø‡§§‡§ø ‡§ß‡•á‡§∞‡•à ‡§´‡•á‡§≠‡§∞‡•á‡§ü ‡§ü‡§ø‡§Æ‡§π‡§∞‡•Å ‡§õ‡§ø‡§ü‡•ç‡§ü‡•à ‡§π‡§æ‡§∞‡•á‡§∞ ‡§ï‡§π‡§ø‡§≤‡•á ‡§™‡§®‡§ø ‡§ó‡§è‡§ï‡§æ ‡§•‡§ø‡§è‡§®‡§®‡•ç\n",
      "Corrected: ‡§â‡§®‡§≤‡•á ‡§≠‡§®‡•á, ‡§Ø‡§§‡§ø ‡§ß‡•á‡§∞‡•à ‡§´‡•á‡§≠‡§∞‡•á‡§ü ‡§ü‡§ø‡§Æ‡§π‡§∞‡•Å ‡§õ‡§ø‡§ü‡•ç‡§ü‡•à ‡§π‡§æ‡§∞‡•á‡§∞ ‡§ï‡§π‡§ø‡§≤‡•á ‡§™‡§®‡§ø ‡§ó‡§è‡§ï‡§æ ‡§•‡§ø‡§è‡§®‡§®‡•ç‡•§\n",
      "label:     ‡§â‡§®‡§≤‡•á ‡§≠‡§®‡•á, ‡§Ø‡§§‡§ø ‡§ß‡•á‡§∞‡•à ‡§´‡•á‡§≠‡§∞‡•á‡§ü ‡§ü‡§ø‡§Æ‡§π‡§∞‡•Å ‡§õ‡§ø‡§ü‡•ç‡§ü‡•à ‡§π‡§æ‡§∞‡•á‡§∞ ‡§ï‡§π‡§ø‡§≤‡•á ‡§™‡§®‡§ø ‡§ó‡§è‡§ï‡§æ ‡§•‡§ø‡§è‡§®‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§∞ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§ö‡§æ‡§∏‡•ã ‡§∞ ‡§∏‡§∞‡•ã‡§ï‡§æ‡§∞‡§ï‡§æ ‡§µ‡§ø‡§∑‡§Ø ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡§§‡•ç‡§∞‡§™‡§§‡•ç‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§® ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§¶‡§õ ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡•à‡§ó‡§∞‡•Ä ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§ö‡§æ‡§∏‡•ã ‡§∞ ‡§∏‡§∞‡•ã‡§ï‡§æ‡§∞‡§ï‡§æ ‡§µ‡§ø‡§∑‡§Ø ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡§§‡•ç‡§∞‡§™‡§§‡•ç‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§® ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§¶‡§õ ‡•§\n",
      "label:     ‡§Ø‡§∏‡•à‡§ó‡§∞‡•Ä ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§ö‡§æ‡§∏‡•ã ‡§∞ ‡§∏‡§∞‡•ã‡§ï‡§æ‡§∞‡§ï‡§æ ‡§µ‡§ø‡§∑‡§Ø ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡§§‡•ç‡§∞‡§™‡§§‡•ç‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§® ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§¶‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§á‡§Ç‡§ó‡•ç‡§≤‡•ç‡§Ø‡§æ‡§®‡•ç‡§° ‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏‡§Æ‡§æ ‡§≠‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡§™‡§Æ‡§æ ‡§¨‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§´‡•ç‡§≤‡•ç‡§Ø‡§æ‡§ü ‡§™‡§ø‡§ö‡§≤‡•á ‡§¨‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡§Æ‡•ç‡§Ø‡§æ‡§®‡§≤‡§æ‡§à ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡•Å‡§ó‡•ç‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ó‡§∞‡§ø‡§è ‡§™‡§®‡§ø ‡§Ö‡§≤‡•Ä ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§ö‡§ø‡§®‡•ç‡§§‡§ø‡§§ ‡§õ‡§® ‡•§\n",
      "Corrected: ‡§á‡§Ç‡§ó‡•ç‡§≤‡•ç‡§Ø‡§æ‡§®‡•ç‡§° ‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏‡§Æ‡§æ ‡§≠‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡§™‡§Æ‡§æ ‡§¨‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§´‡•ç‡§≤‡•ç‡§Ø‡§æ‡§ü ‡§™‡§ø‡§ö‡§≤‡•á ‡§¨‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡§Æ‡•ç‡§Ø‡§æ‡§®‡§≤‡§æ‡§à ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡•Å‡§ó‡•ç‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ó‡§∞‡§ø‡§è ‡§™‡§®‡§ø ‡§Ö‡§≤‡•Ä ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§ö‡§ø‡§®‡•ç‡§§‡§ø‡§§ ‡§õ‡•à‡§®‡§®‡•ç ‡•§\n",
      "label:     ‡§á‡§Ç‡§ó‡•ç‡§≤‡•ç‡§Ø‡§æ‡§®‡•ç‡§° ‡§∞ ‡§µ‡•á‡§≤‡•ç‡§∏‡§Æ‡§æ ‡§≠‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡§™‡§Æ‡§æ ‡§¨‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§´‡•ç‡§≤‡•ç‡§Ø‡§æ‡§ü ‡§™‡§ø‡§ö‡§≤‡•á ‡§¨‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡§Æ‡•ç‡§Ø‡§æ‡§®‡§≤‡§æ‡§à ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§™‡•Å‡§ó‡•ç‡§®‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ó‡§∞‡§ø‡§è ‡§™‡§®‡§ø ‡§Ö‡§≤‡•Ä ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§ö‡§ø‡§®‡•ç‡§§‡§ø‡§§ ‡§õ‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§§‡§ø‡§¨‡•ç‡§∞ ‡§µ‡§æ ‡§õ‡§ø‡§ü‡•ã ‡§õ‡§ø‡§®‡•ã ‡§ñ‡§æ‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§õ‡•á‡§≤‡•á ‡§ß‡•á‡§∞‡•à ‡§ñ‡§æ‡§®‡•ç ‡•§\n",
      "Corrected: ‡§§‡§ø‡§¨‡•ç‡§∞ ‡§µ‡§æ ‡§õ‡§ø‡§ü‡•ã ‡§õ‡§ø‡§®‡•ã ‡§ñ‡§æ‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§õ‡•á‡§≤‡•á ‡§ß‡•á‡§∞‡•à ‡§ñ‡§æ‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§§‡§ø‡§¨‡•ç‡§∞ ‡§µ‡§æ ‡§õ‡§ø‡§ü‡•ã ‡§õ‡§ø‡§®‡•ã ‡§ñ‡§æ‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§õ‡•á‡§≤‡•á ‡§ß‡•á‡§∞‡•à ‡§ñ‡§æ‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§§‡•ç‡§§‡§æ‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§æ‡§Ç‡§∏‡§¶‡§π‡§∞‡•Ç ‡§ï‡•á‡§∏‡•Ä‡§ï‡•ã ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§â‡§®‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§•‡§®‡§Æ‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡§æ ‡•§\n",
      "Corrected: ‡§∏‡§§‡•ç‡§§‡§æ‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§æ‡§Ç‡§∏‡§¶‡§π‡§∞‡•Ç ‡§ï‡•á‡§∏‡•Ä‡§ï‡•ã ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§â‡§®‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§•‡§®‡§Æ‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§∏‡§§‡•ç‡§§‡§æ‡§™‡§ï‡•ç‡§∑‡•Ä‡§Ø ‡§∏‡§æ‡§Ç‡§∏‡§¶‡§π‡§∞‡•Ç ‡§ï‡•á‡§∏‡•Ä‡§ï‡•ã ‡§µ‡§ø‡§™‡§ï‡•ç‡§∑ ‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§™‡§ï‡•ç‡§∑‡•Ä ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§â‡§®‡§ï‡•ã ‡§∏‡§Æ‡§∞‡•ç‡§•‡§®‡§Æ‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•à ‡§®‡•Ä‡§§‡§ø‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£‡•Ä ‡§ö‡§ø‡§®‡§ø‡§Ø‡§æ‡§Å‡§π‡§∞‡•Ç ‡§≤‡§ó‡§æ‡§®‡•Ä‡§ï‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ ‡§¨‡•ã‡§ï‡•á‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§∏‡§Æ‡•ç‡§Æ‡•à ‡§™‡•Å‡§ó‡§ø‡§∏‡§ï‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ?\n",
      "Corrected: ‡§Ø‡§∏‡•à ‡§®‡•Ä‡§§‡§ø‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£‡•Ä ‡§ö‡§ø‡§®‡§ø‡§Ø‡§æ‡§Å‡§π‡§∞‡•Ç ‡§≤‡§ó‡§æ‡§®‡•Ä‡§ï‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ ‡§¨‡•ã‡§ï‡•á‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§∏‡§Æ‡•ç‡§Æ‡•à ‡§™‡•Å‡§ó‡§ø‡§∏‡§ï‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§Ø‡§∏‡•à ‡§®‡•Ä‡§§‡§ø‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£‡•Ä ‡§ö‡§ø‡§®‡§ø‡§Ø‡§æ‡§Å‡§π‡§∞‡•Ç ‡§≤‡§ó‡§æ‡§®‡•Ä‡§ï‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ ‡§¨‡•ã‡§ï‡•á‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§∏‡§Æ‡•ç‡§Æ‡•à ‡§™‡•Å‡§ó‡§ø‡§∏‡§ï‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§≤‡•á ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§™‡§§‡§ø ‡§ü‡•ç‡§∞‡§Æ‡•ç‡§™‡§≤‡§æ‡§à ‡§°‡•ã‡§®‡§æ‡§≤‡•ç‡§° ‡§•‡§™ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡§≤‡•á ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§™‡§§‡§ø ‡§°‡•ã‡§®‡§æ‡§≤‡•ç‡§° ‡§ü‡•ç‡§∞‡§Æ‡•ç‡§™‡§≤‡§æ‡§à ‡§•‡§™ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§Ø‡§∏‡§≤‡•á ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§™‡§§‡§ø ‡§°‡•ã‡§®‡§æ‡§≤‡•ç‡§° ‡§ü‡•ç‡§∞‡§Æ‡•ç‡§™‡§≤‡§æ‡§à ‡§•‡§™ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§ï‡§æ ‡§Ø‡§ø‡§®‡•à ‡§ó‡•Å‡§£‡§≤‡•á ‡§ï‡§æ‡§Æ‡§¶‡§æ‡§∞‡§ï‡•ã ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§Æ‡§æ‡§ó ‡§ï‡§æ‡§Ø‡§Æ‡•à ‡§∞‡§π‡§®‡•á‡§õ ‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡§æ ‡§Æ‡•ç‡§Ø‡§æ‡§®‡§™‡§æ‡§µ‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§™‡§æ‡§â‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "Corrected: ‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§ï‡§æ ‡§Ø‡§ø‡§®‡•à ‡§ó‡•Å‡§£‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§ï‡§æ‡§Æ‡§¶‡§æ‡§∞‡§ï‡•ã ‡§Æ‡§æ‡§ó ‡§ï‡§æ‡§Ø‡§Æ‡•à ‡§∞‡§π‡§®‡•á‡§õ ‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡§æ ‡§Æ‡•ç‡§Ø‡§æ‡§®‡§™‡§æ‡§µ‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§™‡§æ‡§â‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "label:     ‡§®‡•á‡§™‡§æ‡§≤‡•Ä‡§ï‡§æ ‡§Ø‡§ø‡§®‡•à ‡§ó‡•Å‡§£‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§ï‡§æ‡§Æ‡§¶‡§æ‡§∞‡§ï‡•ã ‡§Æ‡§æ‡§ó ‡§ï‡§æ‡§Ø‡§Æ‡•à ‡§∞‡§π‡§®‡•á‡§õ ‡§∞ ‡§®‡•á‡§™‡§æ‡§≤‡§ï‡§æ ‡§Æ‡•ç‡§Ø‡§æ‡§®‡§™‡§æ‡§µ‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§∏‡•á‡§µ‡§æ ‡§∂‡•Å‡§≤‡•ç‡§ï ‡§™‡§æ‡§â‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§§‡§∞, ‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£‡§≤‡•á ‡§°‡•á‡§¢ ‡§Ö‡§∞‡•ç‡§¨ ‡§Æ‡§æ‡§§‡•ç‡§∞‡•à ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§™‡•ç‡§∞‡§§‡§ø‡§¨‡§¶‡•ç‡§ß‡§§‡§æ ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡§â‡§®‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "Corrected: ‡§§‡§∞, ‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£‡§≤‡•á ‡§°‡•á‡§¢ ‡§Ö‡§∞‡•ç‡§¨ ‡§Æ‡§æ‡§§‡•ç‡§∞‡•à ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ó‡§∞‡§æ‡§â‡§®‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§¨‡§¶‡•ç‡§ß‡§§‡§æ ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡§â‡§®‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "label:     ‡§§‡§∞, ‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£‡§≤‡•á ‡§°‡•á‡§¢ ‡§Ö‡§∞‡•ç‡§¨ ‡§Æ‡§æ‡§§‡•ç‡§∞‡•à ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ó‡§∞‡§æ‡§â‡§®‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§¨‡§¶‡•ç‡§ß‡§§‡§æ ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡§â‡§®‡§≤‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§§‡§ø‡§∏‡§Æ‡•ç‡§Æ ‡§ï‡§ø ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∂‡•à‡§∂‡§µ‡§ï‡§æ‡§≤‡§¶‡•á‡§ñ‡§ø ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§π‡§∞‡•á‡§ï ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ò‡§ü‡§®‡§æ, ‡§§‡§ø‡§•‡§ø‚Äì‡§Æ‡§ø‡§§‡§ø‡§∏‡§π‡§ø‡§§ ‡§∏‡§µ‡§æ‡§≤‚Äì‡§ú‡§µ‡§æ‡§´ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ ‡§â‡§®‡•Ä ‡•§\n",
      "Corrected: ‡§Ø‡§§‡§ø‡§∏‡§Æ‡•ç‡§Æ ‡§ï‡§ø ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∂‡•à‡§∂‡§µ‡§ï‡§æ‡§≤‡§¶‡•á‡§ñ‡§ø ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§π‡§∞‡•á‡§ï ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ò‡§ü‡§®‡§æ, ‡§§‡§ø‡§•‡§ø‚Äì‡§Æ‡§ø‡§§‡§ø‡§∏‡§π‡§ø‡§§ ‡§∏‡§µ‡§æ‡§≤‚Äì‡§ú‡§µ‡§æ‡§´ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ‡§®‡•ç ‡§â‡§®‡•Ä ‡•§\n",
      "label:     ‡§Ø‡§§‡§ø‡§∏‡§Æ‡•ç‡§Æ ‡§ï‡§ø ‡§Ü‡§´‡•ç‡§®‡•ã ‡§∂‡•à‡§∂‡§µ‡§ï‡§æ‡§≤‡§¶‡•á‡§ñ‡§ø ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§π‡§∞‡•á‡§ï ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ò‡§ü‡§®‡§æ, ‡§§‡§ø‡§•‡§ø‚Äì‡§Æ‡§ø‡§§‡§ø‡§∏‡§π‡§ø‡§§ ‡§∏‡§µ‡§æ‡§≤‚Äì‡§ú‡§µ‡§æ‡§´ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ‡§®‡•ç ‡§â‡§®‡•Ä ‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡§ø‡§°‡§ø‡§Ø‡§æ ‡§Ü‡§´‡•Ç‡§™‡•ç‡§∞‡§§‡§ø ‡§®‡§ï‡§æ‡§∞‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∞‡§π‡•á‡§ï‡•ã ‡§Æ‡§π‡§æ‡§®‡§ó‡§∞‡§≤‡•á ‡§≠‡§®‡•ç‡§¶‡•à ‡§è‡§ï ‡§µ‡§∞‡•ç‡§∑‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ß‡•á‡§∞‡•à ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: ‡§Æ‡§ø‡§°‡§ø‡§Ø‡§æ ‡§Ü‡§´‡•Ç‡§™‡•ç‡§∞‡§§‡§ø ‡§®‡§ï‡§æ‡§∞‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∞‡§π‡•á‡§ï‡•ã ‡§≠‡§®‡•ç‡§¶‡•à ‡§Æ‡§π‡§æ‡§®‡§ó‡§∞‡§≤‡•á ‡§è‡§ï ‡§µ‡§∞‡•ç‡§∑‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ß‡•á‡§∞‡•à ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§Æ‡§ø‡§°‡§ø‡§Ø‡§æ ‡§Ü‡§´‡•Ç‡§™‡•ç‡§∞‡§§‡§ø ‡§®‡§ï‡§æ‡§∞‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∞‡§π‡•á‡§ï‡•ã ‡§≠‡§®‡•ç‡§¶‡•à ‡§Æ‡§π‡§æ‡§®‡§ó‡§∞‡§≤‡•á ‡§è‡§ï ‡§µ‡§∞‡•ç‡§∑‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ß‡•á‡§∞‡•à ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§è‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§®‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§®‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ ‡•§\n",
      "label:     ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ö‡§®‡•ç‡§§‡•ç‡§Ø ‡§®‡§π‡•Å‡§® ‡§∏‡§ï‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§®‡•ç‡§Ø ‡§™‡§∞‡§ø‡§ö‡§Ø‡§™‡§§‡•ç‡§∞‡§ß‡§æ‡§∞‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§ï‡•ç‡§∞‡§Æ‡§∂‡§É ‡§∏‡§π‡•Å‡§≤‡§ø‡§Ø‡§§‡§Æ‡§æ ‡§∏‡•á‡§µ‡§æ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§™‡§æ‡§â‡§®‡•á ‡§ú‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§õ\n",
      "Corrected: ‡§Ö‡§®‡•ç‡§Ø ‡§™‡§∞‡§ø‡§ö‡§Ø‡§™‡§§‡•ç‡§∞‡§ß‡§æ‡§∞‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§ï‡•ç‡§∞‡§Æ‡§∂‡§É ‡§∏‡§π‡•Å‡§≤‡§ø‡§Ø‡§§‡§Æ‡§æ ‡§∏‡•á‡§µ‡§æ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§™‡§æ‡§â‡§®‡•á ‡§ú‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§Ö‡§®‡•ç‡§Ø ‡§™‡§∞‡§ø‡§ö‡§Ø‡§™‡§§‡•ç‡§∞‡§ß‡§æ‡§∞‡•Ä‡§≤‡•á ‡§™‡§®‡§ø ‡§ï‡•ç‡§∞‡§Æ‡§∂‡§É ‡§∏‡§π‡•Å‡§≤‡§ø‡§Ø‡§§‡§Æ‡§æ ‡§∏‡•á‡§µ‡§æ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§™‡§æ‡§â‡§®‡•á ‡§ú‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ó‡•ã‡§ö‡§∞‡§≤‡•á ‡§è‡§ï ‡§∏‡§§‡§§‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ‡§ó‡§∞‡•ç‡§®‡•á ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§‡§§‡§æ‡§≤‡§æ‡§à ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ï‡•ã ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ó‡§∞‡•ç‡§® ‡§â‡§§‡•ç‡§™‡•ç‡§∞‡•á‡§∞‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "Corrected: ‡§ó‡•ã‡§ö‡§∞‡§≤‡•á ‡§è‡§ï ‡§∏‡§§‡§§‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ‡§ó‡§∞‡•ç‡§®‡•á ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§‡§§‡§æ‡§≤‡§æ‡§à ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ó‡§∞‡•ç‡§® ‡§â‡§§‡•ç‡§™‡•ç‡§∞‡•á‡§∞‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "label:     ‡§ó‡•ã‡§ö‡§∞‡§≤‡•á ‡§è‡§ï ‡§∏‡§§‡§§‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ‡§ó‡§∞‡•ç‡§®‡•á ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡§ï‡•ã ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§‡§§‡§æ‡§≤‡§æ‡§à ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ó‡§∞‡•ç‡§® ‡§â‡§§‡•ç‡§™‡•ç‡§∞‡•á‡§∞‡§ø‡§§ ‡§ó‡§∞‡•á‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§ú‡•Å‡§® ‡§¶‡•á‡§∂‡§∏‡§Å‡§ó ‡§ú‡•á ‡§µ‡§∏‡•ç‡§§‡•Å ‡§™‡•ç‡§∞‡§ö‡•Å‡§∞ ‡§õ ‡§§‡•ç‡§Ø‡§∏‡§ï‡•ã ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•Ä ‡§Ö‡§ò‡§ø ‡§¨‡§¢‡•ç‡§®‡•á ‡•§\n",
      "Corrected: ‡§ú‡•Å‡§® ‡§¶‡•á‡§∂‡§∏‡§Å‡§ó ‡§ú‡•á ‡§µ‡§∏‡•ç‡§§‡•Å ‡§™‡•ç‡§∞‡§ö‡•Å‡§∞ ‡§õ ‡§§‡•ç‡§Ø‡§∏‡§ï‡•ã ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•Ä ‡§Ö‡§ò‡§ø ‡§¨‡§¢‡•ç‡§®‡•á ‡§π‡•ã ‡•§\n",
      "label:     ‡§ú‡•Å‡§® ‡§¶‡•á‡§∂‡§∏‡§Å‡§ó ‡§ú‡•á ‡§µ‡§∏‡•ç‡§§‡•Å ‡§™‡•ç‡§∞‡§ö‡•Å‡§∞ ‡§õ ‡§§‡•ç‡§Ø‡§∏‡§ï‡•ã ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•Ä ‡§Ö‡§ò‡§ø ‡§¨‡§¢‡•ç‡§®‡•á ‡§π‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Æ‡•ç‡§ù‡•å‡§§‡§æ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ï‡§æ‡§Æ ‡§∞ ‡§§‡§≤‡§¨ ‡§®‡§™‡§æ‡§è‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§™‡§®‡§ø ‡§â‡§®‡•Ä‡§π‡§∞‡•Å ‡§â‡§¶‡•ç‡§ß‡§æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡•ã ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§≤‡•á ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡•§\n",
      "Corrected: ‡§∏‡§Æ‡•ç‡§ù‡•å‡§§‡§æ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ï‡§æ‡§Æ ‡§∞ ‡§§‡§≤‡§¨ ‡§®‡§™‡§æ‡§è‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§™‡§®‡§ø ‡§â‡§®‡•Ä‡§π‡§∞‡•Å ‡§â‡§¶‡•ç‡§ß‡§æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡•ã ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§≤‡•á ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§∏‡§Æ‡•ç‡§ù‡•å‡§§‡§æ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§ï‡§æ‡§Æ ‡§∞ ‡§§‡§≤‡§¨ ‡§®‡§™‡§æ‡§è‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§™‡§®‡§ø ‡§â‡§®‡•Ä‡§π‡§∞‡•Å ‡§â‡§¶‡•ç‡§ß‡§æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡•ã ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§≤‡•á ‡§ú‡§®‡§æ‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§®‡§Æ‡§æ ‡§µ‡§ø‡§Æ‡§æ‡§®‡§∏‡•ç‡§•‡§≤ ‡§µ‡§∞‡§™‡§∞‡§ï‡§æ ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§§‡§•‡§æ ‡§ó‡§æ‡§â‡§Å‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡§æ‡§à ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§è‡§µ‡§Ç ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§∂‡§π‡§∞ ‡§¨‡§®‡§® ‡§≤‡§ó‡§æ‡§è‡§Æ‡§æ ‡§è‡§Ø‡§∞‡§™‡•ã‡§∞‡•ç‡§ü ‡§∏‡§ø‡§ü‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Å‡§®‡•á ‡§†‡§π‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§®‡§Æ‡§æ ‡§µ‡§ø‡§Æ‡§æ‡§®‡§∏‡•ç‡§•‡§≤ ‡§µ‡§∞‡§™‡§∞‡§ï‡§æ ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§§‡§•‡§æ ‡§ó‡§æ‡§â‡§Å‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡§æ‡§à ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§è‡§µ‡§Ç ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§∂‡§π‡§∞ ‡§¨‡§®‡§æ‡§â‡§® ‡§≤‡§ó‡§æ‡§è‡§Æ‡§æ ‡§è‡§Ø‡§∞‡§™‡•ã‡§∞‡•ç‡§ü ‡§∏‡§ø‡§ü‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Å‡§®‡•á ‡§†‡§π‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§®‡§Æ‡§æ ‡§µ‡§ø‡§Æ‡§æ‡§®‡§∏‡•ç‡§•‡§≤ ‡§µ‡§∞‡§™‡§∞‡§ï‡§æ ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§§‡§•‡§æ ‡§ó‡§æ‡§â‡§Å‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡§æ‡§à ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§ø‡§§ ‡§è‡§µ‡§Ç ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï ‡§∂‡§π‡§∞ ‡§¨‡§®‡§æ‡§â‡§® ‡§≤‡§ó‡§æ‡§è‡§Æ‡§æ ‡§è‡§Ø‡§∞‡§™‡•ã‡§∞‡•ç‡§ü ‡§∏‡§ø‡§ü‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§®‡§π‡•Å‡§®‡•á ‡§†‡§π‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡•Ä‡§Æ‡§æ‡§∏‡•ç‡§§‡§Æ‡•ç‡§≠ ‡§ó‡§æ‡§°‡•ç‡§®‡•Å‡§Ö‡§ò‡§ø ‡§§‡•ç‡§Ø‡§∏ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§∏‡§Å‡§ó ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§®‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•á ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡•§\n",
      "Corrected: ‡§∏‡•Ä‡§Æ‡§æ‡§∏‡•ç‡§§‡§Æ‡•ç‡§≠ ‡§ó‡§æ‡§°‡•ç‡§®‡•Å‡§Ö‡§ò‡§ø ‡§§‡•ç‡§Ø‡§∏ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§∏‡§Å‡§ó ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§®‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•á ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§¨‡•Å‡§ù‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡•§\n",
      "label:     ‡§∏‡•Ä‡§Æ‡§æ‡§∏‡•ç‡§§‡§Æ‡•ç‡§≠ ‡§ó‡§æ‡§°‡•ç‡§®‡•Å‡§Ö‡§ò‡§ø ‡§§‡•ç‡§Ø‡§∏ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡§æ ‡§¨‡§æ‡§∏‡§ø‡§®‡•ç‡§¶‡§æ‡§∏‡§Å‡§ó ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§®‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•á ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§¨‡•Å‡§ù‡•ç‡§® ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§Æ‡•á‡§ï‡§æ‡§®‡§ø‡§ú‡•ç‡§Æ ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§õ ‡•§\n",
      "Corrected: ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§Æ‡•á‡§ï‡§æ‡§®‡§ø‡§ú‡•ç‡§Æ ‡§§ ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§õ ‡•§\n",
      "label:     ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§Æ‡•á‡§ï‡§æ‡§®‡§ø‡§ú‡•ç‡§Æ ‡§§ ‡§§‡•ç‡§Ø‡§∏‡§Æ‡§æ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§§‡•ç‡§Ø‡§∏‡•à‡§≤‡•á ‡§π‡§æ‡§Æ‡•Ä ‡§≠‡§æ‡§∞‡§§‡§ï‡•ã ‡§≤‡§¶‡§æ‡§ñ ‡§™‡•Å‡§ó‡•ç‡•å ‡•§\n",
      "Corrected: ‡§§‡•ç‡§Ø‡§∏‡•à‡§≤‡•á ‡§π‡§æ‡§Æ‡•Ä ‡§≠‡§æ‡§∞‡§§‡§ï‡•ã ‡§≤‡§¶‡§æ‡§ñ ‡§™‡•Å‡§ó‡•ç‡§Ø‡•å‡§Å ‡•§\n",
      "label:     ‡§§‡•ç‡§Ø‡§∏‡•à‡§≤‡•á ‡§π‡§æ‡§Æ‡•Ä ‡§≠‡§æ‡§∞‡§§‡§ï‡•ã ‡§≤‡§¶‡§æ‡§ñ ‡§™‡•Å‡§ó‡•ç‡§Ø‡•å‡§Å ‡•§\n",
      "---\n",
      "Original:  ‡§∞‡§µ‡•Ä‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§ï‡•ã ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø‡§≤‡•á ‡§ï‡§∞ ‡§â‡§®‡•ç‡§Æ‡•Å‡§ï‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§®‡•à ‡§∏‡§ò‡§æ‡§â ‡§™‡•Å‡§∞‡•ç‚Äç‡§Ø‡§æ‡§â‡§®‡•á ‡§ó‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡•§\n",
      "Corrected: ‡§∞‡§µ‡•Ä‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§ï‡•ã ‡§§‡§§‡•ç‡§ï‡§æ‡§≤‡•Ä‡§® ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø‡§≤‡•á ‡§ï‡§∞ ‡§â‡§®‡•ç‡§Æ‡•Å‡§ï‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§®‡•à ‡§∏‡§ò‡§æ‡§â ‡§™‡•Å‡§∞‡•ç ‡§Ø‡§æ‡§â‡§®‡•á ‡§ó‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡•§\n",
      "label:     ‡§∞‡§µ‡•Ä‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ‡§ï‡•ã ‡§§‡§§‡•ç‡§ï‡§æ‡§≤‡•Ä‡§® ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§∏‡§Æ‡§ø‡§§‡§ø‡§≤‡•á ‡§ï‡§∞ ‡§â‡§®‡•ç‡§Æ‡•Å‡§ï‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§®‡•à ‡§∏‡§ò‡§æ‡§â ‡§™‡•Å‡§∞‡•ç‚Äç‡§Ø‡§æ‡§â‡§®‡•á ‡§ó‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§≤‡•á ‡§¨‡§ö‡•ç‡§ö‡§æ‡§π‡§∞‡•Å‡§≤‡§æ‡§à ‡§π‡§ø‡§Ç‡§∏‡•ç‡§∞‡§ï, ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§ï ‡§¨‡§®‡§õ ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡§≤‡•á ‡§¨‡§ö‡•ç‡§ö‡§æ‡§π‡§∞‡•Å‡§≤‡§æ‡§à ‡§π‡§ø‡§Ç‡§∏‡•ç‡§∞‡§ï, ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§ï ‡§¨‡§®‡§æ‡§â‡§Å‡§õ ‡•§\n",
      "label:     ‡§Ø‡§∏‡§≤‡•á ‡§¨‡§ö‡•ç‡§ö‡§æ‡§π‡§∞‡•Å‡§≤‡§æ‡§à ‡§π‡§ø‡§Ç‡§∏‡•ç‡§∞‡§ï, ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§ï ‡§¨‡§®‡§æ‡§â‡§Å‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∞‡§Æ‡§æ‡§à ‡§∞‡§Æ‡§æ‡§à ‡§Æ ‡§§‡§ø‡§®‡•à ‡§õ‡§æ‡§≤ ‡§π‡•á‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•ç‡§¶‡•ã ‡§∞‡§π‡§¶ ‡•§\n",
      "Corrected: ‡§∞‡§Æ‡§æ‡§à ‡§∞‡§Æ‡§æ‡§à ‡§Æ ‡§§‡§ø‡§®‡•à ‡§õ‡§æ‡§≤ ‡§π‡•á‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•ç‡§¶‡•ã ‡§∞‡§π‡•á‡§õ‡•Å ‡•§\n",
      "label:     ‡§∞‡§Æ‡§æ‡§à ‡§∞‡§Æ‡§æ‡§à ‡§Æ ‡§§‡§ø‡§®‡•à ‡§õ‡§æ‡§≤ ‡§π‡•á‡§∞‡•ç‡§® ‡§•‡§æ‡§≤‡•ç‡§¶‡•ã ‡§∞‡§π‡•á‡§õ‡•Å ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§™‡•Ç‡§ú‡§æ ‡§ó‡§∞‡•ç‡§¶‡§æ ‡§≠‡§ó‡§µ‡§æ‡§®‡•ç‡§≤‡§æ‡§à ‡§≠‡•ã‡§ó ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡§¨‡•à ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§â‡§®‡•à‡§≤‡•á ‡§™‡§ï‡§æ‡§á‡§™ ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§™‡•Ç‡§ú‡§æ ‡§ó‡§∞‡•ç‡§¶‡§æ ‡§≠‡§ó‡§µ‡§æ‡§®‡•ç‡§≤‡§æ‡§à ‡§≠‡•ã‡§ó ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡§¨‡•à ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§â‡§®‡•à‡§≤‡•á ‡§™‡§ï‡§æ‡§á‡§¶‡§ø‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "label:     ‡§Ø‡§∏‡•ç‡§§‡•ã ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§™‡•Ç‡§ú‡§æ ‡§ó‡§∞‡•ç‡§¶‡§æ ‡§≠‡§ó‡§µ‡§æ‡§®‡•ç‡§≤‡§æ‡§à ‡§≠‡•ã‡§ó ‡§≤‡§ó‡§æ‡§â‡§®‡•á ‡§∏‡§¨‡•à ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§â‡§®‡•à‡§≤‡•á ‡§™‡§ï‡§æ‡§á‡§¶‡§ø‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§® ‡§™‡§®‡§ø ‡§ó‡§∞‡§ø‡§Ø‡•ã, ‡§∏‡§¨‡•à ‡§ï‡•Å‡§∞‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§®‡§≠‡§è‡§∏‡§Æ‡•ç‡§Æ ‡§ú‡§ó‡•ç‡§ó‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡§æ‡§à ‡§¶‡§ø‡§®‡•ç‡§®‡•å‡§Ç ‡§™‡§®‡§ø ‡§≠‡§®‡•ç‡•å ‡•§\n",
      "Corrected: ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§® ‡§™‡§®‡§ø ‡§ó‡§∞‡§ø‡§Ø‡•ã, ‡§∏‡§¨‡•à ‡§ï‡•Å‡§∞‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§®‡§≠‡§è‡§∏‡§Æ‡•ç‡§Æ ‡§ú‡§ó‡•ç‡§ó‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡§æ‡§à ‡§¶‡§ø‡§®‡•ç‡§®‡•å‡§Ç ‡§™‡§®‡§ø ‡§≠‡§®‡•ç‡§Ø‡•å‡§Ç ‡•§\n",
      "label:     ‡§Ü‡§®‡•ç‡§¶‡•ã‡§≤‡§® ‡§™‡§®‡§ø ‡§ó‡§∞‡§ø‡§Ø‡•ã, ‡§∏‡§¨‡•à ‡§ï‡•Å‡§∞‡§æ ‡§™‡•ç‡§∞‡§∏‡•ç‡§ü ‡§®‡§≠‡§è‡§∏‡§Æ‡•ç‡§Æ ‡§ú‡§ó‡•ç‡§ó‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡§æ‡§à ‡§¶‡§ø‡§®‡•ç‡§®‡•å‡§Ç ‡§™‡§®‡§ø ‡§≠‡§®‡•ç‡§Ø‡•å‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§è‡§®‡§™‡§ø‡§è‡§≤‡§Æ‡§æ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä‡§ï‡•ã ‡§Æ‡•ç‡§Ø‡§æ‡§ö ‡§´‡§ø‡§Æ‡§æ ‡§ö‡§æ‡§∞ ‡§ó‡•Å‡§£‡§æ‡§≤‡•á ‡§¨‡•É‡§¶‡•ç‡§ß‡§ø ‡§≠‡§è‡§ï‡•ã ‡§ú‡•ã‡§π‡§∞‡§æ‡§≤‡•á ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ó‡§∞‡•á‡§ï‡•ã ‡•§\n",
      "Corrected: ‡§è‡§®‡§™‡§ø‡§è‡§≤‡§Æ‡§æ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä‡§ï‡•ã ‡§Æ‡•ç‡§Ø‡§æ‡§ö ‡§´‡§ø‡§Æ‡§æ ‡§ö‡§æ‡§∞ ‡§ó‡•Å‡§£‡§æ‡§≤‡•á ‡§¨‡•É‡§¶‡•ç‡§ß‡§ø ‡§≠‡§è‡§ï‡•ã ‡§ú‡•ã‡§π‡§∞‡§æ‡§≤‡•á ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§è‡§®‡§™‡§ø‡§è‡§≤‡§Æ‡§æ ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ñ‡•á‡§≤‡§æ‡§°‡•Ä‡§ï‡•ã ‡§Æ‡•ç‡§Ø‡§æ‡§ö ‡§´‡§ø‡§Æ‡§æ ‡§ö‡§æ‡§∞ ‡§ó‡•Å‡§£‡§æ‡§≤‡•á ‡§¨‡•É‡§¶‡•ç‡§ß‡§ø ‡§≠‡§è‡§ï‡•ã ‡§ú‡•ã‡§π‡§∞‡§æ‡§≤‡•á ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡•à ‡§µ‡§∞‡•ç‡§∑ ‡§•‡§™ ‡§ó‡§∞‡§ø‡§è‡§ï‡§æ ‡•©‡•Æ ‡§µ‡§ü‡§æ ‡§∏‡§°‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§≠‡§®‡•á ‡§Ø‡§π‡•Ä ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡•ç‡§™ ‡§∞‡§π‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡•à ‡§µ‡§∞‡•ç‡§∑ ‡§•‡§™ ‡§ó‡§∞‡§ø‡§è‡§ï‡§æ ‡•©‡•Æ ‡§µ‡§ü‡§æ ‡§∏‡§°‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§≠‡§®‡•á ‡§Ø‡§π‡•Ä ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§∞‡§π‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§Ø‡§∏‡•à ‡§µ‡§∞‡•ç‡§∑ ‡§•‡§™ ‡§ó‡§∞‡§ø‡§è‡§ï‡§æ ‡•©‡•Æ ‡§µ‡§ü‡§æ ‡§∏‡§°‡§ï ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§≠‡§®‡•á ‡§Ø‡§π‡•Ä ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∏‡§Æ‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§∞‡§π‡•á‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Æ‡§ó‡•ç‡§∞‡§Æ‡§æ, ‡§π‡•ã‡§≤‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ ‡§∞ ‡§Ü‡§®‡§®‡•ç‡§¶‡§ï‡•ã ‡§â‡§§‡•ç‡§∏‡§µ ‡§π‡•ã\n",
      "Corrected: ‡§∏‡§Æ‡§ó‡•ç‡§∞‡§Æ‡§æ, ‡§π‡•ã‡§≤‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ ‡§∞ ‡§Ü‡§®‡§®‡•ç‡§¶‡§ï‡•ã ‡§â‡§§‡•ç‡§∏‡§µ ‡§π‡•ã ‡•§\n",
      "label:     ‡§∏‡§Æ‡§ó‡•ç‡§∞‡§Æ‡§æ, ‡§π‡•ã‡§≤‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ ‡§∞ ‡§Ü‡§®‡§®‡•ç‡§¶‡§ï‡•ã ‡§â‡§§‡•ç‡§∏‡§µ ‡§π‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡•®‡•¶ ‡§∞ ‡•®‡•´ ‡§≤‡§æ‡§ñ‡§∏‡§Æ‡•ç‡§Æ‡§ï‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§≠‡§è‡§® ‡•®‡•¶ ‡§®‡•à ‡§¨‡§®‡§® ‡•§\n",
      "Corrected: ‡•®‡•¶ ‡§∞ ‡•®‡•´ ‡§≤‡§æ‡§ñ‡§∏‡§Æ‡•ç‡§Æ‡§ï‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§≠‡§è‡§® ‡•®‡•¶ ‡§®‡•à ‡§¨‡§®‡§æ‡§â‡§®‡•á ‡•§\n",
      "label:     ‡•®‡•¶ ‡§∞ ‡•®‡•´ ‡§≤‡§æ‡§ñ‡§∏‡§Æ‡•ç‡§Æ‡§ï‡•ã ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§® ‡§≠‡§è‡§® ‡•®‡•¶ ‡§®‡•à ‡§¨‡§®‡§æ‡§â‡§®‡•á ‡•§\n",
      "---\n",
      "Original:  ‡§µ‡§ø‡§ó‡§§ ‡•©‡•¶ ‡§µ‡§∞‡•ç‡§∑‡§∏‡§Æ‡•ç‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§¶‡§ø‡§è‡§™‡§õ‡§ø ‡§ï‡•á‡§è‡§≤‡§è‡§Æ‡§ï‡•ã ‡§Ø‡•ã ‡§µ‡§ø‡§Æ‡§æ‡§®‡§≤‡•á ‡§™‡§Ç‡§ñ‡§æ‡§≤‡§æ‡§à ‡§Ü‡§∞‡§æ‡§Æ ‡§¶‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§µ‡§ø‡§ó‡§§ ‡•©‡•¶ ‡§µ‡§∞‡•ç‡§∑‡§∏‡§Æ‡•ç‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§¶‡§ø‡§è‡§™‡§õ‡§ø ‡§ï‡•á‡§è‡§≤‡§è‡§Æ‡§ï‡•ã ‡§Ø‡•ã ‡§µ‡§ø‡§Æ‡§æ‡§®‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§™‡§Ç‡§ñ‡§æ‡§≤‡§æ‡§à ‡§Ü‡§∞‡§æ‡§Æ ‡§¶‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§µ‡§ø‡§ó‡§§ ‡•©‡•¶ ‡§µ‡§∞‡•ç‡§∑‡§∏‡§Æ‡•ç‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§¶‡§ø‡§è‡§™‡§õ‡§ø ‡§ï‡•á‡§è‡§≤‡§è‡§Æ‡§ï‡•ã ‡§Ø‡•ã ‡§µ‡§ø‡§Æ‡§æ‡§®‡§≤‡•á ‡§Ü‡§´‡•ç‡§®‡•ã ‡§™‡§Ç‡§ñ‡§æ‡§≤‡§æ‡§à ‡§Ü‡§∞‡§æ‡§Æ ‡§¶‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç ‡§ï‡§§‡§æ‡§∞‡§Æ‡§æ : ‡§π‡•Å‡§®‡•á ‡§Ü‡§†‡•å‡§Ç ‡§®‡•á‡§´‡•ç‡§ü‡§æ ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§Ö‡§µ‡§æ‡§∞‡•ç‡§°‡§ï‡§æ ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§™‡§æ‡§Å‡§ö ‡§Æ‡§®‡•ã‡§®‡§Ø‡§® ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§≠‡§è‡§ï‡•ã ‡§õ‡•§\n",
      "Corrected: ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç : ‡§ï‡§§‡§æ‡§∞‡§Æ‡§æ ‡§π‡•Å‡§®‡•á ‡§Ü‡§†‡•å‡§Ç ‡§®‡•á‡§´‡•ç‡§ü‡§æ ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§Ö‡§µ‡§æ‡§∞‡•ç‡§°‡§ï‡§æ ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§™‡§æ‡§Å‡§ö ‡§Æ‡§®‡•ã‡§®‡§Ø‡§® ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§≠‡§è‡§ï‡•ã ‡§õ‡•§\n",
      "label:     ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç : ‡§ï‡§§‡§æ‡§∞‡§Æ‡§æ ‡§π‡•Å‡§®‡•á ‡§Ü‡§†‡•å‡§Ç ‡§®‡•á‡§´‡•ç‡§ü‡§æ ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§Ö‡§µ‡§æ‡§∞‡•ç‡§°‡§ï‡§æ ‡§â‡§§‡•ç‡§ï‡•É‡§∑‡•ç‡§ü ‡§™‡§æ‡§Å‡§ö ‡§Æ‡§®‡•ã‡§®‡§Ø‡§® ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§≠‡§è‡§ï‡•ã ‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä‡§ï‡•ã ‡§Ø‡§∏‡§™‡§ü‡§ï‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§®‡§ø‡§Ø‡§æ‡§≤‡•ç‡§®‡•Å ‡§≠‡§è‡§ï‡•ã ?\n",
      "Corrected: ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä‡§ï‡•ã ‡§Ø‡§∏‡§™‡§ü‡§ï‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§®‡§ø‡§Ø‡§æ‡§≤‡•ç‡§®‡•Å ‡§≠‡§è‡§ï‡•ã ‡§õ ?\n",
      "label:     ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä‡§ï‡•ã ‡§Ø‡§∏‡§™‡§ü‡§ï‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§≤‡§æ‡§à ‡§ï‡§∏‡§∞‡•Ä ‡§®‡§ø‡§Ø‡§æ‡§≤‡•ç‡§®‡•Å ‡§≠‡§è‡§ï‡•ã ‡§õ ?\n",
      "---\n",
      "Original:  ‡§¨‡•à‡§Ç‡§ï‡§∏‡§Å‡§ó ‡§ó‡§∞‡•ç‡§¶‡•à ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡•ç‡§™‡§∞‡•ç‡§ß‡§æ ‡§Æ‡§π‡§Ç‡§ó‡•ã‡§Æ‡§æ ‡§®‡§ø‡§ï‡•ç‡§∑‡•á‡§™ ‡§≤‡§ø‡§®‡•Å‡§™‡§∞‡•á‡§ï‡§æ‡§≤‡•á ‡§∏‡§π‡§ï‡§æ‡§∞‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§ã‡§£‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§æ‡§ú‡§¶‡§∞ ‡§â‡§ö‡•ç‡§ö ‡§π‡•Å‡§®‡•á ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡§π‡§ï‡§æ‡§∞‡•Ä‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: ‡§¨‡•à‡§Ç‡§ï‡§∏‡§Å‡§ó ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡•ç‡§™‡§∞‡•ç‡§ß‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à ‡§Æ‡§π‡§Ç‡§ó‡•ã‡§Æ‡§æ ‡§®‡§ø‡§ï‡•ç‡§∑‡•á‡§™ ‡§≤‡§ø‡§®‡•Å‡§™‡§∞‡•á‡§ï‡§æ‡§≤‡•á ‡§∏‡§π‡§ï‡§æ‡§∞‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§ã‡§£‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§æ‡§ú‡§¶‡§∞ ‡§â‡§ö‡•ç‡§ö ‡§π‡•Å‡§®‡•á ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡§π‡§ï‡§æ‡§∞‡•Ä‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§¨‡•à‡§Ç‡§ï‡§∏‡§Å‡§ó ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡•ç‡§™‡§∞‡•ç‡§ß‡§æ ‡§ó‡§∞‡•ç‡§¶‡•à ‡§Æ‡§π‡§Ç‡§ó‡•ã‡§Æ‡§æ ‡§®‡§ø‡§ï‡•ç‡§∑‡•á‡§™ ‡§≤‡§ø‡§®‡•Å‡§™‡§∞‡•á‡§ï‡§æ‡§≤‡•á ‡§∏‡§π‡§ï‡§æ‡§∞‡•Ä‡§≤‡•á ‡§¶‡§ø‡§®‡•á ‡§ã‡§£‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§æ‡§ú‡§¶‡§∞ ‡§â‡§ö‡•ç‡§ö ‡§π‡•Å‡§®‡•á ‡§ó‡§∞‡•á‡§ï‡•ã ‡§∏‡§π‡§ï‡§æ‡§∞‡•Ä‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§Ü‡§è‡§ï‡•ã ‡§≤‡§ø‡§® ‡§∏‡§≠‡§æ‡§∏‡§¶ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§≠‡§è‡§∞ ‡§¶‡§Æ‡§®‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§® ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§®‡•Å ‡§≤‡§æ‡§ú‡§Æ‡§∞‡•ç‡§¶‡•ã ‡§π‡•ã‡•§\n",
      "Corrected: ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§≤‡§ø‡§® ‡§Ü‡§è‡§ï‡•ã ‡§∏‡§≠‡§æ‡§∏‡§¶ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§≠‡§è‡§∞ ‡§¶‡§Æ‡§®‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§® ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§®‡•Å ‡§≤‡§æ‡§ú‡§Æ‡§∞‡•ç‡§¶‡•ã ‡§π‡•ã‡•§\n",
      "label:     ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§≤‡§ø‡§® ‡§Ü‡§è‡§ï‡•ã ‡§∏‡§≠‡§æ‡§∏‡§¶ ‡§Ü‡§ï‡•ç‡§∞‡•ã‡§∂‡§ø‡§§ ‡§≠‡§è‡§∞ ‡§¶‡§Æ‡§®‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§® ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡§® ‡§¶‡§ø‡§®‡•Å ‡§≤‡§æ‡§ú‡§Æ‡§∞‡•ç‡§¶‡•ã ‡§π‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡•Å‡§∞‡§æ ‡§∞ ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§Ø‡§π‡§ø ‡§¨‡§ø‡§ö‡§æ‡§∞, ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£, ‡§§‡§∞‡§ø‡§ï‡§æ ‡§∞ ‡§§‡§Ø‡§æ‡§∞‡•Ä‡§≤‡•á ‡§∏‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§Ü‡§Ø‡§æ‡§§ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§Ü‡§∏‡•á‡§™‡§æ‡§∏‡•á‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§¨‡§æ‡§Å‡§°‡•á‡§∞ ‡§ñ‡§æ‡§®‡•á ‡§¶‡•á‡§ñ‡§ø‡§®‡•ç‡§õ‡•§\n",
      "Corrected: ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§∞ ‡§ï‡•Å‡§∞‡§æ ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§Ø‡§π‡§ø ‡§¨‡§ø‡§ö‡§æ‡§∞, ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£, ‡§§‡§∞‡§ø‡§ï‡§æ ‡§∞ ‡§§‡§Ø‡§æ‡§∞‡•Ä‡§≤‡•á ‡§∏‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§Ü‡§Ø‡§æ‡§§ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§Ü‡§∏‡•á‡§™‡§æ‡§∏‡•á‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§¨‡§æ‡§Å‡§°‡•á‡§∞ ‡§ñ‡§æ‡§®‡•á ‡§¶‡•á‡§ñ‡§ø‡§®‡•ç‡§õ‡•§\n",
      "label:     ‡§Ö‡§π‡§ø‡§≤‡•á‡§∏‡§Æ‡•ç‡§Æ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§∞ ‡§ï‡•Å‡§∞‡§æ ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§Ø‡§π‡§ø ‡§¨‡§ø‡§ö‡§æ‡§∞, ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£, ‡§§‡§∞‡§ø‡§ï‡§æ ‡§∞ ‡§§‡§Ø‡§æ‡§∞‡•Ä‡§≤‡•á ‡§∏‡§µ‡•É‡§¶‡•ç‡§ß‡§ø ‡§Ü‡§Ø‡§æ‡§§ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§Ü‡§∏‡•á‡§™‡§æ‡§∏‡•á‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§¨‡§æ‡§Å‡§°‡•á‡§∞ ‡§ñ‡§æ‡§®‡•á ‡§¶‡•á‡§ñ‡§ø‡§®‡•ç‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡•ç‡§∞‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡§æ‡§∞‡•Ä, ‡§Ö‡§ó‡•ç‡§∞‡§ó‡§æ‡§Æ‡•Ä ‡§®‡•á‡§§‡§æ ‡§Æ‡§æ‡§®‡•ç‡§® ‡§≠‡§®‡•Ä ‡§π‡§æ‡§Æ‡•Ä‡§≤‡§æ‡§à ‡§∏‡§ø‡§ï‡§æ‡§á‡§®‡•ç‡§õ ‡•§\n",
      "Corrected: ‡§ï‡•ç‡§∞‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡§æ‡§∞‡•Ä, ‡§Ö‡§ó‡•ç‡§∞‡§ó‡§æ‡§Æ‡•Ä ‡§®‡•á‡§§‡§æ ‡§Æ‡§æ‡§®‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•Ä ‡§π‡§æ‡§Æ‡•Ä‡§≤‡§æ‡§à ‡§∏‡§ø‡§ï‡§æ‡§á‡§®‡•ç‡§õ ‡•§\n",
      "label:     ‡§ï‡•ç‡§∞‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡§æ‡§∞‡•Ä, ‡§Ö‡§ó‡•ç‡§∞‡§ó‡§æ‡§Æ‡•Ä ‡§®‡•á‡§§‡§æ ‡§Æ‡§æ‡§®‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•Ä ‡§π‡§æ‡§Æ‡•Ä‡§≤‡§æ‡§à ‡§∏‡§ø‡§ï‡§æ‡§á‡§®‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§¨‡•á‡§™‡§§‡•ç‡§§‡§æ ‡§π‡•Å‡§®‡•Å‡§Æ‡§æ ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ‡§ï‡•ã ‡§™‡§®‡§ø ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§¨‡•Å‡§ù‡§æ‡§á‡§≤‡§æ‡§à ‡§ï‡•á‡§π‡•Ä ‡§™‡•ç‡§∞‡§∑‡•ç‡§ü ‡§™‡§æ‡§∞‡§ø‡§ø ‡§®‡•§\n",
      "Corrected: ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§¨‡•á‡§™‡§§‡•ç‡§§‡§æ ‡§π‡•Å‡§®‡•Å‡§Æ‡§æ ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ‡§ï‡•ã ‡§™‡§®‡§ø ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§¨‡•Å‡§ù‡§æ‡§á‡§≤‡§æ‡§à ‡§ï‡•á‡§π‡•Ä ‡§™‡•ç‡§∞‡§∑‡•ç‡§ü ‡§™‡§æ‡§∞‡§ø‡§¶‡§ø‡§®‡•Å ‡§®‡•§\n",
      "label:     ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï ‡§¨‡•á‡§™‡§§‡•ç‡§§‡§æ ‡§π‡•Å‡§®‡•Å‡§Æ‡§æ ‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø‡§ï ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ‡§ï‡•ã ‡§™‡§®‡§ø ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§¨‡•Å‡§ù‡§æ‡§á‡§≤‡§æ‡§à ‡§ï‡•á‡§π‡•Ä ‡§™‡•ç‡§∞‡§∑‡•ç‡§ü ‡§™‡§æ‡§∞‡§ø‡§¶‡§ø‡§®‡•Å ‡§®‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ‡§ø‡§§ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§®‡•Ä‡§§‡§ø‡§Æ‡§æ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§∏‡§Å‡§ó ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§ó‡§∞‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§§‡§π‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ ‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡§ø‡§®‡•á‡§õ ‡•§\n",
      "Corrected: ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ‡§ø‡§§ ‡§®‡•Ä‡§§‡§ø‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§∏‡§Å‡§ó ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§ó‡§∞‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§§‡§π‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ ‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡§ø‡§®‡•á‡§õ ‡•§\n",
      "label:     ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡§æ‡§µ‡§ø‡§§ ‡§®‡•Ä‡§§‡§ø‡§Æ‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§∏‡§Å‡§ó ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§ó‡§∞‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§§‡§π‡§Æ‡§æ ‡§Ü‡§ß‡§æ‡§∞‡§≠‡•Ç‡§§ ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ ‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞ ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡§ø‡§®‡•á‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§π‡§Æ‡•á‡§Ç ‡§§‡•ã ‡§Ö‡§™‡§®‡•ã‡§Ç ‡§®‡•á ‡§π‡•Ä ‡§≤‡•Å‡§ü‡§æ, ‡§ó‡•à‡§∞‡•ã‡§Ç ‡§ï‡§π‡§æ‡§Å ‡§¶‡§Æ ‡§•‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§ï‡§∂‡•ç‡§§‡•Ä ‡§≠‡•Ä ‡§µ‡§π‡•Ä‡§Å ‡§°‡•Å‡§¨‡•Ä, ‡§ú‡§π‡§æ‡§Å ‡§™‡§æ‡§®‡•Ä ‡§ï‡§Æ ‡§•‡§æ‡•§\n",
      "Corrected: ‡§π‡§Æ‡•á‡§Ç ‡§§‡•ã ‡§Ö‡§™‡§®‡•ã‡§Ç ‡§®‡•á ‡§π‡•Ä ‡§≤‡•Å‡§ü‡§æ, ‡§ó‡•à‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§π‡§æ‡§Å ‡§¶‡§Æ ‡§•‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§ï‡§∂‡•ç‡§§‡•Ä ‡§≠‡•Ä ‡§µ‡§π‡•Ä‡§Å ‡§°‡•Å‡§¨‡•Ä, ‡§ú‡§π‡§æ‡§Å ‡§™‡§æ‡§®‡•Ä ‡§ï‡§Æ ‡§•‡§æ‡•§\n",
      "label:     ‡§π‡§Æ‡•á‡§Ç ‡§§‡•ã ‡§Ö‡§™‡§®‡•ã‡§Ç ‡§®‡•á ‡§π‡•Ä ‡§≤‡•Å‡§ü‡§æ, ‡§ó‡•à‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§π‡§æ‡§Å ‡§¶‡§Æ ‡§•‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§ï‡§∂‡•ç‡§§‡•Ä ‡§≠‡•Ä ‡§µ‡§π‡•Ä‡§Å ‡§°‡•Å‡§¨‡•Ä, ‡§ú‡§π‡§æ‡§Å ‡§™‡§æ‡§®‡•Ä ‡§ï‡§Æ ‡§•‡§æ‡•§\n",
      "---\n",
      "Original:  ‡§ñ‡§æ‡§∏ ‡§¶‡§æ‡§®‡§µ ‡§§‡§ø‡§®‡•Ä‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç, ‡§ú‡§∏‡§≤‡•á ‡§â‡§®‡§≤‡§æ‡§à ‡§¶‡•á‡§µ‡§§‡§æ ‡§µ‡§æ ‡§¶‡§æ‡§®‡§µ ‡§ú‡§∏‡§∞‡•Ä ‡§π‡•á‡§∞‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: ‡§ñ‡§æ‡§∏ ‡§¶‡§æ‡§®‡§µ ‡§§ ‡§§‡§ø‡§®‡•Ä‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç, ‡§ú‡§∏‡§≤‡•á ‡§â‡§®‡§≤‡§æ‡§à ‡§¶‡•á‡§µ‡§§‡§æ ‡§µ‡§æ ‡§¶‡§æ‡§®‡§µ ‡§ú‡§∏‡§∞‡•Ä ‡§π‡•á‡§∞‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§ñ‡§æ‡§∏ ‡§¶‡§æ‡§®‡§µ ‡§§ ‡§§‡§ø‡§®‡•Ä‡§π‡§∞‡•Ç ‡§π‡•Å‡§®‡•ç, ‡§ú‡§∏‡§≤‡•á ‡§â‡§®‡§≤‡§æ‡§à ‡§¶‡•á‡§µ‡§§‡§æ ‡§µ‡§æ ‡§¶‡§æ‡§®‡§µ ‡§ú‡§∏‡§∞‡•Ä ‡§π‡•á‡§∞‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§è‡§ï‡§§‡§æ ‡§≠‡§§‡•ç‡§ï‡§® ‡§ú‡§∏‡•ç‡§§‡•ã‡§∏‡•Å‡§ï‡•à ‡§∑‡§°‡•ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§ñ‡§§‡§∞‡§æ : ‡§™‡•ç‡§∞‡§ö‡§£‡•ç‡§° ‡§ï‡•ã ‡§≤‡§æ‡§ó‡•Ä ‡§ï‡•Å‡§®‡•à ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§õ‡•à‡§® ‡•§\n",
      "Corrected: ‡§è‡§ï‡§§‡§æ ‡§≠‡§§‡•ç‡§ï‡§æ‡§â‡§® ‡§ú‡§∏‡•ç‡§§‡•ã‡§∏‡•Å‡§ï‡•à ‡§∑‡§°‡•ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§ñ‡§§‡§∞‡§æ : ‡§™‡•ç‡§∞‡§ö‡§£‡•ç‡§° ‡§ï‡•ã ‡§≤‡§æ‡§ó‡•Ä ‡§ï‡•Å‡§®‡•à ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§õ‡•à‡§® ‡•§\n",
      "label:     ‡§è‡§ï‡§§‡§æ ‡§≠‡§§‡•ç‡§ï‡§æ‡§â‡§® ‡§ú‡§∏‡•ç‡§§‡•ã‡§∏‡•Å‡§ï‡•à ‡§∑‡§°‡•ç‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§ï‡•ã ‡§ñ‡§§‡§∞‡§æ : ‡§™‡•ç‡§∞‡§ö‡§£‡•ç‡§° ‡§ï‡•ã ‡§≤‡§æ‡§ó‡•Ä ‡§ï‡•Å‡§®‡•à ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§õ‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§Æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡•Å‡§ñ ‡§π‡•Å‡§¶ ‡§Æ‡•à‡§≤‡•á ‡§™‡•Ç‡§∞‡•à ‡§™‡§æ‡§†‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§Å ‡•§\n",
      "Corrected: ‡§Æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡•Å‡§ñ ‡§π‡•Å‡•Å‡§Å‡§¶‡§æ ‡§Æ‡•à‡§≤‡•á ‡§™‡•Ç‡§∞‡•à ‡§™‡§æ‡§†‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§Å ‡•§\n",
      "label:     ‡§Æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡•Å‡§ñ ‡§π‡•Å‡•Å‡§Å‡§¶‡§æ ‡§Æ‡•à‡§≤‡•á ‡§™‡•Ç‡§∞‡•à ‡§™‡§æ‡§†‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§¨‡§®‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§è‡§Å ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§æ‡§´‡§æ‡§Æ‡§æ ‡§ö‡§≤‡•ç‡§®‡•á, ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ß‡•á‡§∞‡•à ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§®‡§ø ‡§ï‡§Æ ‡§π‡•Å‡§®‡•á ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡•á‡§ü‡•ç‡§∞‡•ã‡§∞‡•á‡§≤ ‡§∏‡§û‡•ç‡§ö‡§æ‡§≤‡§® ‡§ó‡§∞‡•ç‡§® ‡§ï‡§§‡•ç‡§§‡§ø ‡§™‡§®‡§ø ‡§¢‡§ø‡§≤‡§æ‡§á ‡•§\n",
      "Corrected: ‡§®‡§æ‡§´‡§æ‡§Æ‡§æ ‡§ö‡§≤‡•ç‡§®‡•á, ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ß‡•á‡§∞‡•à ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§®‡§ø ‡§ï‡§Æ ‡§π‡•Å‡§®‡•á ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡•á‡§ü‡•ç‡§∞‡•ã‡§∞‡•á‡§≤ ‡§∏‡§û‡•ç‡§ö‡§æ‡§≤‡§® ‡§ó‡§∞‡•ç‡§® ‡§ï‡§§‡•ç‡§§‡§ø ‡§™‡§®‡§ø ‡§¢‡§ø‡§≤‡§æ‡§á ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•Å‡§Å‡§¶‡•à‡§® ‡•§\n",
      "label:     ‡§®‡§æ‡§´‡§æ‡§Æ‡§æ ‡§ö‡§≤‡•ç‡§®‡•á, ‡§Ø‡§æ‡§§‡•ç‡§∞‡•Å‡§π‡§∞‡•Ç‡§≤‡§æ‡§à ‡§ß‡•á‡§∞‡•à ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§π‡•Å‡§®‡•á ‡§∞ ‡§™‡•ç‡§∞‡§¶‡•Ç‡§∑‡§£ ‡§™‡§®‡§ø ‡§ï‡§Æ ‡§π‡•Å‡§®‡•á ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡•á‡§ü‡•ç‡§∞‡•ã‡§∞‡•á‡§≤ ‡§∏‡§û‡•ç‡§ö‡§æ‡§≤‡§® ‡§ó‡§∞‡•ç‡§® ‡§ï‡§§‡•ç‡§§‡§ø ‡§™‡§®‡§ø ‡§¢‡§ø‡§≤‡§æ‡§á ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•Å‡§Å‡§¶‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§æ‡§π‡§ø‡§§‡•ç‡§Ø‡§≤‡§æ‡§à ‡§®‡§Ö‡§Å‡§ó‡§æ‡§≤‡•Ä ‡§â‡§®‡•Ä ‡§ú‡§ø‡§â‡§®‡•à ‡§∏‡§ï‡•ç‡•à ‡•§\n",
      "Corrected: ‡§∏‡§æ‡§π‡§ø‡§§‡•ç‡§Ø‡§≤‡§æ‡§à ‡§®‡§Ö‡§Å‡§ó‡§æ‡§≤‡•Ä ‡§â‡§®‡•Ä ‡§ú‡§ø‡§â‡§®‡•à ‡§∏‡§ï‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "label:     ‡§∏‡§æ‡§π‡§ø‡§§‡•ç‡§Ø‡§≤‡§æ‡§à ‡§®‡§Ö‡§Å‡§ó‡§æ‡§≤‡•Ä ‡§â‡§®‡•Ä ‡§ú‡§ø‡§â‡§®‡•à ‡§∏‡§ï‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§°‡•á‡§¢ ‡§á‡§®‡•ç‡§ö ‡§≠‡§®‡•ç‡§¶‡§æ ‡§Ö‡§ó‡•ç‡§≤‡•ã ‡§π‡§æ‡§á ‡§π‡§ø‡§≤ ‡§≤‡§ó‡§æ‡•Å ‡§π‡•Å‡§®‡•ç‡§® ‡•§\n",
      "Corrected: ‡§°‡•á‡§¢ ‡§á‡§®‡•ç‡§ö ‡§≠‡§®‡•ç‡§¶‡§æ ‡§Ö‡§ó‡•ç‡§≤‡•ã ‡§π‡§æ‡§á ‡§π‡§ø‡§≤ ‡§≤‡§ó‡§æ‡§â‡§®‡•Å ‡§π‡•Å‡§®‡•ç‡§® ‡•§\n",
      "label:     ‡§°‡•á‡§¢ ‡§á‡§®‡•ç‡§ö ‡§≠‡§®‡•ç‡§¶‡§æ ‡§Ö‡§ó‡•ç‡§≤‡•ã ‡§π‡§æ‡§á ‡§π‡§ø‡§≤ ‡§≤‡§ó‡§æ‡§â‡§®‡•Å ‡§π‡•Å‡§®‡•ç‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§â‡§ï‡•ç‡§§ ‡§ù‡§°‡§™ ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¶‡§∞‡•ç‡§ú‡§®‡•å‡§Ç ‡§∞‡§æ‡§â‡§®‡•ç‡§° ‡§Ö‡§∂‡•ç‡§∞‡•Å‡§ó‡•ç‡§Ø‡§æ‡§∏ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•á‡§ï‡•ã ‡§á‡§≤‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡•á‡§≤‡•ç‡§ü‡§æ‡§∞‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§≠‡•Ä‡§Æ‡§ï‡§æ‡§®‡•ç‡§§ ‡§∏‡§ø‡§≤‡§µ‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§è?\n",
      "Corrected: ‡§â‡§ï‡•ç‡§§ ‡§ù‡§°‡§™ ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¶‡§∞‡•ç‡§ú‡§®‡•å‡§Ç ‡§∞‡§æ‡§â‡§®‡•ç‡§° ‡§Ö‡§∂‡•ç‡§∞‡•Å‡§ó‡•ç‡§Ø‡§æ‡§∏ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•á‡§ï‡•ã ‡§á‡§≤‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡•á‡§≤‡•ç‡§ü‡§æ‡§∞‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§≠‡•Ä‡§Æ‡§ï‡§æ‡§®‡•ç‡§§ ‡§∏‡§ø‡§≤‡§µ‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "label:     ‡§â‡§ï‡•ç‡§§ ‡§ù‡§°‡§™ ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¶‡§∞‡•ç‡§ú‡§®‡•å‡§Ç ‡§∞‡§æ‡§â‡§®‡•ç‡§° ‡§Ö‡§∂‡•ç‡§∞‡•Å‡§ó‡•ç‡§Ø‡§æ‡§∏ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•á‡§ï‡•ã ‡§á‡§≤‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡•á‡§≤‡•ç‡§ü‡§æ‡§∞‡§ï‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§≠‡•Ä‡§Æ‡§ï‡§æ‡§®‡•ç‡§§ ‡§∏‡§ø‡§≤‡§µ‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§®‡§ø ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø ‡§∏‡§≠‡§æ‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§µ‡§æ‡§ö‡§® ‡§™‡§π‡§ø‡§≤‡§æ ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§â‡§§‡•ç‡§§‡§ø‡§ï‡•à‡•§\n",
      "Corrected: ‡§Ö‡§®‡§ø ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø ‡§∏‡§≠‡§æ‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§µ‡§æ‡§ö‡§® ‡§™‡§π‡§ø‡§≤‡§æ ‡§π‡•Å‡§®‡§∏‡§ï‡•ç‡§®‡•á ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§â‡§§‡•ç‡§§‡§ø‡§ï‡•à‡•§\n",
      "label:     ‡§Ö‡§®‡§ø ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø ‡§∏‡§≠‡§æ‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§µ‡§æ‡§ö‡§® ‡§™‡§π‡§ø‡§≤‡§æ ‡§π‡•Å‡§®‡§∏‡§ï‡•ç‡§®‡•á ‡§∏‡§Æ‡•ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§â‡§§‡•ç‡§§‡§ø‡§ï‡•à‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§°‡§ï ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§ï‡•ã ‡§ï‡§æ‡§Æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§∏‡§ï‡§ø‡§è‡§ï‡•ã ‡§Ø‡•ã‡§ú‡§®‡§æ‡§Æ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∞‡§§ ‡§á‡§û‡•ç‡§ú‡§ø‡§®‡•Ä‡§Ø‡§∞ ‡§®‡•Ä‡§∞‡§û‡•ç‡§ú‡§® ‡§∂‡§∞‡•ç‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§â‡•Å ‡•§\n",
      "Corrected: ‡§∏‡§°‡§ï ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§ï‡•ã ‡§ï‡§æ‡§Æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§∏‡§ï‡§ø‡§è‡§ï‡•ã ‡§Ø‡•ã‡§ú‡§®‡§æ‡§Æ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∞‡§§ ‡§á‡§û‡•ç‡§ú‡§ø‡§®‡•Ä‡§Ø‡§∞ ‡§®‡•Ä‡§∞‡§û‡•ç‡§ú‡§® ‡§∂‡§∞‡•ç‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§â‡§®‡•Å‡§≠‡§Ø‡•ã ‡•§\n",
      "label:     ‡§∏‡§°‡§ï ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£‡§ï‡•ã ‡§ï‡§æ‡§Æ ‡§§‡•ã‡§ï‡§ø‡§è‡§ï‡•ã ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§∏‡§ï‡§ø‡§è‡§ï‡•ã ‡§Ø‡•ã‡§ú‡§®‡§æ‡§Æ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§∞‡§§ ‡§á‡§û‡•ç‡§ú‡§ø‡§®‡•Ä‡§Ø‡§∞ ‡§®‡•Ä‡§∞‡§û‡•ç‡§ú‡§® ‡§∂‡§∞‡•ç‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§¨‡§§‡§æ‡§â‡§®‡•Å‡§≠‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§°‡•Ä‡§™‡•Ä‡§Ü‡§∞ ‡§§‡§Ø‡§æ‡§∞ ‡§≠‡§è‡§™‡§õ‡§ø ‡§¨‡•Å‡§ü ‡§Æ‡•ã‡§°‡•á‡§≤‡§Æ‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡•ã ‡§†‡•á‡§ï‡•ç‡§ï‡§æ ‡§¶‡§ø‡§®‡•á ‡§∏‡•ã‡§ö ‡§∞‡§π‡•á‡§ï‡•ã ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç‡§ï‡§æ ‡§Æ‡•á‡§Ø‡§∞ ‡§∂‡§æ‡§ï‡•ç‡§Ø ‡§¨‡§§‡§æ‡§â‡§õ ‡•§\n",
      "Corrected: ‡§°‡•Ä‡§™‡•Ä‡§Ü‡§∞ ‡§§‡§Ø‡§æ‡§∞ ‡§≠‡§è‡§™‡§õ‡§ø ‡§¨‡•Å‡§ü ‡§Æ‡•ã‡§°‡•á‡§≤‡§Æ‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡•ã ‡§†‡•á‡§ï‡•ç‡§ï‡§æ ‡§¶‡§ø‡§®‡•á ‡§∏‡•ã‡§ö ‡§∞‡§π‡•á‡§ï‡•ã ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç‡§ï‡§æ ‡§Æ‡•á‡§Ø‡§∞ ‡§∂‡§æ‡§ï‡•ç‡§Ø ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§°‡•Ä‡§™‡•Ä‡§Ü‡§∞ ‡§§‡§Ø‡§æ‡§∞ ‡§≠‡§è‡§™‡§õ‡§ø ‡§¨‡•Å‡§ü ‡§Æ‡•ã‡§°‡•á‡§≤‡§Æ‡§æ ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ‡§ï‡•ã ‡§†‡•á‡§ï‡•ç‡§ï‡§æ ‡§¶‡§ø‡§®‡•á ‡§∏‡•ã‡§ö ‡§∞‡§π‡•á‡§ï‡•ã ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç‡§ï‡§æ ‡§Æ‡•á‡§Ø‡§∞ ‡§∂‡§æ‡§ï‡•ç‡§Ø ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ü‡§Å‡§∏‡•Å‡§®‡§≤‡•Ä ‡§¨‡§®‡•ç‡§¶ ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§®‡§ø‡§∏‡•ç‡§ï‡§®‡•á ‡§ó‡§∞‡•ç‡§õ\n",
      "Corrected: ‡§Ü‡§Å‡§∏‡•Å‡§®‡§≤‡•Ä ‡§¨‡§®‡•ç‡§¶ ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§®‡§ø‡§∏‡•ç‡§ï‡§®‡•á ‡§ó‡§∞‡•ç‡§õ ‡•§\n",
      "label:     ‡§Ü‡§Å‡§∏‡•Å‡§®‡§≤‡•Ä ‡§¨‡§®‡•ç‡§¶ ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§Æ‡§æ‡§§‡•ç‡§∞ ‡§Ü‡§Å‡§ñ‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§®‡§ø‡§∏‡•ç‡§ï‡§®‡•á ‡§ó‡§∞‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§§‡§ø‡§∞‡•ã‡§ß‡§æ‡§§‡•ç‡§Æ‡§ï ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§¨‡§¢‡•ç‡§® ‡•§\n",
      "Corrected: ‡§™‡•ç‡§∞‡§§‡§ø‡§∞‡•ã‡§ß‡§æ‡§§‡•ç‡§Æ‡§ï ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§¨‡§¢‡•ç‡§®‡•á‡§õ ‡•§\n",
      "label:     ‡§™‡•ç‡§∞‡§§‡§ø‡§∞‡•ã‡§ß‡§æ‡§§‡•ç‡§Æ‡§ï ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§¨‡§¢‡•ç‡§®‡•á‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡§æ‡§≤‡§≤‡•á ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§£ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡§ø‡§è‡§∏‡§Å‡§ó‡•à ‡§∞‡§æ‡§§‡§ø ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§®‡•à ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "Corrected: ‡§™‡§æ‡§≤‡§≤‡•á ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§£ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡§ø‡§è‡§∏‡§Å‡§ó‡•à ‡§∞‡§æ‡§§‡§ø ‡§®‡•à ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "label:     ‡§™‡§æ‡§≤‡§≤‡•á ‡§Ü‡§ï‡•ç‡§∞‡§Æ‡§£ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡§ø‡§è‡§∏‡§Å‡§ó‡•à ‡§∞‡§æ‡§§‡§ø ‡§®‡•à ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§ï‡§∞‡•ç‡§Æ‡•Ä ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§Æ‡•ç‡§Ø‡•Å‡§®‡§ø‡§∏‡•ç‡§ü‡§ú‡§∏‡•ç‡§§‡•ã ‡§∏‡§§‡•ç‡§§‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§¨‡§∏‡•ç‡§¶‡§æ ‡§Ü‡§§‡§Ç‡§ï ‡§Æ‡§ö‡•ç‡§ö‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§∞ ‡§∞‡•á‡§≤‡§ø‡§ô ‡§≠‡§æ‡§Å‡§ö‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§æ ‡§∞‡§æ‡§ñ‡•ç‡•ç ‡•§\n",
      "Corrected: ‡§ï‡§Æ‡•ç‡§Ø‡•Å‡§®‡§ø‡§∏‡•ç‡§ü‡§ú‡§∏‡•ç‡§§‡•ã ‡§∏‡§§‡•ç‡§§‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§¨‡§∏‡•ç‡§¶‡§æ ‡§Ü‡§§‡§Ç‡§ï ‡§Æ‡§ö‡•ç‡§ö‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§∞ ‡§∞‡•á‡§≤‡§ø‡§ô ‡§≠‡§æ‡§Å‡§ö‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•Å‡§π‡•Å‡§Å‡§¶‡•à‡§® ‡•§\n",
      "label:     ‡§ï‡§Æ‡•ç‡§Ø‡•Å‡§®‡§ø‡§∏‡•ç‡§ü‡§ú‡§∏‡•ç‡§§‡•ã ‡§∏‡§§‡•ç‡§§‡§æ ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§¨‡§∏‡•ç‡§¶‡§æ ‡§Ü‡§§‡§Ç‡§ï ‡§Æ‡§ö‡•ç‡§ö‡§æ‡§â‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§∞ ‡§∞‡•á‡§≤‡§ø‡§ô ‡§≠‡§æ‡§Å‡§ö‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Æ‡§æ‡§®‡•ç‡§Ø‡§§‡§æ ‡§∞‡§æ‡§ñ‡•ç‡§®‡•Å‡§π‡•Å‡§Å‡§¶‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à !\n",
      "Corrected: ‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à ?\n",
      "label:     ‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à ?\n",
      "---\n",
      "Original:  ‡§Ø‡§∏ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§¨‡•Å‡§¨‡§æ ‡§∞ ‡§Ü‡§Æ‡§æ‡§ï‡•ã ‡§®‡§æ‡§è‡§Å‡§Æ‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Æ‡•Ä‡§®‡§æ‡§∞‡§æ‡§Ø‡§£‚Äì‡§™‡•Å‡§®‡§Æ‡§æ‡§Ø‡§æ ‡§∏‡§ø‡§∞‡§™‡§æ (‡§™‡•Å‡§∞‡§∏‡•ç‡§ï‡§æ‡§∞) ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡•á‡§Ç ‡•§\n",
      "Corrected: ‡§Ø‡§∏ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§¨‡•Å‡§¨‡§æ ‡§∞ ‡§Ü‡§Æ‡§æ‡§ï‡•ã ‡§®‡§æ‡§è‡§Å‡§Æ‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Æ‡•Ä‡§®‡§æ‡§∞‡§æ‡§Ø‡§£‚Äì‡§™‡•Å‡§®‡§Æ‡§æ‡§Ø‡§æ ‡§∏‡§ø‡§∞‡§™‡§æ (‡§™‡•Å‡§∞‡§∏‡•ç‡§ï‡§æ‡§∞) ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡•á‡§Ç ‡•§\n",
      "label:     ‡§Ø‡§∏ ‡§ï‡•ç‡§∞‡§Æ‡§Æ‡§æ ‡§Æ‡•á‡§∞‡§æ ‡§¨‡•Å‡§¨‡§æ ‡§∞ ‡§Ü‡§Æ‡§æ‡§ï‡•ã ‡§®‡§æ‡§è‡§Å‡§Æ‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Æ‡•Ä‡§®‡§æ‡§∞‡§æ‡§Ø‡§£‚Äì‡§™‡•Å‡§®‡§Æ‡§æ‡§Ø‡§æ ‡§∏‡§ø‡§∞‡§™‡§æ (‡§™‡•Å‡§∞‡§∏‡•ç‡§ï‡§æ‡§∞) ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡•á‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§≤‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó‡§¶‡•á‡§ñ‡§ø ‡§∂‡§∞‡•Ä‡§∞‡§≤‡§æ‡§à ‡§∏‡§Æ‡•á‡§§ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§´‡§æ‡§á‡§¶‡§æ ‡§™‡•Å¬•‡§Ø‡§æ‡§á‡§∞‡§π‡•á‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: ‡§Ø‡§∏‡§≤‡•á ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§¶‡§ø‡§Æ‡§æ‡§ó‡§¶‡•á‡§ñ‡§ø ‡§∂‡§∞‡•Ä‡§∞‡§≤‡§æ‡§à ‡§∏‡§Æ‡•á‡§§ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§´‡§æ‡§á‡§¶‡§æ ‡§™‡•Å¬•‡§Ø‡§æ‡§á‡§∞‡§π‡•á‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§Ø‡§∏‡§≤‡•á ‡§π‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§¶‡§ø‡§Æ‡§æ‡§ó‡§¶‡•á‡§ñ‡§ø ‡§∂‡§∞‡•Ä‡§∞‡§≤‡§æ‡§à ‡§∏‡§Æ‡•á‡§§ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§´‡§æ‡§á‡§¶‡§æ ‡§™‡•Å¬•‡§Ø‡§æ‡§á‡§∞‡§π‡•á‡§ï‡§æ ‡§π‡•Å‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§§‡•ç‡§§‡§æ‡§ß‡§æ‡§∞‡•Ä‡§π‡§∞‡•Ç ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡•Ä‡§°‡§æ‡§Æ‡§æ ‡§ö‡§ø‡§§‡•ç‡§§ ‡§®‡§¶‡•Å:‡§ñ‡§æ‡§â‡§®‡•á ‡§∞ ‡§∂‡§æ‡§∏‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞‡§¶‡§æ‡§Ø‡•Ä ‡§≠‡§®‡•á ‡§Ö‡§µ‡§ø‡§ï‡§æ‡§∏‡§ï‡•ã ‡§Ö‡§π‡§Æ‡•ç ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ï‡§æ‡§∞‡§£ ‡§§‡§ø‡§®‡•à ‡§¨‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "Corrected: ‡§∏‡§§‡•ç‡§§‡§æ‡§ß‡§æ‡§∞‡•Ä‡§π‡§∞‡•Ç ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡•Ä‡§°‡§æ‡§Æ‡§æ ‡§ö‡§ø‡§§‡•ç‡§§ ‡§®‡§¶‡•Å:‡§ñ‡§æ‡§â‡§®‡•á ‡§∞ ‡§∂‡§æ‡§∏‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞‡§¶‡§æ‡§Ø‡•Ä ‡§≠‡§á‡§¶‡§ø‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Ö‡§µ‡§ø‡§ï‡§æ‡§∏‡§ï‡•ã ‡§Ö‡§π‡§Æ‡•ç ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ï‡§æ‡§∞‡§£ ‡§§‡§ø‡§®‡•à ‡§¨‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§∏‡§§‡•ç‡§§‡§æ‡§ß‡§æ‡§∞‡•Ä‡§π‡§∞‡•Ç ‡§ú‡§®‡§§‡§æ‡§ï‡•ã ‡§™‡•Ä‡§°‡§æ‡§Æ‡§æ ‡§ö‡§ø‡§§‡•ç‡§§ ‡§®‡§¶‡•Å:‡§ñ‡§æ‡§â‡§®‡•á ‡§∞ ‡§∂‡§æ‡§∏‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Ö‡§®‡•Å‡§§‡•ç‡§§‡§∞‡§¶‡§æ‡§Ø‡•Ä ‡§≠‡§á‡§¶‡§ø‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Ö‡§µ‡§ø‡§ï‡§æ‡§∏‡§ï‡•ã ‡§Ö‡§π‡§Æ‡•ç ‡§∞ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ï‡§æ‡§∞‡§£ ‡§§‡§ø‡§®‡•à ‡§¨‡§®‡•ç‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§¶‡•ã‡§∏‡•ç‡§∞‡•ã‡§™‡§≤‡•ç‡§ü ‡§ï‡§æ‡§®‡•ç‡§§‡§ø‡§™‡•Å‡§∞ ‡§π‡§æ‡§´ ‡§Æ‡•ç‡§Ø‡§æ‡§∞‡§æ‡§•‡§® ‡§ö‡•ç‡§Ø‡§æ‡§Æ‡•ç‡§™‡§ø‡§Ø‡§® ‡§¨‡§®‡•ç ‡•§\n",
      "Corrected: ‡§¶‡•ã‡§∏‡•ç‡§∞‡•ã‡§™‡§≤‡•ç‡§ü ‡§ï‡§æ‡§®‡•ç‡§§‡§ø‡§™‡•Å‡§∞ ‡§π‡§æ‡§´ ‡§Æ‡•ç‡§Ø‡§æ‡§∞‡§æ‡§•‡§® ‡§ö‡•ç‡§Ø‡§æ‡§Æ‡•ç‡§™‡§ø‡§Ø‡§® ‡§¨‡§®‡§ø‡§®‡•ç ‡•§\n",
      "label:     ‡§¶‡•ã‡§∏‡•ç‡§∞‡•ã‡§™‡§≤‡•ç‡§ü ‡§ï‡§æ‡§®‡•ç‡§§‡§ø‡§™‡•Å‡§∞ ‡§π‡§æ‡§´ ‡§Æ‡•ç‡§Ø‡§æ‡§∞‡§æ‡§•‡§® ‡§ö‡•ç‡§Ø‡§æ‡§Æ‡•ç‡§™‡§ø‡§Ø‡§® ‡§¨‡§®‡§ø‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§®‡•ç‡§ú‡•Å‡§Æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Æ‡§π‡§Ç‡§ó‡•ã ‡§≠‡§è‡§™‡§õ‡§ø ‡§ß‡•á‡§∞‡•à‡§≤‡•á ‡§§ ‡§ï‡§ø‡§®‡•ç‡§® ‡•§\n",
      "Corrected: ‡§ï‡§®‡•ç‡§ú‡•Å‡§Æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Æ‡§π‡§Ç‡§ó‡•ã ‡§≠‡§è‡§™‡§õ‡§ø ‡§ß‡•á‡§∞‡•à‡§≤‡•á ‡§§ ‡§ï‡§ø‡§®‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "label:     ‡§ï‡§®‡•ç‡§ú‡•Å‡§Æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§‡§ø‡§≤‡§æ‡§à ‡§π‡•á‡§∞‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡§≠‡§®‡•á ‡§Æ‡§π‡§Ç‡§ó‡•ã ‡§≠‡§è‡§™‡§õ‡§ø ‡§ß‡•á‡§∞‡•à‡§≤‡•á ‡§§ ‡§ï‡§ø‡§®‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ö‡§π‡§ø‡§≤‡•á‡§ï‡•ã ‡§Ü‡§â‡§Å‡§õ ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§≠‡§®‡•ç‡§®‡•á ‡§Ü‡§∂‡§æ ‡§õ ‡•§\n",
      "Corrected: ‡§Ö‡§π‡§ø‡§≤‡•á‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§Ü‡§â‡§Å‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Ü‡§∂‡§æ ‡§õ ‡•§\n",
      "label:     ‡§Ö‡§π‡§ø‡§≤‡•á‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§µ‡•á‡§¶‡§® ‡§Ü‡§â‡§Å‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§Ü‡§∂‡§æ ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç, (‡§®‡•á‡§∏) ‡§è‡§®‡§∏‡•á‡§≤‡§ï‡§æ ‡§®‡•á‡§™‡§æ‡§≤‡§¨‡§æ‡§π‡§ø‡§∞ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡§≤‡•á ‡§∞‡§π‡•á‡§ï‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§§‡§•‡§æ ‡§∏‡§æ‡§•‡•Ä‡§≠‡§æ‡§à‡§∏‡§Å‡§ó ‡§Ö‡§¨ ‡§Ö‡§ù ‡§∏‡•Å‡§≤‡§≠ ‡§¶‡§∞‡§Æ‡§æ ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "Corrected: ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç, (‡§®‡•á‡§∏) ‡§è‡§®‡§∏‡•á‡§≤‡§ï‡§æ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§¨‡§æ‡§π‡§ø‡§∞ ‡§∞‡§π‡•á‡§ï‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§§‡§•‡§æ ‡§∏‡§æ‡§•‡•Ä‡§≠‡§æ‡§à‡§∏‡§Å‡§ó ‡§Ö‡§¨ ‡§Ö‡§ù ‡§∏‡•Å‡§≤‡§≠ ‡§¶‡§∞‡§Æ‡§æ ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "label:     ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç, (‡§®‡•á‡§∏) ‡§è‡§®‡§∏‡•á‡§≤‡§ï‡§æ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡§≤‡•á ‡§®‡•á‡§™‡§æ‡§≤‡§¨‡§æ‡§π‡§ø‡§∞ ‡§∞‡§π‡•á‡§ï‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§§‡§•‡§æ ‡§∏‡§æ‡§•‡•Ä‡§≠‡§æ‡§à‡§∏‡§Å‡§ó ‡§Ö‡§¨ ‡§Ö‡§ù ‡§∏‡•Å‡§≤‡§≠ ‡§¶‡§∞‡§Æ‡§æ ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§®‡•á‡§õ‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡§æ‡§®‡§ø‡§∏‡§ï‡•ã ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§≤‡§æ‡§à ‡§ß‡•ç‡§Ø‡§æ‡§®‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•á‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§¶‡§ø‡§∞‡§æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§∞ ‡§â‡§™‡§≠‡•ã‡§ó‡§≤‡§æ‡§à ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¨‡•á‡§≤‡§æ ‡§¨‡•á‡§≤‡§æ‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§®‡§ø‡§Ø‡§Æ‡§π‡§∞‡•Å ‡§Ü‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§Æ‡§æ‡§®‡§ø‡§∏‡§ï‡•ã ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§≤‡§æ‡§à ‡§ß‡•ç‡§Ø‡§æ‡§®‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•á‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§¶‡§ø‡§∞‡§æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§∞ ‡§â‡§™‡§≠‡•ã‡§ó‡§≤‡§æ‡§à ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¨‡•á‡§≤‡§æ ‡§¨‡•á‡§≤‡§æ‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§®‡§ø‡§Ø‡§Æ‡§π‡§∞‡•Å ‡§≤‡§ó‡§æ‡§â‡§Å‡§¶‡•à ‡§Ü‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§Æ‡§æ‡§®‡§ø‡§∏‡§ï‡•ã ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø‡§≤‡§æ‡§à ‡§ß‡•ç‡§Ø‡§æ‡§®‡§Æ‡§æ ‡§∞‡§æ‡§ñ‡•á‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Æ‡§¶‡§ø‡§∞‡§æ‡§ï‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§∞ ‡§â‡§™‡§≠‡•ã‡§ó‡§≤‡§æ‡§à ‡§®‡§ø‡§Ø‡§®‡•ç‡§§‡•ç‡§∞‡§£ ‡§ó‡§∞‡•ç‡§® ‡§¨‡•á‡§≤‡§æ ‡§¨‡•á‡§≤‡§æ‡§Æ‡§æ ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§®‡§ø‡§Ø‡§Æ‡§π‡§∞‡•Å ‡§≤‡§ó‡§æ‡§â‡§Å‡§¶‡•à ‡§Ü‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§∏‡§≠‡§æ‡§Æ‡§æ ‡§π‡§æ‡§Æ‡•Ä ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§≤‡•á‡§ñ‡§®‡§ï‡§æ ‡§è‡§ú‡•á‡§£‡•ç‡§°‡§æ‡§Æ‡•à ‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§ ‡•§\n",
      "Corrected: ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§∏‡§≠‡§æ‡§Æ‡§æ ‡§π‡§æ‡§Æ‡•Ä ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§≤‡•á‡§ñ‡§®‡§ï‡§æ ‡§è‡§ú‡•á‡§£‡•ç‡§°‡§æ‡§Æ‡•à ‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§ ‡§π‡•Å‡§®‡•ç‡§•‡•ç‡§Ø‡•å‡§Ç ‡•§\n",
      "label:     ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§®‡§∏‡§≠‡§æ‡§Æ‡§æ ‡§π‡§æ‡§Æ‡•Ä ‡§∏‡§Ç‡§µ‡§ø‡§ß‡§æ‡§® ‡§≤‡•á‡§ñ‡§®‡§ï‡§æ ‡§è‡§ú‡•á‡§£‡•ç‡§°‡§æ‡§Æ‡•à ‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§ ‡§π‡•Å‡§®‡•ç‡§•‡•ç‡§Ø‡•å‡§Ç ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§π‡§ø‡§∞‡§æ‡§¶‡•á‡§µ‡•Ä ‡§™‡•å‡§°‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§ó‡•ç‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§≠‡§æ‡§â ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï ‡§¨‡§®‡§™ ‡§™‡§ü‡§ï ‡§™‡§ü‡§ï ‡§™‡§π‡§≤ ‡§ó‡§∞‡•á ‡§™‡§®‡§ø ‡§¨‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä‡§≤‡•á ‡§Ö‡§ü‡•á‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§á‡§®‡•ç ‡•§\n",
      "Corrected: ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§π‡§ø‡§∞‡§æ‡§¶‡•á‡§µ‡•Ä ‡§™‡•å‡§°‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§ó‡•ç‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§≠‡§æ‡§â ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï ‡§¨‡§®‡§æ‡§â‡§® ‡§™‡§ü‡§ï ‡§™‡§ü‡§ï ‡§™‡§π‡§≤ ‡§ó‡§∞‡•á ‡§™‡§®‡§ø ‡§¨‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä‡§≤‡•á ‡§Ö‡§ü‡•á‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§á‡§®‡•ç ‡•§\n",
      "label:     ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ú‡§ø‡§≤‡•ç‡§≤‡§æ ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞‡•Ä ‡§π‡§ø‡§∞‡§æ‡§¶‡•á‡§µ‡•Ä ‡§™‡•å‡§°‡•ç‡§Ø‡§æ‡§≤‡§≤‡•á ‡§ó‡•ç‡§Ø‡§æ‡§∏‡§ï‡•ã ‡§≠‡§æ‡§â ‡§µ‡•à‡§ú‡•ç‡§û‡§æ‡§®‡§ø‡§ï ‡§¨‡§®‡§æ‡§â‡§® ‡§™‡§ü‡§ï ‡§™‡§ü‡§ï ‡§™‡§π‡§≤ ‡§ó‡§∞‡•á ‡§™‡§®‡§ø ‡§¨‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞‡•Ä‡§≤‡•á ‡§Ö‡§ü‡•á‡§∞ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§á‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§§‡§∞, ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä ‡§ó‡§∞‡•ç‡§®‡•á ‡§∏‡§Æ‡•Ç‡§π‡§≤‡•á ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§§‡§∞‡§ø‡§ï‡§æ ‡§Ö‡§™‡§®‡§æ‡§è‡§∞ ‡§∏‡•Å‡§® ‡§≠‡§ø‡§§‡•ç‡§∞‡§â ‡§ï‡•ç‡§∞‡§Æ ‡§Ö‡§ù‡•à ‡§ú‡§æ‡§∞‡•Ä ‡§õ ‡•§\n",
      "Corrected: ‡§§‡§∞, ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä ‡§ó‡§∞‡•ç‡§®‡•á ‡§∏‡§Æ‡•Ç‡§π‡§≤‡•á ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§§‡§∞‡§ø‡§ï‡§æ ‡§Ö‡§™‡§®‡§æ‡§è‡§∞ ‡§∏‡•Å‡§® ‡§≠‡§ø‡§§‡•ç‡§∞‡•ç‡§Ø‡§æ‡§â‡§®‡•á ‡§ï‡•ç‡§∞‡§Æ ‡§Ö‡§ù‡•à ‡§ú‡§æ‡§∞‡•Ä ‡§õ ‡•§\n",
      "label:     ‡§§‡§∞, ‡§§‡§∏‡•ç‡§ï‡§∞‡•Ä ‡§ó‡§∞‡•ç‡§®‡•á ‡§∏‡§Æ‡•Ç‡§π‡§≤‡•á ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§§‡§∞‡§ø‡§ï‡§æ ‡§Ö‡§™‡§®‡§æ‡§è‡§∞ ‡§∏‡•Å‡§® ‡§≠‡§ø‡§§‡•ç‡§∞‡•ç‡§Ø‡§æ‡§â‡§®‡•á ‡§ï‡•ç‡§∞‡§Æ ‡§Ö‡§ù‡•à ‡§ú‡§æ‡§∞‡•Ä ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§∏‡§Ç‡§ò ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡§∞‡§ø‡§∑‡§¶‡§Æ‡§æ ‡§Ø‡•ã ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§â‡§†‡§æ‡§â‡§® ‡§Ö‡§µ‡§∂‡•ç‡§Ø ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§§‡§∞ ‡§ö‡•Ä‡§®‡§≤‡•á ‡§≠‡§ø‡§ü‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡§ø‡§¶‡§ø‡§®‡•á ‡•§\n",
      "Corrected: ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§∏‡§Ç‡§ò ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡§∞‡§ø‡§∑‡§¶‡§Æ‡§æ ‡§Ø‡•ã ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§â‡§†‡§æ‡§â‡§® ‡§Ö‡§µ‡§∂‡•ç‡§Ø ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§§‡§∞ ‡§ö‡•Ä‡§®‡§≤‡•á ‡§≠‡§ø‡§ü‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡§ø‡§¶‡§ø‡§®‡•á ‡§õ ‡•§\n",
      "label:     ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§∏‡§Ç‡§ò ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡§∞‡§ø‡§∑‡§¶‡§Æ‡§æ ‡§Ø‡•ã ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§â‡§†‡§æ‡§â‡§® ‡§Ö‡§µ‡§∂‡•ç‡§Ø ‡§∏‡§ï‡§ø‡§®‡•ç‡§õ ‡§§‡§∞ ‡§ö‡•Ä‡§®‡§≤‡•á ‡§≠‡§ø‡§ü‡•ã ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡§ø‡§¶‡§ø‡§®‡•á ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§ø‡§∞‡•ç‡§Æ‡§≤‡§æ ‡§™‡§®‡•ç‡§§‡§ï‡§æ ‡§¨‡§≤‡§æ‡§§‡•ç‡§ï‡§æ‡§∞‡•Ä‚Äì‡§π‡§§‡•ç‡§Ø‡§æ‡§∞‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§≤‡§æ‡§à ‡§Ø‡§∏‡•à ‡§∏‡•á‡§∞‡•ã‡§´‡•á‡§∞‡§æ‡§Æ‡§æ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•Ä‡§§ ‡§ó‡§∞‡•á‡§™‡§®‡§ø ‡§Ö‡§™‡§∞‡§æ‡§ß‡•Ä ‡§≠‡•á‡§ü‡§ø‡§®‡•á ‡§Ü‡§Æ‡§¨‡•Å‡§ù‡§æ‡§á ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§®‡§ø‡§∞‡•ç‡§Æ‡§≤‡§æ ‡§™‡§®‡•ç‡§§‡§ï‡§æ ‡§¨‡§≤‡§æ‡§§‡•ç‡§ï‡§æ‡§∞‡•Ä‚Äì‡§π‡§§‡•ç‡§Ø‡§æ‡§∞‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§≤‡§æ‡§à ‡§Ø‡§∏‡•à ‡§∏‡•á‡§∞‡•ã‡§´‡•á‡§∞‡§æ‡§Æ‡§æ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•Ä‡§§ ‡§ó‡§∞‡•á‡§™‡§®‡§ø ‡§Ö‡§™‡§∞‡§æ‡§ß‡•Ä ‡§≠‡•á‡§ü‡§ø‡§®‡•á ‡§Ü‡§Æ‡§¨‡•Å‡§ù‡§æ‡§á ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§®‡§ø‡§∞‡•ç‡§Æ‡§≤‡§æ ‡§™‡§®‡•ç‡§§‡§ï‡§æ ‡§¨‡§≤‡§æ‡§§‡•ç‡§ï‡§æ‡§∞‡•Ä‚Äì‡§π‡§§‡•ç‡§Ø‡§æ‡§∞‡§æ ‡§ñ‡•ã‡§ú‡•ç‡§®‡•á ‡§µ‡§ø‡§∑‡§Ø‡§≤‡§æ‡§à ‡§Ø‡§∏‡•à ‡§∏‡•á‡§∞‡•ã‡§´‡•á‡§∞‡§æ‡§Æ‡§æ ‡§ï‡•á‡§®‡•ç‡§¶‡•ç‡§∞‡•Ä‡§§ ‡§ó‡§∞‡•á‡§™‡§®‡§ø ‡§Ö‡§™‡§∞‡§æ‡§ß‡•Ä ‡§≠‡•á‡§ü‡§ø‡§®‡•á ‡§Ü‡§Æ‡§¨‡•Å‡§ù‡§æ‡§á ‡§¨‡§®‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡•ã‡§π‡•Ä ‡§ï‡§∏‡•à‡§≤‡•á ‡§ö‡§æ‡§π‡§Å‡§¶‡•à‡§Æ‡§æ ‡§ï‡§æ‡§≤‡•Ä‡§ó‡§£‡•ç‡§°‡§ï‡•Ä‡§ï‡•ã ‡§°‡§æ‡§á‡§≠‡§∞‡•ç‡§∏‡§® ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§® ‡§Ö‡§∞‡•ç‡§•‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§ó‡•Å‡§∞‡•Å‡§ô‡§≤‡•á ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä ‡§¶‡§ø‡§è ‡•§\n",
      "Corrected: ‡§ï‡•ã‡§π‡•Ä ‡§ï‡§∏‡•à‡§≤‡•á ‡§ö‡§æ‡§π‡§Å‡§¶‡•à‡§Æ‡§æ ‡§ï‡§æ‡§≤‡•Ä‡§ó‡§£‡•ç‡§°‡§ï‡•Ä‡§ï‡•ã ‡§°‡§æ‡§á‡§≠‡§∞‡•ç‡§∏‡§® ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§® ‡§Ö‡§∞‡•ç‡§•‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§ó‡•Å‡§∞‡•Å‡§ô‡§≤‡•á ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä ‡§¶‡§ø‡§è ‡•§\n",
      "label:     ‡§ï‡•ã‡§π‡•Ä ‡§ï‡§∏‡•à‡§≤‡•á ‡§ö‡§æ‡§π‡§Å‡§¶‡•à‡§Æ‡§æ ‡§ï‡§æ‡§≤‡•Ä‡§ó‡§£‡•ç‡§°‡§ï‡•Ä‡§ï‡•ã ‡§°‡§æ‡§á‡§≠‡§∞‡•ç‡§∏‡§® ‡§π‡•Å‡§®‡•ç‡§õ ‡§≠‡§®‡•ç‡§® ‡§®‡§∏‡•ã‡§ö‡•ç‡§® ‡§Ö‡§∞‡•ç‡§•‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä ‡§ó‡•Å‡§∞‡•Å‡§ô‡§≤‡•á ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä ‡§¶‡§ø‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§≠‡§æ‡§∑‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§™‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•á‡§≤‡•á ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ‡§≤‡•á ‡§ö‡§Ø‡§® ‡§®‡§ó‡§∞‡•á ‡§™‡•Å‡§®‡§É ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§∏‡§π‡§≠‡§æ‡§ó‡•Ä ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ?\n",
      "Corrected: ‡§≠‡§æ‡§∑‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§™‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•á‡§≤‡•á ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ‡§≤‡•á ‡§ö‡§Ø‡§® ‡§®‡§ó‡§∞‡•á ‡§™‡•Å‡§®‡§É ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§∏‡§π‡§≠‡§æ‡§ó‡•Ä ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "label:     ‡§≠‡§æ‡§∑‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§™‡§æ‡§∏ ‡§ó‡§∞‡•ç‡§®‡•á‡§≤‡•á ‡§¶‡•Å‡§à ‡§µ‡§∞‡•ç‡§∑‡§≠‡§ø‡§§‡•ç‡§∞ ‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡§¶‡§æ‡§§‡§æ‡§≤‡•á ‡§ö‡§Ø‡§® ‡§®‡§ó‡§∞‡•á ‡§™‡•Å‡§®‡§É ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§∏‡§π‡§≠‡§æ‡§ó‡•Ä ‡§π‡•Å‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§æ‡§ó‡§æ‡§µ‡§≤‡•ç‡§∞‡•ç‡§°‡§∏‡§Å‡§ó ‡§•‡•ç‡§∞‡§ø‡§∏‡•ç‡§ü‡§æ‡§∞‡§≤‡•á ‡•ß‚Äì‡•ß ‡§ó‡•ã‡§≤‡§ï‡•ã ‡§¨‡§∞‡§æ‡§¨‡§∞‡•Ä ‡§ñ‡•á‡§≤‡•ç‡§¶‡§æ ‡§™‡§®‡§ø ‡§Æ‡§æ‡§∞‡•ç‡§ü‡§ø‡§®‡•ç‡§∏‡§≤‡•á ‡§®‡•à ‡§è‡§ï ‡§ó‡•ã‡§≤ ‡§´‡§∞‡•ç‡§ï‡§∞ ‡§π‡§æ‡§∞‡§¨‡§æ‡§ü ‡§ú‡•ã‡§ó‡§æ‡§è‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "Corrected: ‡§®‡§æ‡§ó‡§æ‡§µ‡§≤‡•ç‡§∞‡•ç‡§°‡§∏‡§Å‡§ó ‡§•‡•ç‡§∞‡§ø‡§∏‡•ç‡§ü‡§æ‡§∞‡§≤‡•á ‡•ß‚Äì‡•ß ‡§ó‡•ã‡§≤‡§ï‡•ã ‡§¨‡§∞‡§æ‡§¨‡§∞‡•Ä ‡§ñ‡•á‡§≤‡•ç‡§¶‡§æ ‡§™‡§®‡§ø ‡§Æ‡§æ‡§∞‡•ç‡§ü‡§ø‡§®‡•ç‡§∏‡§≤‡•á ‡§®‡•à ‡§è‡§ï ‡§ó‡•ã‡§≤ ‡§´‡§∞‡•ç‡§ï‡§æ‡§è‡§∞ ‡§π‡§æ‡§∞‡§¨‡§æ‡§ü ‡§ú‡•ã‡§ó‡§æ‡§è‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "label:     ‡§®‡§æ‡§ó‡§æ‡§µ‡§≤‡•ç‡§∞‡•ç‡§°‡§∏‡§Å‡§ó ‡§•‡•ç‡§∞‡§ø‡§∏‡•ç‡§ü‡§æ‡§∞‡§≤‡•á ‡•ß‚Äì‡•ß ‡§ó‡•ã‡§≤‡§ï‡•ã ‡§¨‡§∞‡§æ‡§¨‡§∞‡•Ä ‡§ñ‡•á‡§≤‡•ç‡§¶‡§æ ‡§™‡§®‡§ø ‡§Æ‡§æ‡§∞‡•ç‡§ü‡§ø‡§®‡•ç‡§∏‡§≤‡•á ‡§®‡•à ‡§è‡§ï ‡§ó‡•ã‡§≤ ‡§´‡§∞‡•ç‡§ï‡§æ‡§è‡§∞ ‡§π‡§æ‡§∞‡§¨‡§æ‡§ü ‡§ú‡•ã‡§ó‡§æ‡§è‡§ï‡§æ ‡§•‡§ø‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡•Å‡§≤‡•Å‡§ï ‡§Ö‡§π‡§ø‡§≤‡•á ‡§è‡§ï‡§¶‡§Æ‡•à ‡§∏‡§Ç‡§ó‡•Ä‡§® ‡§ò‡§°‡•Ä‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§∞ ‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‚Äì‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‡§ï‡•ã ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§Æ‡•Å‡§≤‡•Å‡§ï ‡§Ö‡§π‡§ø‡§≤‡•á ‡§è‡§ï‡§¶‡§Æ‡•à ‡§∏‡§Ç‡§ó‡•Ä‡§® ‡§ò‡§°‡•Ä‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡§∞ ‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‚Äì‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‡§ï‡•ã ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§Æ‡•Å‡§≤‡•Å‡§ï ‡§Ö‡§π‡§ø‡§≤‡•á ‡§è‡§ï‡§¶‡§Æ‡•à ‡§∏‡§Ç‡§ó‡•Ä‡§® ‡§ò‡§°‡•Ä‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡§∞ ‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‚Äì‡§∏‡•á‡§ï‡•á‡§£‡•ç‡§°‡§ï‡•ã ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§∂‡§æ‡§≤‡•Ä ‡§Æ‡§æ‡§®‡§ø‡§®‡•á ‡§Ø‡•Å‡§µ‡§æ ‡§∞ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä ‡§∏‡§Ç‡§ó‡§†‡§®‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§è‡§Æ‡§æ‡§≤‡•á‡§≤‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§ï‡•ã ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ ‡§≤‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "Corrected: ‡§∏‡§¨‡•à‡§≠‡§®‡•ç‡§¶‡§æ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§∂‡§æ‡§≤‡•Ä ‡§Æ‡§æ‡§®‡§ø‡§®‡•á ‡§Ø‡•Å‡§µ‡§æ ‡§∞ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä ‡§∏‡§Ç‡§ó‡§†‡§®‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§è‡§Æ‡§æ‡§≤‡•á‡§≤‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§ï‡•ã ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ ‡§≤‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§∏‡§¨‡•à‡§≠‡§®‡•ç‡§¶‡§æ ‡§™‡•ç‡§∞‡§≠‡§æ‡§µ‡§∂‡§æ‡§≤‡•Ä ‡§Æ‡§æ‡§®‡§ø‡§®‡•á ‡§Ø‡•Å‡§µ‡§æ ‡§∞ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä ‡§∏‡§Ç‡§ó‡§†‡§®‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§è‡§Æ‡§æ‡§≤‡•á‡§≤‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§ï‡•ã ‡§®‡•á‡§§‡•É‡§§‡•ç‡§µ ‡§≤‡§ø‡§®‡•á ‡§≠‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§è‡§â‡§ü‡•à ‡§µ‡§°‡§æ‡§¨‡§æ‡§ü ‡§ï‡§∞‡§ø‡§¨ ‡•¨‡•¶ ‡§¶‡•á‡§ñ‡•Ä ‡•Æ‡•¶ ‡§ï‡§ø‡§≤‡•ã ‡§Æ‡§æ‡§∏‡•Å‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§°‡§∞ ‡§Ü‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§∏‡§Æ‡§æ‡§®‡•Ä‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "Corrected: ‡§è‡§â‡§ü‡•à ‡§µ‡§°‡§æ‡§¨‡§æ‡§ü ‡§ï‡§∞‡§ø‡§¨ ‡•¨‡•¶ ‡§¶‡•á‡§ñ‡§ø ‡•Æ‡•¶ ‡§ï‡§ø‡§≤‡•ã ‡§Æ‡§æ‡§∏‡•Å‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§°‡§∞ ‡§Ü‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§∏‡§Æ‡§æ‡§®‡•Ä‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "label:     ‡§è‡§â‡§ü‡•à ‡§µ‡§°‡§æ‡§¨‡§æ‡§ü ‡§ï‡§∞‡§ø‡§¨ ‡•¨‡•¶ ‡§¶‡•á‡§ñ‡§ø ‡•Æ‡•¶ ‡§ï‡§ø‡§≤‡•ã ‡§Æ‡§æ‡§∏‡•Å‡§ï‡•ã ‡§Ö‡§∞‡•ç‡§°‡§∞ ‡§Ü‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§∏‡§Æ‡§æ‡§®‡•Ä‡§≤‡•á ‡§¨‡§§‡§æ‡§è‡•§\n",
      "---\n",
      "Original:  ‡§¨‡§≤‡§ø‡§ô‡§Æ‡§æ ‡§∏‡•Å‡§∂‡§® ‡§™‡•ã‡§ñ‡§∞‡§æ‡§ï‡§æ ‡§≠‡§æ‡§∞‡•Ä ‡§∞ ‡§™‡§â‡§≤ ‡§ï‡§ò‡§≤‡§ø‡§®‡§≤‡•á ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞‡§ï‡§æ ‡§∏‡§®‡•ç‡§¶‡•Ä‡§™ ‡§≤‡§æ‡§Æ‡§ø‡§õ‡§æ‡§®‡•á ‡§∏‡§Æ‡§æ‡§® ‡•´ ‡§µ‡§ø‡§ï‡•á‡§ü ‡§≤‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "Corrected: ‡§¨‡§≤‡§ø‡§ô‡§Æ‡§æ ‡§™‡•ã‡§ñ‡§∞‡§æ‡§ï‡§æ ‡§∏‡•Å‡§∂‡§® ‡§≠‡§æ‡§∞‡•Ä ‡§∞ ‡§™‡§â‡§≤ ‡§ï‡§ò‡§≤‡§ø‡§®‡§≤‡•á ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞‡§ï‡§æ ‡§∏‡§®‡•ç‡§¶‡•Ä‡§™ ‡§≤‡§æ‡§Æ‡§ø‡§õ‡§æ‡§®‡•á ‡§∏‡§Æ‡§æ‡§® ‡•´ ‡§µ‡§ø‡§ï‡•á‡§ü ‡§≤‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "label:     ‡§¨‡§≤‡§ø‡§ô‡§Æ‡§æ ‡§™‡•ã‡§ñ‡§∞‡§æ‡§ï‡§æ ‡§∏‡•Å‡§∂‡§® ‡§≠‡§æ‡§∞‡•Ä ‡§∞ ‡§™‡§â‡§≤ ‡§ï‡§ò‡§≤‡§ø‡§®‡§≤‡•á ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞‡§ï‡§æ ‡§∏‡§®‡•ç‡§¶‡•Ä‡§™ ‡§≤‡§æ‡§Æ‡§ø‡§õ‡§æ‡§®‡•á ‡§∏‡§Æ‡§æ‡§® ‡•´ ‡§µ‡§ø‡§ï‡•á‡§ü ‡§≤‡§ø‡§è‡§ï‡§æ ‡§õ‡§®‡•ç‡•§\n",
      "---\n",
      "Original:  ‡§ò‡§ü‡§®‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑‡§¶‡§∞‡•ç‡§∂‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡•Å‡§Æ‡§æ‡§∞‡§ï‡§æ‡§∏‡§æ‡§•‡•Ä ‡§ú‡§Ø‡§ï‡§æ‡§®‡•ç‡§§ ‡§â‡§®‡•Ä ‡§®‡§Æ‡•ç‡§∞, ‡§¨‡§æ‡§Å‡§°‡•Ä‡§ö‡•Å‡§Å‡§°‡•Ä ‡§ñ‡§æ‡§®‡•á ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§®‡§¨‡•ã‡§≤‡•ç‡§®‡•á ‡§ñ‡§æ‡§≤‡§ï‡•ã ‡§≠‡§è‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å ‡•§\n",
      "Corrected: ‡§ò‡§ü‡§®‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑‡§¶‡§∞‡•ç‡§∂‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡•Å‡§Æ‡§æ‡§∞‡§ï‡§æ‡§∏‡§æ‡§•‡•Ä ‡§ú‡§Ø‡§ï‡§æ‡§®‡•ç‡§§ ‡§â‡§®‡•Ä ‡§®‡§Æ‡•ç‡§∞, ‡§¨‡§æ‡§Å‡§°‡•Ä‡§ö‡•Å‡§Å‡§°‡•Ä ‡§ñ‡§æ‡§®‡•á ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§®‡§¨‡•ã‡§≤‡•ç‡§®‡•á ‡§ñ‡§æ‡§≤‡§ï‡•ã ‡§≠‡§è‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "label:     ‡§ò‡§ü‡§®‡§æ‡§ï‡§æ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑‡§¶‡§∞‡•ç‡§∂‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡•Å‡§Æ‡§æ‡§∞‡§ï‡§æ‡§∏‡§æ‡§•‡•Ä ‡§ú‡§Ø‡§ï‡§æ‡§®‡•ç‡§§ ‡§â‡§®‡•Ä ‡§®‡§Æ‡•ç‡§∞, ‡§¨‡§æ‡§Å‡§°‡•Ä‡§ö‡•Å‡§Å‡§°‡•Ä ‡§ñ‡§æ‡§®‡•á ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§®‡§¨‡•ã‡§≤‡•ç‡§®‡•á ‡§ñ‡§æ‡§≤‡§ï‡•ã ‡§≠‡§è‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§ú‡§ø‡§™ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä ‡•© ‡§π‡§ú‡§æ‡§∞‡§≠‡§®‡•ç‡§¶‡§æ ‡§§‡§≤‡§ï‡•ã ‡§≠‡§æ‡§°‡§æ‡§Æ‡§æ ‡§ú‡§æ‡§®‡•à ‡§Æ‡§æ‡§®‡•ç‡§® ‡•§\n",
      "Corrected: ‡§ú‡§ø‡§™ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä ‡•© ‡§π‡§ú‡§æ‡§∞‡§≠‡§®‡•ç‡§¶‡§æ ‡§§‡§≤‡§ï‡•ã ‡§≠‡§æ‡§°‡§æ‡§Æ‡§æ ‡§ú‡§æ‡§®‡•à ‡§Æ‡§æ‡§®‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "label:     ‡§ú‡§ø‡§™ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø‡•Ä ‡•© ‡§π‡§ú‡§æ‡§∞‡§≠‡§®‡•ç‡§¶‡§æ ‡§§‡§≤‡§ï‡•ã ‡§≠‡§æ‡§°‡§æ‡§Æ‡§æ ‡§ú‡§æ‡§®‡•à ‡§Æ‡§æ‡§®‡•ç‡§¶‡•à‡§®‡§®‡•ç ‡•§\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def correct_batch(texts, batch_size=8):\n",
    "    \"\"\"\n",
    "    Correct grammar for multiple sentences\n",
    "    \"\"\"\n",
    "    corrected_texts = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Add prefix to each text\n",
    "        input_texts = [f\"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: {text}\" for text in batch_texts]\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            input_texts,\n",
    "            return_tensors = \"pt\",\n",
    "            truncation = True,\n",
    "            padding=True\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generate correction\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs.input_ids,\n",
    "                # attention_mask=inputs.attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=5,\n",
    "                repetition_penalty=2.5\n",
    "            )\n",
    "            \n",
    "        # Decode batch\n",
    "        batch_corrected = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        corrected_texts.extend(batch_corrected)\n",
    "        \n",
    "    return corrected_texts\n",
    "        \n",
    "    \n",
    "test_sentences = small_dataset[\"train\"][\"incorrect_sentence\"][:]\n",
    "labels = small_dataset[\"train\"][\"correct_sentence\"][:]\n",
    "corrected_sentences = correct_batch(test_sentences)\n",
    "for orig, corr, lab in zip(test_sentences, corrected_sentences, labels):\n",
    "    print(f\"Original:  {orig}\")\n",
    "    print(f\"Corrected: {corr}\")\n",
    "    print(f\"label:     {lab}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042d6ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corrected_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m compute_metrics((\u001b[43mcorrected_sentences\u001b[49m, labels))\n",
      "\u001b[31mNameError\u001b[39m: name 'corrected_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "compute_metrics((corrected_sentences, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f608f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
