{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3025d85f",
   "metadata": {},
   "source": [
    "Lets see whether simple mt5 model overfits in small data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b854e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSeq2SeqLM,\n",
    "                          Seq2SeqTrainer,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          DataCollatorForSeq2Seq\n",
    "                          )\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "# Set all seeds for reproducibility\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "torch.manual_seed(100)\n",
    "torch.cuda.manual_seed_all(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ab664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aryal's dataset from hf\n",
    "# ds = load_dataset(\"sumitaryal/nepali_grammatical_error_correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a99e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select randomly few samples from train \n",
    "# split further into train and valid dataset\n",
    "# small_dataset = ds[\"train\"].shuffle(seed=42).select(range(125))\n",
    "# small_dataset = small_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "# small_dataset[\"valid\"] = small_dataset[\"test\"] # Rename the split in the DatasetDict\n",
    "# del small_dataset[\"test\"]\n",
    "# small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5f7ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['incorrect_sentence', 'correct_sentence'],\n",
       "    num_rows: 40\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "small_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=\"multi_seman.txt\",\n",
    "    sep=\", \",         # use \",\" if comma-separated\n",
    "    column_names=[\"incorrect_sentence\", \"correct_sentence\"]\n",
    ")\n",
    "small_dataset[\"train\"].shuffle(seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ced447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ckpt = \"google/mt5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebb360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"वाक्य सच्याउनुहोस्: \"\n",
    "\n",
    "def preprocess(batch):\n",
    "    \n",
    "    inputs = [prefix + inp for inp in batch[\"incorrect_sentence\"]]\n",
    "\n",
    "    # tokenize input (incorrect)\n",
    "    input_encodings = tokenizer(\n",
    "        inputs, \n",
    "        max_length=128,\n",
    "        truncation=True \n",
    "    )\n",
    "    # tokenize target (correct)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(\n",
    "            batch[\"correct_sentence\"], \n",
    "            max_length=128,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    # set labels for seq2seq training                           # for seq2deq models, the \"labels\" are the token IDs of the target sequence\n",
    "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]   \n",
    "\n",
    "    return input_encodings\n",
    "\n",
    "dataset_encoded = small_dataset.map(preprocess, batched=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47d6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch model expects in tensor format\n",
    "dataset_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf332a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load metrics once\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute BLEU, chrF, Correction Accuracy, and BERTScore for Nepali GEC.\n",
    "    Handles both token IDs and plain text predictions.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # --- Handle tuple outputs (e.g., logits + labels) ---\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # --- If preds/labels are lists of strings, skip decoding ---\n",
    "    if isinstance(predictions[0], str) and isinstance(labels[0], str):\n",
    "        preds_clean = [p.strip() for p in predictions]\n",
    "        refs_clean = [r.strip() for r in labels]\n",
    "    else:\n",
    "        # Convert to numpy arrays\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Handle logits (vocab dimension)\n",
    "        if predictions.ndim == 3:\n",
    "            predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "        # Replace -100 with pad_token_id\n",
    "        predictions = np.where(predictions == -100, tokenizer.pad_token_id, predictions)\n",
    "        labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "        # Decode\n",
    "        preds = tokenizer.batch_decode(predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        refs = tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        preds_clean = [p.strip() for p in preds]\n",
    "        refs_clean = [r.strip() for r in refs]\n",
    "\n",
    "    # --- Format for metrics ---\n",
    "    references = [[r] for r in refs_clean]\n",
    "    metrics = {}\n",
    "\n",
    "    # --- BLEU ---\n",
    "    try:\n",
    "        non_empty_indices = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "        if non_empty_indices:\n",
    "            preds_bleu = [preds_clean[i] for i in non_empty_indices]\n",
    "            refs_bleu = [[refs_clean[i]] for i in non_empty_indices]\n",
    "            bleu_result = bleu_metric.compute(predictions=preds_bleu, references=refs_bleu)\n",
    "            metrics[\"bleu\"] = bleu_result[\"bleu\"]\n",
    "        else:\n",
    "            metrics[\"bleu\"] = 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU computation failed: {e}\")\n",
    "        metrics[\"bleu\"] = 0.0\n",
    "\n",
    "    # --- chrF ---\n",
    "    try:\n",
    "        chrf_result = chrf_metric.compute(predictions=preds_clean, references=refs_clean)\n",
    "        metrics[\"chrf\"] = chrf_result[\"score\"]\n",
    "    except Exception as e:\n",
    "        print(f\"chrF computation failed: {e}\")\n",
    "        metrics[\"chrf\"] = 0.0\n",
    "\n",
    "    # --- Correction Accuracy ---\n",
    "    try:\n",
    "        exact_matches = np.mean([p == r for p, r in zip(preds_clean, refs_clean)])\n",
    "        metrics[\"correction_accuracy\"] = exact_matches\n",
    "    except Exception as e:\n",
    "        print(f\"Correction accuracy computation failed: {e}\")\n",
    "        metrics[\"correction_accuracy\"] = 0.0\n",
    "\n",
    "    # --- BERTScore ---\n",
    "    try:\n",
    "        non_empty_indices_bert = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "        if non_empty_indices_bert:\n",
    "            preds_bert = [preds_clean[i] for i in non_empty_indices_bert]\n",
    "            refs_bert = [refs_clean[i] for i in non_empty_indices_bert]\n",
    "            bertscore_result = bertscore_metric.compute(\n",
    "                predictions=preds_bert,\n",
    "                references=refs_bert,\n",
    "                lang=\"ne\",\n",
    "                model_type=\"microsoft/mdeberta-v3-base\"\n",
    "            )\n",
    "            metrics[\"bertscore_f1\"] = float(np.mean(bertscore_result[\"f1\"]))\n",
    "        else:\n",
    "            metrics[\"bertscore_f1\"] = 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"BERTScore computation failed: {e}\")\n",
    "        metrics[\"bertscore_f1\"] = 0.0\n",
    "\n",
    "    # --- Print one sample for sanity ---\n",
    "    if len(preds_clean) > 0:\n",
    "        print(f\"🔍 Sample - Pred: '{preds_clean[0][:50]}...' | Ref: '{refs_clean[0][:50]}...' | Match: {preds_clean[0] == refs_clean[0]}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8969948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "\n",
    "# # Load metrics once\n",
    "# bleu_metric = evaluate.load(\"bleu\")\n",
    "# chrf_metric = evaluate.load(\"chrf\")\n",
    "# bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "# # Minimum GPU memory (bytes) to safely run BERTScore\n",
    "# MIN_BERTSCORE_GPU_FREE = 3 * 1024**3  # 3 GB, adjust if needed\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     \"\"\"\n",
    "#     Compute BLEU, chrF, Correction Accuracy, and BERTScore for Nepali GEC.\n",
    "#     BERTScore is skipped if GPU RAM is insufficient.\n",
    "#     Handles both token IDs and plain text predictions.\n",
    "#     \"\"\"\n",
    "#     predictions, labels = eval_pred\n",
    "\n",
    "#     # --- Handle tuple outputs (e.g., logits + labels) ---\n",
    "#     if isinstance(predictions, tuple):\n",
    "#         predictions = predictions[0]\n",
    "\n",
    "#     # --- If preds/labels are lists of strings, skip decoding ---\n",
    "#     if isinstance(predictions[0], str) and isinstance(labels[0], str):\n",
    "#         preds_clean = [p.strip() for p in predictions]\n",
    "#         refs_clean = [r.strip() for r in labels]\n",
    "#     else:\n",
    "#         if tokenizer is None:\n",
    "#             raise ValueError(\"Tokenizer must be provided for decoding token IDs.\")\n",
    "#         predictions = np.array(predictions)\n",
    "#         labels = np.array(labels)\n",
    "\n",
    "#         if predictions.ndim == 3:\n",
    "#             predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "#         predictions = np.where(predictions == -100, tokenizer.pad_token_id, predictions)\n",
    "#         labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "#         preds = tokenizer.batch_decode(predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "#         refs = tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "#         preds_clean = [p.strip() for p in preds]\n",
    "#         refs_clean = [r.strip() for r in refs]\n",
    "\n",
    "#     metrics = {}\n",
    "\n",
    "#     # --- BLEU ---\n",
    "#     try:\n",
    "#         non_empty_indices = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "#         if non_empty_indices:\n",
    "#             preds_bleu = [preds_clean[i] for i in non_empty_indices]\n",
    "#             refs_bleu = [[refs_clean[i]] for i in non_empty_indices]\n",
    "#             bleu_result = bleu_metric.compute(predictions=preds_bleu, references=refs_bleu)\n",
    "#             metrics[\"bleu\"] = bleu_result[\"bleu\"]\n",
    "#         else:\n",
    "#             metrics[\"bleu\"] = 0.0\n",
    "#     except Exception as e:\n",
    "#         print(f\"BLEU computation failed: {e}\")\n",
    "#         metrics[\"bleu\"] = 0.0\n",
    "\n",
    "#     # --- chrF ---\n",
    "#     try:\n",
    "#         chrf_result = chrf_metric.compute(predictions=preds_clean, references=refs_clean)\n",
    "#         metrics[\"chrf\"] = chrf_result[\"score\"]\n",
    "#     except Exception as e:\n",
    "#         print(f\"chrF computation failed: {e}\")\n",
    "#         metrics[\"chrf\"] = 0.0\n",
    "\n",
    "#     # --- Correction Accuracy ---\n",
    "#     try:\n",
    "#         exact_matches = np.mean([p == r for p, r in zip(preds_clean, refs_clean)])\n",
    "#         metrics[\"correction_accuracy\"] = exact_matches\n",
    "#     except Exception as e:\n",
    "#         print(f\"Correction accuracy computation failed: {e}\")\n",
    "#         metrics[\"correction_accuracy\"] = 0.0\n",
    "\n",
    "#     # --- BERTScore (skip if GPU memory low) ---\n",
    "#     try:\n",
    "#         free_mem = torch.cuda.mem_get_info()[0] if torch.cuda.is_available() else 0\n",
    "#         if free_mem >= MIN_BERTSCORE_GPU_FREE:\n",
    "#             non_empty_indices_bert = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "#             if non_empty_indices_bert:\n",
    "#                 preds_bert = [preds_clean[i] for i in non_empty_indices_bert]\n",
    "#                 refs_bert = [refs_clean[i] for i in non_empty_indices_bert]\n",
    "#                 bertscore_result = bertscore_metric.compute(\n",
    "#                     predictions=preds_bert,\n",
    "#                     references=refs_bert,\n",
    "#                     lang=\"ne\",\n",
    "#                     model_type=\"microsoft/mdeberta-v3-base\"\n",
    "#                 )\n",
    "#                 metrics[\"bertscore_f1\"] = float(np.mean(bertscore_result[\"f1\"]))\n",
    "#             else:\n",
    "#                 metrics[\"bertscore_f1\"] = 0.0\n",
    "#         else:\n",
    "#             print(f\"⚠️ Skipping BERTScore: free GPU memory {free_mem / 1024**3:.2f} GB < required {MIN_BERTSCORE_GPU_FREE / 1024**3:.1f} GB\")\n",
    "#             metrics[\"bertscore_f1\"] = None\n",
    "#     except Exception as e:\n",
    "#         print(f\"BERTScore computation failed: {e}\")\n",
    "#         metrics[\"bertscore_f1\"] = None\n",
    "\n",
    "#     # --- Print one sample for sanity ---\n",
    "#     if len(preds_clean) > 0:\n",
    "#         print(f\"🔍 Sample - Pred: '{preds_clean[0][:50]}...' | Ref: '{refs_clean[0][:50]}...' | Match: {preds_clean[0] == refs_clean[0]}\")\n",
    "\n",
    "#     return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda18e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sample - Pred: 'मेरो नाम सन्तोष हो ।...' | Ref: 'मेरो नाम सन्तोष हो ।...' | Match: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 1.0,\n",
       " 'chrf': 100.0,\n",
       " 'correction_accuracy': np.float64(1.0),\n",
       " 'bertscore_f1': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [\"मेरो नाम सन्तोष हो ।\", \"म स्कुल जान्छु ।\", \"म खाना खान्छु ।\"]\n",
    "refs  = [\"मेरो नाम सन्तोष हो ।\", \"म स्कुल जान्छु ।\", \"म खाना खान्छु ।\"]\n",
    "compute_metrics((preds, refs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2519bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# del model       # or del comet_model\n",
    "gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7c9f555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlsumit008\u001b[0m (\u001b[33mlsumit008-khwopa-college-of-engineering\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\notebooks\\wandb\\run-20251029_005805-6hqlnc2b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit/runs/6hqlnc2b' target=\"_blank\">decent-lion-57</a></strong> to <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit/runs/6hqlnc2b' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit/runs/6hqlnc2b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"gec_overfit\")\n",
    "run_id = wandb.run.id\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"../outputs\",\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc006b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sample - Pred: '<extra_id_0>  कोन))्द <extra_id_56>ई <extra_id_40>...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 09:40, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>Correction Accuracy</th>\n",
       "      <th>Bertscore F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.081500</td>\n",
       "      <td>7.849360</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.192697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12.376600</td>\n",
       "      <td>6.568001</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.896298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12.528800</td>\n",
       "      <td>5.910247</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.242493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.612200</td>\n",
       "      <td>4.559451</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.159604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.136800</td>\n",
       "      <td>3.623879</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.111680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.051300</td>\n",
       "      <td>2.754323</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>31.526172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.134000</td>\n",
       "      <td>2.143264</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>40.162586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.062800</td>\n",
       "      <td>1.976315</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>44.938007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.860400</td>\n",
       "      <td>1.729370</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>47.942412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.446100</td>\n",
       "      <td>1.614933</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.057083</td>\n",
       "      <td>51.747946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.492000</td>\n",
       "      <td>1.498002</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>52.262642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.139900</td>\n",
       "      <td>1.348219</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.062734</td>\n",
       "      <td>54.360724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.902700</td>\n",
       "      <td>1.250142</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>55.299773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.726787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.120500</td>\n",
       "      <td>1.288797</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.064912</td>\n",
       "      <td>56.452659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.655800</td>\n",
       "      <td>1.149951</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.068930</td>\n",
       "      <td>59.360514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.876500</td>\n",
       "      <td>1.111799</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>63.778590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.769500</td>\n",
       "      <td>1.054322</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.143108</td>\n",
       "      <td>66.582717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.137700</td>\n",
       "      <td>1.043109</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.155873</td>\n",
       "      <td>67.315690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.787808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>0.956445</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.165579</td>\n",
       "      <td>67.625376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.931900</td>\n",
       "      <td>0.931749</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.168331</td>\n",
       "      <td>67.753518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.598800</td>\n",
       "      <td>0.897593</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.178178</td>\n",
       "      <td>69.532464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.023500</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.183609</td>\n",
       "      <td>69.668498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.453900</td>\n",
       "      <td>0.858751</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.200769</td>\n",
       "      <td>70.420077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.203300</td>\n",
       "      <td>0.833343</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.195888</td>\n",
       "      <td>70.578580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.356500</td>\n",
       "      <td>0.769364</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.227762</td>\n",
       "      <td>72.263211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>0.737270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.234343</td>\n",
       "      <td>73.318366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.358400</td>\n",
       "      <td>0.734035</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.254142</td>\n",
       "      <td>74.406625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.726402</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.256338</td>\n",
       "      <td>74.586444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.490300</td>\n",
       "      <td>0.724622</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.256864</td>\n",
       "      <td>74.517170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.330900</td>\n",
       "      <td>0.723910</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.257985</td>\n",
       "      <td>74.483639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sample - Pred: '<extra_id_0>....बाट),्द... <extra_id_2> <extra_id_...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>.ईकोबीच  ्दितचीुर <extra_id_44>!नीन्जि...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>य ई य।्दीरी <extra_id_43>लोुर ध्वनीन्ज...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>य ईरहेको्दछभरछान्तको <extra_id_11>मधुर...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>र ः नै्दछमाान्तरमधुर ध्वनी गुन्जिन्छने...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई र मिल ्दछमा शान्तको मधुर ध्वनी ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्दछमा शान्तको सुमधुर...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>ध्व दुई हात मिल मिल्दछ श शान्तको सुमधु...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्दछ श शान्तको सुमधुर...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>ध्व दुई हात मिल मिल्दछ श शान्तको सुमधु...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्दछ श शान्तको सुमधुर...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्दछमा शान्तको सुमधुर...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्दछमा शान्तको सुमधुर...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्द विश्वमा शान्तिको ...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: '<extra_id_0>यी दुई हात मिल मिल्दा विश्वमा शान्तिको...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: 'बियी दुई हात मिल मिल्दा विश्वमा शान्तिको सुमधुर ध्...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: 'बियी दुई हात मिल मिल्दा विश्वमा शान्तिको सुमधुर ध्...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: 'बियी दुई हात मिल मिल्द विश्वमा शान्तिको सुमधुर ध्व...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n",
      "🔍 Sample - Pred: 'बियी दुई हात मिल मिल्द विश्वमा शान्तिको सुमधुर ध्व...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=4.047622843682766, metrics={'train_runtime': 582.8035, 'train_samples_per_second': 2.059, 'train_steps_per_second': 1.03, 'total_flos': 91019779209216.0, 'train_loss': 4.047622843682766, 'epoch': 30.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"train\"].select(range(15)),  # same dataset for overfitting here\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=seq2seq_data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "      \n",
    ")\n",
    "trainer.evaluate()\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff205b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# del model       # or del comet_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6223af",
   "metadata": {},
   "source": [
    "Testing with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c59b2e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sample - Pred: 'बियी दुई हात मिल मिल्द विश्वमा शान्तिको सुमधुर ध्व...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9358439445495605,\n",
       " 'eval_model_preparation_time': 0.0035,\n",
       " 'eval_bleu': 0.23839540672661175,\n",
       " 'eval_chrf': 75.09730452317531,\n",
       " 'eval_correction_accuracy': 0.025,\n",
       " 'eval_bertscore_f1': 0.8259538620710373,\n",
       " 'eval_runtime': 13.4613,\n",
       " 'eval_samples_per_second': 2.971,\n",
       " 'eval_steps_per_second': 1.486,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with same train dataset for overfit model in order to check whether metrics function works. \n",
    "trainer.evaluate(dataset_encoded[\"train\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d0507",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a032119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: नगरपालिका कस्तो किसिमको पर्यटक ल्याउन सक्छे \n",
      "Corrected: <extra_id_0> नगरपालिका कस्ता किसिमको पर्यटक ल्याउन सक्छ ?\n"
     ]
    }
   ],
   "source": [
    "def correct_grammar_simple(text):\n",
    "    # Add task prefix (use the same format as during training)\n",
    "    input_text = f\"वाक्य सुधार्नुहोस्: {text}\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors = \"pt\",\n",
    "        truncation = True,\n",
    "        padding=False\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate correction\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=128,\n",
    "            # num_beams=5,\n",
    "            # repetition_penalty=2.5,\n",
    "            # length_penalty=1.0,\n",
    "            # temperature=0.8\n",
    "        )\n",
    "        \n",
    "    # Decode output\n",
    "    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "\n",
    "# Test\n",
    "test_sentence = \"नगरपालिका कस्तो किसिमको पर्यटक ल्याउन सक्छे \"\n",
    "corrected = correct_grammar_simple(test_sentence)\n",
    "print(f\"Original: {test_sentence}\")\n",
    "print(f\"Corrected: {corrected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f45e1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  यी दुई हात मिल्दछ विश्वमा शान्तीको सुमधुर ध्वनी गुन्जिन्छे\n",
      "Corrected: यी दुई हात मिल्दा विश्वमा शान्तिको सुमधुर ध्वनी गुञ्जिनेछ।\n",
      "label:     यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि गुञ्जिनेछ ।\n",
      "---\n",
      "Original:  फुटबल छुनै दिन्न थिएन।\n",
      "Corrected: <extra_id_0> थिएन।\n",
      "label:     फुटबल छुनै दिँदैन थिए ।\n",
      "---\n",
      "Original:  मलाई भन्न त धेरै मन हो\n",
      "Corrected: बिहान मलाई भन्न त धेरै मन छ ।\n",
      "label:     मलाई भन्न त धेरै मन छ।\n",
      "---\n",
      "Original:  नेक्सनमा ६ स्पिड गेअर बम्स रहको हो।\n",
      "Corrected: ६ स्पिड गेअर बम्स रहन्छ।\n",
      "label:     नेक्सनमा ६ स्पीड गेयर बम्स रहेको छ ।\n",
      "---\n",
      "Original:  सिलाइ कटाई तालिम लिएको व्यवसाय चलाउ योजना बनाइ\n",
      "Corrected: <extra_id_0> व्यवसाय चलाउने योजना बनाइएको छ ।\n",
      "label:     सिलाइकटाइ तालिम लिएर व्यवसाय चलाउने योजना बनाइन् ।\n",
      "---\n",
      "Original:  काठमाण्डौले दिएको ९० रनको लक्ष्य ललितपुर १६.३ ओभरमा ३ विकेट हराएर पुरा गर्यो\n",
      "Corrected: ललितपुरले दिएको ९० रनको लक्ष्य काठमाण्डौले १६.३ ओभरमा ३ विकेट गुमाएर पुरा गर्यो।\n",
      "label:     काठमाडौंले दिएको ९० रनको लक्ष्य ललितपुरले १६.३ ओभरमा ३ विकेट गुमाएर पुरा ग¥यो ।\n",
      "---\n",
      "Original:  सामुदायिक पढ्ने विद्यार्थीले अघिल्लो किताब सुविधा पाउँछन यसमा पनि निरन्तरता दिइयो\n",
      "Corrected: बिद्यालयमा पढ्ने विद्यार्थीले अघिल्लो किताब सुविधा पाउँछन यसमा निरन्तरता दिइएको छ ।\n",
      "label:     सामुदायिकमा अध्ययन गर्ने विद्यार्थीले यसअघि पाइरहेको पाठ्यपुस्तक सुविधा भने यसमा पनि निरन्तरता दिइएको छ ।\n",
      "---\n",
      "Original:  सबै भन्दा धेरे मुद्दा लागेका सांसद जेडीयू को हो\n",
      "Corrected: धेरै मुद्दा लागेका सांसद जेडीयूको हो ।\n",
      "label:     सबैभन्दा धेरै मुद्दा लागेका सांसद जेडीयूका छन् ।\n",
      "---\n",
      "Original:  यी क्षेत्रको बिकासको लागि सरकार प्राथमिकता निर्धारण गरि लगानी बढाउनु चाहिन्छ\n",
      "Corrected: यी क्षेत्रको बिकासको लागि सरकार प्राथमिकता निर्धारण गरि लगानी बढाउनु आवश्यक छ ।\n",
      "label:     यी क्षेत्रको विकासका लागि सरकारले प्राथमिकता निर्धारण गरी उल्लेख्य मात्रामा लगानी विस्तार तथा लगानी आकर्षण गर्नुपर्छ ।\n",
      "---\n",
      "Original:  प्रहरीले चाबी काट्दै छ थाहा पाए पछि भान्सा तलामा उक्लिएर हाम्फाल्नुपर्ने कारण किन आय\n",
      "Corrected: <extra_id_0>ले चाबी काटिरहेको छ थाहा पाए पछि भान्सा तलामा उक्लिएर हाम्फालिनुपर्ने कारण किन आयो ?\n",
      "label:     प्रहरीले चाबी काटिरहेको थाहा पाउने बित्तिकै भान्छा रहेको तलामा उक्लिएर हाम्फालिहाल्नु पर्ने कारण किन आयो?\n",
      "---\n",
      "Original:  बाहिर बाट हेर्दा ठिक ठाक लाग्छ तर सन्तान नभएको कारण उनिहरु को कुरा काटिन्छथ्यो\n",
      "Corrected: बिहानबाट हेर्दा ठिकठाक लागे पनि सन्तान नभएको कारण उनिहरुको कुरा काटिन्थ्यो।\n",
      "label:     बाहिरबाट हेर्दा ठीकठाक लागे पनि सन्तान नभएको विषयले उनीहरुको कुरा काटिन्थ्यो।\n",
      "---\n",
      "Original:  बिजेताले ३ लाख उपबिजेताले १ लाख ५० हजार पाउनेछ\n",
      "Corrected: बिजेताले ३ लाख उपविजेताले ३ लाख ५० हजार पाउनेछ ।\n",
      "label:     विजेताले ३ लाख र उपविजेताले १ लाख ५० हजार प्राप्त गर्नेछन् ।\n",
      "---\n",
      "Original:  राज्य ध्यान जान सक्दैन अवस्था छैन\n",
      "Corrected: ध्यान जान सकेको अवस्था छैन।\n",
      "label:     राज्यको ध्यान जान सकिरहेको अवस्था छैन ।\n",
      "---\n",
      "Original:  पर्यटन प्रहरी पर्टकको सुरक्षासँगै आम समुदायका लागि स्थापना गरिएको बताउँदै उनल पर्यटकीय नगरी सुरक्षित बनाउन आवश्यक रहेको बताए ।\n",
      "Corrected: <extra_id_0> पर्यटकीय नगरी सुरक्षित बनाउन आवश्यक रहेको बताउँदै उनले पर्यटकीय नगरी सुरक्षित बनाउन आवश्यक रहेको बताए ।\n",
      "label:     पर्यटन प्रहरी पर्यटकको सुरक्षासँगै आम समुदायका लागि स्थापना गरिएको बताउँदै उनले पर्यटकीय नगरी सुरक्षित बनाउन आवश्यक रहेको बताए ।\n",
      "---\n",
      "Original:  स्थानीय सरकारको प्राथमिकतामा नपरेको भर्ना अभियान विद्यालयले पुरानै शैलीबाट सुरु गरेको भन्दै उनले यसले शिक्षामा परिवर्तन गर्न नसकिने बताए ।\n",
      "Corrected: <extra_id_0>ले पुरानै शैलीबाट सुरु गरेको भन्दै उनले यसले शिक्षामा परिवर्तन गर्न नसकिने बताए ।\n",
      "label:     स्थानीय सरकारको प्राथमिकतामा नपरेको भर्ना अभियान विद्यालयले पुरानै शैलीबाट सुरु गरेको भन्दै उनले यसले शिक्षामा परिवर्तन गर्न नसकिने बताए ।\n",
      "---\n",
      "Original:  सम्मेलन तयारीको लागि देजमोले यो फागुन ७ देखि २१ सम्म मेचि महाकाली जनजागरण अभियान चलाएको थियो\n",
      "Corrected: <extra_id_0>ले यो फागुन ७ देखि २१ गते मेचि महाकाली जनजागरण अभियान चलाएको थियो।\n",
      "label:     सम्मेलनको तयारीका लागि देजमोले यही फागुन ७ देखि २१ गते सम्म मेचीमहाकाली जन जागरण अभियान चलाएको थियो।\n",
      "---\n",
      "Original:  प्रधानमन्त्रीको भ्रमणमा अमेरिकामा रहेका नेपाली समुदायबाट के कस्ता कार्यक्रमको आयोजना गर्न भन्ने विषयमा मिसनले छलफलको आयोजना समेत गरेक छ।\n",
      "Corrected: <extra_id_0> प्रधानमन्त्रीको भ्रमणमा अमेरिकामा रहेका नेपाली समुदायबाट के कस्ता कार्यक्रमको आयोजना गर्न भन्ने विषयमा मिसनले छलफलको आयोजना समेत गरेको छ।\n",
      "label:     प्रधानमन्त्रीको भ्रमणमा अमेरिकामा रहेका नेपाली समुदायबाट के कस्ता कार्यक्रमको आयोजना गर्ने भन्ने विषयमा मिसनले छलफलको आयोजना समेत गरेको छ।\n",
      "---\n",
      "Original:  यसरी सरकार संवेदनशील भएर बोलाउँछ मलाई लाग्छ उहाँ पनि वार्तामा आउँछ\n",
      "Corrected: यसरी सरकार संवेदनशिल भएर बोलाउँदा मलाई लाग्छ उहाँ पनि वार्तामा आउँछ।\n",
      "label:     यसरी सरकार संवेदनशिल भएर बोलाउँदा मलाई लाग्छ उहाँहरु पनि वार्तामा आउनुहुन्छ ।\n",
      "---\n",
      "Original:  नगरपालिका कस्तो किसिमको पर्यटक ल्याउन सक्छे\n",
      "Corrected: नगरपालिका कस्ता किसिमका पर्यटक ल्याउन सक्छ ?\n",
      "label:     नगरपालिकाले कस्ता किसिमका पर्यटक भित्राउन सक्छ ?\n",
      "---\n",
      "Original:  प्रदेश सकारको गठन भएपछि आफ्ना आफ्ना प्रदेश अनुकलको विधानहरू स्वीकृत प्रदेश सभाले गर्नुपर्ने व्यवस्था ।\n",
      "Corrected: <extra_id_0> प्रदेश अनुकूलको गठन भएपछि आफ्ना आफ्ना प्रदेश अनुकूलको विधानहरू स्वीकृत प्रदेश सभाले गर्नुपर्ने व्यवस्था ।\n",
      "label:     पदेश सरकारको गठन भएपछि आफ्ना आफ्ना प्रदेश अनुकूलको विधानहरू स्वीकृत प्रदेश सभाले गर्नुपर्ने व्यवस्था छ ।\n",
      "---\n",
      "Original:  मैले बिहान खाना हेरे।\n",
      "Corrected: बिहान खाना हेरे।\n",
      "label:     मैले बिहान खाना खाएँ।\n",
      "---\n",
      "Original:  ऊ हिजो आउनेछ।\n",
      "Corrected: ऊ हिजो आउनेछ।\n",
      "label:     ऊ भोलि आउनेछ।\n",
      "---\n",
      "Original:  म खाना पिउन चाहन्न\n",
      "Corrected: बिहान खाना पिउन चाहन्न।\n",
      "label:     म पानी पिउन चाहन्न।\n",
      "---\n",
      "Original:  बिर्खेले किताब खायो।\n",
      "Corrected: <extra_id_0>ले किताब पढ्यो।\n",
      "label:     बिर्खेले किताब पढ्यो।\n",
      "---\n",
      "Original:  सूर्य पश्चिमबाट उदाउँछ।\n",
      "Corrected: सूर्य पूर्वबाट उदाउँछ।\n",
      "label:     सूर्य पूर्वबाट उदाउँछ।\n",
      "---\n",
      "Original:  आज म बिद्यालय नजानेछु किनभने म गएँ।\n",
      "Corrected: बिद्यालय गएँ।\n",
      "label:     आज म बिद्यालय गएँ।\n",
      "---\n",
      "Original:  म कुखुरालाई दूध पिलाएँ।\n",
      "Corrected: <extra_id_0> दूखुरालाई दूर पिएँ।\n",
      "label:     म कुखुरालाई दाना खुवाएँ।\n",
      "---\n",
      "Original:  हावा तातो खान्छ।\n",
      "Corrected: तातो खान्छ।\n",
      "label:     हावा तातो हुन्छ।\n",
      "---\n",
      "Original:  ऊ घाममा नुहाउँदै थियो।\n",
      "Corrected: बिहान घाममा नुहाउँदै थियो।\n",
      "label:     ऊ घाममा तातिँदै थियो।\n",
      "---\n",
      "Original:  मेरो फोन दुख्यो।\n",
      "Corrected: <extra_id_0> दुख्यो।\n",
      "label:     मेरो घाँटी दुख्यो।\n",
      "---\n",
      "Original:  म कागजमा सुत्छु।\n",
      "Corrected: <extra_id_0> सुत्छु।\n",
      "label:     म ओछ्यानमा सुत्छु।\n",
      "---\n",
      "Original:  पानीले आगो जलायो।\n",
      "Corrected: पानीले आगो जलायो।\n",
      "label:     पानीले आगो निभायो।\n",
      "---\n",
      "Original:  हजुरआमाले टेलिभिजन सुने।\n",
      "Corrected: <extra_id_0> हजुरआमाले टेलिभिजन चलाउने।\n",
      "label:     हजुरआमाले टेलिभिजन हेरे।\n",
      "---\n",
      "Original:  कुर्सीले मलाई हिँडायो।\n",
      "Corrected: बिहान मलाई हिँटा।\n",
      "label:     मैले कुर्सी सारें।\n",
      "---\n",
      "Original:  कुकुरले किताब लेख्यो।\n",
      "Corrected: <extra_id_0>।\n",
      "label:     मानिसले किताब लेख्यो।\n",
      "---\n",
      "Original:  आकाश भुइँमा छ।\n",
      "Corrected: बिहानको आकाशमा छ।\n",
      "label:     आकाश माथि छ।\n",
      "---\n",
      "Original:  म पेनले कुरा गर्छु।\n",
      "Corrected: <extra_id_0> कुरा गर्छु।\n",
      "label:     म मुखले कुरा गर्छु।\n",
      "---\n",
      "Original:  ऊ परालमा पौडियो।\n",
      "Corrected: ऊ परालमा पौडियो।\n",
      "label:     ऊ पानीमा पौडियो।\n",
      "---\n",
      "Original:  विद्यालय बिहान बन्द हुन्छ।\n",
      "Corrected: विद्यालय बिहान खुल्छ।\n",
      "label:     विद्यालय बिहान खुल्छ।\n",
      "---\n",
      "Original:  म हिजो जान्छु।\n",
      "Corrected: बिहान जान्छु।\n",
      "label:     म भोलि जान्छु।\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def correct_batch(texts, batch_size=8):\n",
    "    \"\"\"\n",
    "    Correct grammar for multiple sentences\n",
    "    \"\"\"\n",
    "    corrected_texts = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Add prefix to each text\n",
    "        input_texts = [f\"वाक्य सुधार्नुहोस्: {text}\" for text in batch_texts]\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            input_texts,\n",
    "            return_tensors = \"pt\",\n",
    "            truncation = True,\n",
    "            padding=True\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generate correction\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs.input_ids,\n",
    "                # attention_mask=inputs.attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=5,\n",
    "                repetition_penalty=2.5\n",
    "            )\n",
    "            \n",
    "        # Decode batch\n",
    "        batch_corrected = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        corrected_texts.extend(batch_corrected)\n",
    "        \n",
    "    return corrected_texts\n",
    "        \n",
    "    \n",
    "test_sentences = small_dataset[\"train\"][\"incorrect_sentence\"][:]\n",
    "labels = small_dataset[\"train\"][\"correct_sentence\"][:]\n",
    "corrected_sentences = correct_batch(test_sentences)\n",
    "for orig, corr, lab in zip(test_sentences, corrected_sentences, labels):\n",
    "    print(f\"Original:  {orig}\")\n",
    "    print(f\"Corrected: {corr}\")\n",
    "    print(f\"label:     {lab}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0042d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Sample - Pred: 'यी दुई हात मिल्दा विश्वमा शान्तिको सुमधुर ध्वनी गु...' | Ref: 'यी दुई हातहरू मिल्दा विश्वमै शान्तिको सुमधुर ध्वनि...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.315693833959732,\n",
       " 'chrf': 62.606904147812315,\n",
       " 'correction_accuracy': np.float64(0.05),\n",
       " 'bertscore_f1': 0.8399195969104767}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics((corrected_sentences, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f608f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
