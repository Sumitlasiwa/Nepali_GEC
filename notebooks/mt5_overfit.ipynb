{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3025d85f",
   "metadata": {},
   "source": [
    "Lets see whether simple mt5 model overfits in small data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b854e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\myenv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSeq2SeqLM,\n",
    "                          Seq2SeqTrainer,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          DataCollatorForSeq2Seq\n",
    "                          )\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "# Set all seeds for reproducibility\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "torch.manual_seed(100)\n",
    "torch.cuda.manual_seed_all(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ab664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aryal's dataset from hf\n",
    "# ds = load_dataset(\"sumitaryal/nepali_grammatical_error_correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a99e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select randomly few samples from train \n",
    "# split further into train and valid dataset\n",
    "# small_dataset = ds[\"train\"].shuffle(seed=42).select(range(125))\n",
    "# small_dataset = small_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "# small_dataset[\"valid\"] = small_dataset[\"test\"] # Rename the split in the DatasetDict\n",
    "# del small_dataset[\"test\"]\n",
    "# small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5f7ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['incorrect_sentence', 'correct_sentence'],\n",
       "    num_rows: 40\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "small_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=\"multi_seman.txt\",\n",
    "    sep=\", \",         # use \",\" if comma-separated\n",
    "    column_names=[\"incorrect_sentence\", \"correct_sentence\"]\n",
    ")\n",
    "small_dataset[\"train\"].shuffle(seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ced447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ckpt = \"google/mt5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebb360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡§ö‡•ç‡§Ø‡§æ‡§â‡§®‡•Å‡§π‡•ã‡§∏‡•ç: \"\n",
    "\n",
    "def preprocess(batch):\n",
    "    \n",
    "    inputs = [prefix + inp for inp in batch[\"incorrect_sentence\"]]\n",
    "\n",
    "    # tokenize input (incorrect)\n",
    "    input_encodings = tokenizer(\n",
    "        inputs, \n",
    "        max_length=128,\n",
    "        truncation=True \n",
    "    )\n",
    "    # tokenize target (correct)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(\n",
    "            batch[\"correct_sentence\"], \n",
    "            max_length=128,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    # set labels for seq2seq training                           # for seq2deq models, the \"labels\" are the token IDs of the target sequence\n",
    "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]   \n",
    "\n",
    "    return input_encodings\n",
    "\n",
    "dataset_encoded = small_dataset.map(preprocess, batched=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47d6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch model expects in tensor format\n",
    "dataset_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf332a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load metrics once\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute BLEU, chrF, Correction Accuracy, and BERTScore for Nepali GEC.\n",
    "    Handles both token IDs and plain text predictions.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # --- Handle tuple outputs (e.g., logits + labels) ---\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # --- If preds/labels are lists of strings, skip decoding ---\n",
    "    if isinstance(predictions[0], str) and isinstance(labels[0], str):\n",
    "        preds_clean = [p.strip() for p in predictions]\n",
    "        refs_clean = [r.strip() for r in labels]\n",
    "    else:\n",
    "        # Convert to numpy arrays\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # Handle logits (vocab dimension)\n",
    "        if predictions.ndim == 3:\n",
    "            predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "        # Replace -100 with pad_token_id\n",
    "        predictions = np.where(predictions == -100, tokenizer.pad_token_id, predictions)\n",
    "        labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "        # Decode\n",
    "        preds = tokenizer.batch_decode(predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        refs = tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        preds_clean = [p.strip() for p in preds]\n",
    "        refs_clean = [r.strip() for r in refs]\n",
    "\n",
    "    # --- Format for metrics ---\n",
    "    references = [[r] for r in refs_clean]\n",
    "    metrics = {}\n",
    "\n",
    "    # --- BLEU ---\n",
    "    try:\n",
    "        non_empty_indices = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "        if non_empty_indices:\n",
    "            preds_bleu = [preds_clean[i] for i in non_empty_indices]\n",
    "            refs_bleu = [[refs_clean[i]] for i in non_empty_indices]\n",
    "            bleu_result = bleu_metric.compute(predictions=preds_bleu, references=refs_bleu)\n",
    "            metrics[\"bleu\"] = bleu_result[\"bleu\"]\n",
    "        else:\n",
    "            metrics[\"bleu\"] = 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU computation failed: {e}\")\n",
    "        metrics[\"bleu\"] = 0.0\n",
    "\n",
    "    # --- chrF ---\n",
    "    try:\n",
    "        chrf_result = chrf_metric.compute(predictions=preds_clean, references=refs_clean)\n",
    "        metrics[\"chrf\"] = chrf_result[\"score\"]\n",
    "    except Exception as e:\n",
    "        print(f\"chrF computation failed: {e}\")\n",
    "        metrics[\"chrf\"] = 0.0\n",
    "\n",
    "    # --- Correction Accuracy ---\n",
    "    try:\n",
    "        exact_matches = np.mean([p == r for p, r in zip(preds_clean, refs_clean)])\n",
    "        metrics[\"correction_accuracy\"] = exact_matches\n",
    "    except Exception as e:\n",
    "        print(f\"Correction accuracy computation failed: {e}\")\n",
    "        metrics[\"correction_accuracy\"] = 0.0\n",
    "\n",
    "    # --- BERTScore ---\n",
    "    try:\n",
    "        non_empty_indices_bert = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "        if non_empty_indices_bert:\n",
    "            preds_bert = [preds_clean[i] for i in non_empty_indices_bert]\n",
    "            refs_bert = [refs_clean[i] for i in non_empty_indices_bert]\n",
    "            bertscore_result = bertscore_metric.compute(\n",
    "                predictions=preds_bert,\n",
    "                references=refs_bert,\n",
    "                lang=\"ne\",\n",
    "                model_type=\"microsoft/mdeberta-v3-base\"\n",
    "            )\n",
    "            metrics[\"bertscore_f1\"] = float(np.mean(bertscore_result[\"f1\"]))\n",
    "        else:\n",
    "            metrics[\"bertscore_f1\"] = 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"BERTScore computation failed: {e}\")\n",
    "        metrics[\"bertscore_f1\"] = 0.0\n",
    "\n",
    "    # --- Print one sample for sanity ---\n",
    "    if len(preds_clean) > 0:\n",
    "        print(f\"üîç Sample - Pred: '{preds_clean[0][:50]}...' | Ref: '{refs_clean[0][:50]}...' | Match: {preds_clean[0] == refs_clean[0]}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8969948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "\n",
    "# # Load metrics once\n",
    "# bleu_metric = evaluate.load(\"bleu\")\n",
    "# chrf_metric = evaluate.load(\"chrf\")\n",
    "# bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "# # Minimum GPU memory (bytes) to safely run BERTScore\n",
    "# MIN_BERTSCORE_GPU_FREE = 3 * 1024**3  # 3 GB, adjust if needed\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     \"\"\"\n",
    "#     Compute BLEU, chrF, Correction Accuracy, and BERTScore for Nepali GEC.\n",
    "#     BERTScore is skipped if GPU RAM is insufficient.\n",
    "#     Handles both token IDs and plain text predictions.\n",
    "#     \"\"\"\n",
    "#     predictions, labels = eval_pred\n",
    "\n",
    "#     # --- Handle tuple outputs (e.g., logits + labels) ---\n",
    "#     if isinstance(predictions, tuple):\n",
    "#         predictions = predictions[0]\n",
    "\n",
    "#     # --- If preds/labels are lists of strings, skip decoding ---\n",
    "#     if isinstance(predictions[0], str) and isinstance(labels[0], str):\n",
    "#         preds_clean = [p.strip() for p in predictions]\n",
    "#         refs_clean = [r.strip() for r in labels]\n",
    "#     else:\n",
    "#         if tokenizer is None:\n",
    "#             raise ValueError(\"Tokenizer must be provided for decoding token IDs.\")\n",
    "#         predictions = np.array(predictions)\n",
    "#         labels = np.array(labels)\n",
    "\n",
    "#         if predictions.ndim == 3:\n",
    "#             predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "#         predictions = np.where(predictions == -100, tokenizer.pad_token_id, predictions)\n",
    "#         labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "#         preds = tokenizer.batch_decode(predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "#         refs = tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "#         preds_clean = [p.strip() for p in preds]\n",
    "#         refs_clean = [r.strip() for r in refs]\n",
    "\n",
    "#     metrics = {}\n",
    "\n",
    "#     # --- BLEU ---\n",
    "#     try:\n",
    "#         non_empty_indices = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "#         if non_empty_indices:\n",
    "#             preds_bleu = [preds_clean[i] for i in non_empty_indices]\n",
    "#             refs_bleu = [[refs_clean[i]] for i in non_empty_indices]\n",
    "#             bleu_result = bleu_metric.compute(predictions=preds_bleu, references=refs_bleu)\n",
    "#             metrics[\"bleu\"] = bleu_result[\"bleu\"]\n",
    "#         else:\n",
    "#             metrics[\"bleu\"] = 0.0\n",
    "#     except Exception as e:\n",
    "#         print(f\"BLEU computation failed: {e}\")\n",
    "#         metrics[\"bleu\"] = 0.0\n",
    "\n",
    "#     # --- chrF ---\n",
    "#     try:\n",
    "#         chrf_result = chrf_metric.compute(predictions=preds_clean, references=refs_clean)\n",
    "#         metrics[\"chrf\"] = chrf_result[\"score\"]\n",
    "#     except Exception as e:\n",
    "#         print(f\"chrF computation failed: {e}\")\n",
    "#         metrics[\"chrf\"] = 0.0\n",
    "\n",
    "#     # --- Correction Accuracy ---\n",
    "#     try:\n",
    "#         exact_matches = np.mean([p == r for p, r in zip(preds_clean, refs_clean)])\n",
    "#         metrics[\"correction_accuracy\"] = exact_matches\n",
    "#     except Exception as e:\n",
    "#         print(f\"Correction accuracy computation failed: {e}\")\n",
    "#         metrics[\"correction_accuracy\"] = 0.0\n",
    "\n",
    "#     # --- BERTScore (skip if GPU memory low) ---\n",
    "#     try:\n",
    "#         free_mem = torch.cuda.mem_get_info()[0] if torch.cuda.is_available() else 0\n",
    "#         if free_mem >= MIN_BERTSCORE_GPU_FREE:\n",
    "#             non_empty_indices_bert = [i for i, (p, r) in enumerate(zip(preds_clean, refs_clean)) if p and r]\n",
    "#             if non_empty_indices_bert:\n",
    "#                 preds_bert = [preds_clean[i] for i in non_empty_indices_bert]\n",
    "#                 refs_bert = [refs_clean[i] for i in non_empty_indices_bert]\n",
    "#                 bertscore_result = bertscore_metric.compute(\n",
    "#                     predictions=preds_bert,\n",
    "#                     references=refs_bert,\n",
    "#                     lang=\"ne\",\n",
    "#                     model_type=\"microsoft/mdeberta-v3-base\"\n",
    "#                 )\n",
    "#                 metrics[\"bertscore_f1\"] = float(np.mean(bertscore_result[\"f1\"]))\n",
    "#             else:\n",
    "#                 metrics[\"bertscore_f1\"] = 0.0\n",
    "#         else:\n",
    "#             print(f\"‚ö†Ô∏è Skipping BERTScore: free GPU memory {free_mem / 1024**3:.2f} GB < required {MIN_BERTSCORE_GPU_FREE / 1024**3:.1f} GB\")\n",
    "#             metrics[\"bertscore_f1\"] = None\n",
    "#     except Exception as e:\n",
    "#         print(f\"BERTScore computation failed: {e}\")\n",
    "#         metrics[\"bertscore_f1\"] = None\n",
    "\n",
    "#     # --- Print one sample for sanity ---\n",
    "#     if len(preds_clean) > 0:\n",
    "#         print(f\"üîç Sample - Pred: '{preds_clean[0][:50]}...' | Ref: '{refs_clean[0][:50]}...' | Match: {preds_clean[0] == refs_clean[0]}\")\n",
    "\n",
    "#     return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda18e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§...' | Ref: '‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§...' | Match: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 1.0,\n",
       " 'chrf': 100.0,\n",
       " 'correction_accuracy': np.float64(1.0),\n",
       " 'bertscore_f1': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [\"‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§\", \"‡§Æ ‡§∏‡•ç‡§ï‡•Å‡§≤ ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\", \"‡§Æ ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\"]\n",
    "refs  = [\"‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∏‡§®‡•ç‡§§‡•ã‡§∑ ‡§π‡•ã ‡•§\", \"‡§Æ ‡§∏‡•ç‡§ï‡•Å‡§≤ ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\", \"‡§Æ ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§®‡•ç‡§õ‡•Å ‡•§\"]\n",
    "compute_metrics((preds, refs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2519bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# del model       # or del comet_model\n",
    "gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7c9f555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlsumit008\u001b[0m (\u001b[33mlsumit008-khwopa-college-of-engineering\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Lenovo\\Desktop\\Nepali_GEC\\nepali_gec\\notebooks\\wandb\\run-20251029_005805-6hqlnc2b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit/runs/6hqlnc2b' target=\"_blank\">decent-lion-57</a></strong> to <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit/runs/6hqlnc2b' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/gec_overfit/runs/6hqlnc2b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"gec_overfit\")\n",
    "run_id = wandb.run.id\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"../outputs\",\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc006b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0>  ‡§ï‡•ã‡§®))‡•ç‡§¶ <extra_id_56>‡§à <extra_id_40>...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 09:40, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>Correction Accuracy</th>\n",
       "      <th>Bertscore F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.081500</td>\n",
       "      <td>7.849360</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.192697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12.376600</td>\n",
       "      <td>6.568001</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.896298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12.528800</td>\n",
       "      <td>5.910247</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.242493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.612200</td>\n",
       "      <td>4.559451</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.159604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.136800</td>\n",
       "      <td>3.623879</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.111680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.051300</td>\n",
       "      <td>2.754323</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>31.526172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.134000</td>\n",
       "      <td>2.143264</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>40.162586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.062800</td>\n",
       "      <td>1.976315</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>44.938007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.860400</td>\n",
       "      <td>1.729370</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>47.942412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.446100</td>\n",
       "      <td>1.614933</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.057083</td>\n",
       "      <td>51.747946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.492000</td>\n",
       "      <td>1.498002</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>52.262642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.139900</td>\n",
       "      <td>1.348219</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.062734</td>\n",
       "      <td>54.360724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.718928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.902700</td>\n",
       "      <td>1.250142</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.064879</td>\n",
       "      <td>55.299773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.726787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.120500</td>\n",
       "      <td>1.288797</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.064912</td>\n",
       "      <td>56.452659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.655800</td>\n",
       "      <td>1.149951</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.068930</td>\n",
       "      <td>59.360514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.876500</td>\n",
       "      <td>1.111799</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>63.778590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.769500</td>\n",
       "      <td>1.054322</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.143108</td>\n",
       "      <td>66.582717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.137700</td>\n",
       "      <td>1.043109</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.155873</td>\n",
       "      <td>67.315690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.787808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>0.956445</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.165579</td>\n",
       "      <td>67.625376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.931900</td>\n",
       "      <td>0.931749</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.168331</td>\n",
       "      <td>67.753518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.598800</td>\n",
       "      <td>0.897593</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.178178</td>\n",
       "      <td>69.532464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.023500</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.183609</td>\n",
       "      <td>69.668498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.453900</td>\n",
       "      <td>0.858751</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.200769</td>\n",
       "      <td>70.420077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.203300</td>\n",
       "      <td>0.833343</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.195888</td>\n",
       "      <td>70.578580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.356500</td>\n",
       "      <td>0.769364</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.227762</td>\n",
       "      <td>72.263211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>0.737270</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.234343</td>\n",
       "      <td>73.318366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.358400</td>\n",
       "      <td>0.734035</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.254142</td>\n",
       "      <td>74.406625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.726402</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.256338</td>\n",
       "      <td>74.586444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.490300</td>\n",
       "      <td>0.724622</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.256864</td>\n",
       "      <td>74.517170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.330900</td>\n",
       "      <td>0.723910</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.257985</td>\n",
       "      <td>74.483639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.835780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '<extra_id_0>....‡§¨‡§æ‡§ü),‡•ç‡§¶... <extra_id_2> <extra_id_...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>.‡§à‡§ï‡•ã‡§¨‡•Ä‡§ö  ‡•ç‡§¶‡§ø‡§§‡§ö‡•Ä‡•Å‡§∞ <extra_id_44>!‡§®‡•Ä‡§®‡•ç‡§ú‡§ø...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø ‡§à ‡§Ø‡•§‡•ç‡§¶‡•Ä‡§∞‡•Ä <extra_id_43>‡§≤‡•ã‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡•Ä‡§®‡•ç‡§ú...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø ‡§à‡§∞‡§π‡•á‡§ï‡•ã‡•ç‡§¶‡§õ‡§≠‡§∞‡§õ‡§æ‡§®‡•ç‡§§‡§ï‡•ã <extra_id_11>‡§Æ‡§ß‡•Å‡§∞...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§∞ ‡§É ‡§®‡•à‡•ç‡§¶‡§õ‡§Æ‡§æ‡§æ‡§®‡•ç‡§§‡§∞‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡•Ä ‡§ó‡•Å‡§®‡•ç‡§ú‡§ø‡§®‡•ç‡§õ‡§®‡•á...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§∞ ‡§Æ‡§ø‡§≤ ‡•ç‡§¶‡§õ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡•Ä ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§ß‡•ç‡§µ ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ ‡§∂ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ ‡§∂ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§ß‡•ç‡§µ ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ ‡§∂ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ ‡§∂ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '<extra_id_0>‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '‡§¨‡§ø‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '‡§¨‡§ø‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '‡§¨‡§ø‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n",
      "üîç Sample - Pred: '‡§¨‡§ø‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=4.047622843682766, metrics={'train_runtime': 582.8035, 'train_samples_per_second': 2.059, 'train_steps_per_second': 1.03, 'total_flos': 91019779209216.0, 'train_loss': 4.047622843682766, 'epoch': 30.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded[\"train\"],\n",
    "    eval_dataset=dataset_encoded[\"train\"].select(range(15)),  # same dataset for overfitting here\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=seq2seq_data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "      \n",
    ")\n",
    "trainer.evaluate()\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff205b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# del model       # or del comet_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6223af",
   "metadata": {},
   "source": [
    "Testing with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c59b2e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '‡§¨‡§ø‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤ ‡§Æ‡§ø‡§≤‡•ç‡§¶ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9358439445495605,\n",
       " 'eval_model_preparation_time': 0.0035,\n",
       " 'eval_bleu': 0.23839540672661175,\n",
       " 'eval_chrf': 75.09730452317531,\n",
       " 'eval_correction_accuracy': 0.025,\n",
       " 'eval_bertscore_f1': 0.8259538620710373,\n",
       " 'eval_runtime': 13.4613,\n",
       " 'eval_samples_per_second': 2.971,\n",
       " 'eval_steps_per_second': 1.486,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with same train dataset for overfit model in order to check whether metrics function works. \n",
    "trainer.evaluate(dataset_encoded[\"train\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d0507",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a032119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ‡•á \n",
      "Corrected: <extra_id_0> ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡§æ ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ ?\n"
     ]
    }
   ],
   "source": [
    "def correct_grammar_simple(text):\n",
    "    # Add task prefix (use the same format as during training)\n",
    "    input_text = f\"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: {text}\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors = \"pt\",\n",
    "        truncation = True,\n",
    "        padding=False\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate correction\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=128,\n",
    "            # num_beams=5,\n",
    "            # repetition_penalty=2.5,\n",
    "            # length_penalty=1.0,\n",
    "            # temperature=0.8\n",
    "        )\n",
    "        \n",
    "    # Decode output\n",
    "    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected_text\n",
    "\n",
    "# Test\n",
    "test_sentence = \"‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ‡•á \"\n",
    "corrected = correct_grammar_simple(test_sentence)\n",
    "print(f\"Original: {test_sentence}\")\n",
    "print(f\"Corrected: {corrected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f45e1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§õ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡•Ä‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡•Ä ‡§ó‡•Å‡§®‡•ç‡§ú‡§ø‡§®‡•ç‡§õ‡•á\n",
      "Corrected: ‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡•Ä ‡§ó‡•Å‡§û‡•ç‡§ú‡§ø‡§®‡•á‡§õ‡•§\n",
      "label:     ‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø ‡§ó‡•Å‡§û‡•ç‡§ú‡§ø‡§®‡•á‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§´‡•Å‡§ü‡§¨‡§≤ ‡§õ‡•Å‡§®‡•à ‡§¶‡§ø‡§®‡•ç‡§® ‡§•‡§ø‡§è‡§®‡•§\n",
      "Corrected: <extra_id_0> ‡§•‡§ø‡§è‡§®‡•§\n",
      "label:     ‡§´‡•Å‡§ü‡§¨‡§≤ ‡§õ‡•Å‡§®‡•à ‡§¶‡§ø‡§Å‡§¶‡•à‡§® ‡§•‡§ø‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡§≤‡§æ‡§à ‡§≠‡§®‡•ç‡§® ‡§§ ‡§ß‡•á‡§∞‡•à ‡§Æ‡§® ‡§π‡•ã\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§® ‡§Æ‡§≤‡§æ‡§à ‡§≠‡§®‡•ç‡§® ‡§§ ‡§ß‡•á‡§∞‡•à ‡§Æ‡§® ‡§õ ‡•§\n",
      "label:     ‡§Æ‡§≤‡§æ‡§à ‡§≠‡§®‡•ç‡§® ‡§§ ‡§ß‡•á‡§∞‡•à ‡§Æ‡§® ‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§®‡•á‡§ï‡•ç‡§∏‡§®‡§Æ‡§æ ‡•¨ ‡§∏‡•ç‡§™‡§ø‡§° ‡§ó‡•á‡§Ö‡§∞ ‡§¨‡§Æ‡•ç‡§∏ ‡§∞‡§π‡§ï‡•ã ‡§π‡•ã‡•§\n",
      "Corrected: ‡•¨ ‡§∏‡•ç‡§™‡§ø‡§° ‡§ó‡•á‡§Ö‡§∞ ‡§¨‡§Æ‡•ç‡§∏ ‡§∞‡§π‡§®‡•ç‡§õ‡•§\n",
      "label:     ‡§®‡•á‡§ï‡•ç‡§∏‡§®‡§Æ‡§æ ‡•¨ ‡§∏‡•ç‡§™‡•Ä‡§° ‡§ó‡•á‡§Ø‡§∞ ‡§¨‡§Æ‡•ç‡§∏ ‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§ø‡§≤‡§æ‡§á ‡§ï‡§ü‡§æ‡§à ‡§§‡§æ‡§≤‡§ø‡§Æ ‡§≤‡§ø‡§è‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§ö‡§≤‡§æ‡§â ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§¨‡§®‡§æ‡§á\n",
      "Corrected: <extra_id_0> ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§ö‡§≤‡§æ‡§â‡§®‡•á ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§¨‡§®‡§æ‡§á‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§∏‡§ø‡§≤‡§æ‡§á‡§ï‡§ü‡§æ‡§á ‡§§‡§æ‡§≤‡§ø‡§Æ ‡§≤‡§ø‡§è‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§ö‡§≤‡§æ‡§â‡§®‡•á ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§¨‡§®‡§æ‡§á‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§ï‡§æ‡§†‡§Æ‡§æ‡§£‡•ç‡§°‡•å‡§≤‡•á ‡§¶‡§ø‡§è‡§ï‡•ã ‡•Ø‡•¶ ‡§∞‡§®‡§ï‡•ã ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞ ‡•ß‡•¨.‡•© ‡§ì‡§≠‡§∞‡§Æ‡§æ ‡•© ‡§µ‡§ø‡§ï‡•á‡§ü ‡§π‡§∞‡§æ‡§è‡§∞ ‡§™‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§Ø‡•ã\n",
      "Corrected: ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞‡§≤‡•á ‡§¶‡§ø‡§è‡§ï‡•ã ‡•Ø‡•¶ ‡§∞‡§®‡§ï‡•ã ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§ï‡§æ‡§†‡§Æ‡§æ‡§£‡•ç‡§°‡•å‡§≤‡•á ‡•ß‡•¨.‡•© ‡§ì‡§≠‡§∞‡§Æ‡§æ ‡•© ‡§µ‡§ø‡§ï‡•á‡§ü ‡§ó‡•Å‡§Æ‡§æ‡§è‡§∞ ‡§™‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§Ø‡•ã‡•§\n",
      "label:     ‡§ï‡§æ‡§†‡§Æ‡§æ‡§°‡•å‡§Ç‡§≤‡•á ‡§¶‡§ø‡§è‡§ï‡•ã ‡•Ø‡•¶ ‡§∞‡§®‡§ï‡•ã ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§≤‡§≤‡§ø‡§§‡§™‡•Å‡§∞‡§≤‡•á ‡•ß‡•¨.‡•© ‡§ì‡§≠‡§∞‡§Æ‡§æ ‡•© ‡§µ‡§ø‡§ï‡•á‡§ü ‡§ó‡•Å‡§Æ‡§æ‡§è‡§∞ ‡§™‡•Å‡§∞‡§æ ‡§ó¬•‡§Ø‡•ã ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï ‡§™‡§¢‡•ç‡§®‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§≤‡•á ‡§Ö‡§ò‡§ø‡§≤‡•ç‡§≤‡•ã ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§™‡§æ‡§â‡§Å‡§õ‡§® ‡§Ø‡§∏‡§Æ‡§æ ‡§™‡§®‡§ø ‡§®‡§ø‡§∞‡§®‡•ç‡§§‡§∞‡§§‡§æ ‡§¶‡§ø‡§á‡§Ø‡•ã\n",
      "Corrected: ‡§¨‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø‡§Æ‡§æ ‡§™‡§¢‡•ç‡§®‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§≤‡•á ‡§Ö‡§ò‡§ø‡§≤‡•ç‡§≤‡•ã ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§™‡§æ‡§â‡§Å‡§õ‡§® ‡§Ø‡§∏‡§Æ‡§æ ‡§®‡§ø‡§∞‡§®‡•ç‡§§‡§∞‡§§‡§æ ‡§¶‡§ø‡§á‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "label:     ‡§∏‡§æ‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ø‡§ï‡§Æ‡§æ ‡§Ö‡§ß‡•ç‡§Ø‡§Ø‡§® ‡§ó‡§∞‡•ç‡§®‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•Ä‡§≤‡•á ‡§Ø‡§∏‡§Ö‡§ò‡§ø ‡§™‡§æ‡§á‡§∞‡§π‡•á‡§ï‡•ã ‡§™‡§æ‡§†‡•ç‡§Ø‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§≠‡§®‡•á ‡§Ø‡§∏‡§Æ‡§æ ‡§™‡§®‡§ø ‡§®‡§ø‡§∞‡§®‡•ç‡§§‡§∞‡§§‡§æ ‡§¶‡§ø‡§á‡§è‡§ï‡•ã ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§¨‡•à ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•á ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§≤‡§æ‡§ó‡•á‡§ï‡§æ ‡§∏‡§æ‡§Ç‡§∏‡§¶ ‡§ú‡•á‡§°‡•Ä‡§Ø‡•Ç ‡§ï‡•ã ‡§π‡•ã\n",
      "Corrected: ‡§ß‡•á‡§∞‡•à ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§≤‡§æ‡§ó‡•á‡§ï‡§æ ‡§∏‡§æ‡§Ç‡§∏‡§¶ ‡§ú‡•á‡§°‡•Ä‡§Ø‡•Ç‡§ï‡•ã ‡§π‡•ã ‡•§\n",
      "label:     ‡§∏‡§¨‡•à‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•à ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ ‡§≤‡§æ‡§ó‡•á‡§ï‡§æ ‡§∏‡§æ‡§Ç‡§∏‡§¶ ‡§ú‡•á‡§°‡•Ä‡§Ø‡•Ç‡§ï‡§æ ‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡•ã ‡§¨‡§ø‡§ï‡§æ‡§∏‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ ‡§®‡§ø‡§∞‡•ç‡§ß‡§æ‡§∞‡§£ ‡§ó‡§∞‡§ø ‡§≤‡§ó‡§æ‡§®‡•Ä ‡§¨‡§¢‡§æ‡§â‡§®‡•Å ‡§ö‡§æ‡§π‡§ø‡§®‡•ç‡§õ\n",
      "Corrected: ‡§Ø‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡•ã ‡§¨‡§ø‡§ï‡§æ‡§∏‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ ‡§®‡§ø‡§∞‡•ç‡§ß‡§æ‡§∞‡§£ ‡§ó‡§∞‡§ø ‡§≤‡§ó‡§æ‡§®‡•Ä ‡§¨‡§¢‡§æ‡§â‡§®‡•Å ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§õ ‡•§\n",
      "label:     ‡§Ø‡•Ä ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ï‡•ã ‡§µ‡§ø‡§ï‡§æ‡§∏‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ ‡§®‡§ø‡§∞‡•ç‡§ß‡§æ‡§∞‡§£ ‡§ó‡§∞‡•Ä ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ‡•ç‡§Ø ‡§Æ‡§æ‡§§‡•ç‡§∞‡§æ‡§Æ‡§æ ‡§≤‡§ó‡§æ‡§®‡•Ä ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§§‡§•‡§æ ‡§≤‡§ó‡§æ‡§®‡•Ä ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§≤‡•á ‡§ö‡§æ‡§¨‡•Ä ‡§ï‡§æ‡§ü‡•ç‡§¶‡•à ‡§õ ‡§•‡§æ‡§π‡§æ ‡§™‡§æ‡§è ‡§™‡§õ‡§ø ‡§≠‡§æ‡§®‡•ç‡§∏‡§æ ‡§§‡§≤‡§æ‡§Æ‡§æ ‡§â‡§ï‡•ç‡§≤‡§ø‡§è‡§∞ ‡§π‡§æ‡§Æ‡•ç‡§´‡§æ‡§≤‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ï‡§ø‡§® ‡§Ü‡§Ø\n",
      "Corrected: <extra_id_0>‡§≤‡•á ‡§ö‡§æ‡§¨‡•Ä ‡§ï‡§æ‡§ü‡§ø‡§∞‡§π‡•á‡§ï‡•ã ‡§õ ‡§•‡§æ‡§π‡§æ ‡§™‡§æ‡§è ‡§™‡§õ‡§ø ‡§≠‡§æ‡§®‡•ç‡§∏‡§æ ‡§§‡§≤‡§æ‡§Æ‡§æ ‡§â‡§ï‡•ç‡§≤‡§ø‡§è‡§∞ ‡§π‡§æ‡§Æ‡•ç‡§´‡§æ‡§≤‡§ø‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ï‡§ø‡§® ‡§Ü‡§Ø‡•ã ?\n",
      "label:     ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä‡§≤‡•á ‡§ö‡§æ‡§¨‡•Ä ‡§ï‡§æ‡§ü‡§ø‡§∞‡§π‡•á‡§ï‡•ã ‡§•‡§æ‡§π‡§æ ‡§™‡§æ‡§â‡§®‡•á ‡§¨‡§ø‡§§‡•ç‡§§‡§ø‡§ï‡•à ‡§≠‡§æ‡§®‡•ç‡§õ‡§æ ‡§∞‡§π‡•á‡§ï‡•ã ‡§§‡§≤‡§æ‡§Æ‡§æ ‡§â‡§ï‡•ç‡§≤‡§ø‡§è‡§∞ ‡§π‡§æ‡§Æ‡•ç‡§´‡§æ‡§≤‡§ø‡§π‡§æ‡§≤‡•ç‡§®‡•Å ‡§™‡§∞‡•ç‡§®‡•á ‡§ï‡§æ‡§∞‡§£ ‡§ï‡§ø‡§® ‡§Ü‡§Ø‡•ã?\n",
      "---\n",
      "Original:  ‡§¨‡§æ‡§π‡§ø‡§∞ ‡§¨‡§æ‡§ü ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§†‡§ø‡§ï ‡§†‡§æ‡§ï ‡§≤‡§æ‡§ó‡•ç‡§õ ‡§§‡§∞ ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§®‡§≠‡§è‡§ï‡•ã ‡§ï‡§æ‡§∞‡§£ ‡§â‡§®‡§ø‡§π‡§∞‡•Å ‡§ï‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§ï‡§æ‡§ü‡§ø‡§®‡•ç‡§õ‡§•‡•ç‡§Ø‡•ã\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§®‡§¨‡§æ‡§ü ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§†‡§ø‡§ï‡§†‡§æ‡§ï ‡§≤‡§æ‡§ó‡•á ‡§™‡§®‡§ø ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§®‡§≠‡§è‡§ï‡•ã ‡§ï‡§æ‡§∞‡§£ ‡§â‡§®‡§ø‡§π‡§∞‡•Å‡§ï‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§ï‡§æ‡§ü‡§ø‡§®‡•ç‡§•‡•ç‡§Ø‡•ã‡•§\n",
      "label:     ‡§¨‡§æ‡§π‡§ø‡§∞‡§¨‡§æ‡§ü ‡§π‡•á‡§∞‡•ç‡§¶‡§æ ‡§†‡•Ä‡§ï‡§†‡§æ‡§ï ‡§≤‡§æ‡§ó‡•á ‡§™‡§®‡§ø ‡§∏‡§®‡•ç‡§§‡§æ‡§® ‡§®‡§≠‡§è‡§ï‡•ã ‡§µ‡§ø‡§∑‡§Ø‡§≤‡•á ‡§â‡§®‡•Ä‡§π‡§∞‡•Å‡§ï‡•ã ‡§ï‡•Å‡§∞‡§æ ‡§ï‡§æ‡§ü‡§ø‡§®‡•ç‡§•‡•ç‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§¨‡§ø‡§ú‡•á‡§§‡§æ‡§≤‡•á ‡•© ‡§≤‡§æ‡§ñ ‡§â‡§™‡§¨‡§ø‡§ú‡•á‡§§‡§æ‡§≤‡•á ‡•ß ‡§≤‡§æ‡§ñ ‡•´‡•¶ ‡§π‡§ú‡§æ‡§∞ ‡§™‡§æ‡§â‡§®‡•á‡§õ\n",
      "Corrected: ‡§¨‡§ø‡§ú‡•á‡§§‡§æ‡§≤‡•á ‡•© ‡§≤‡§æ‡§ñ ‡§â‡§™‡§µ‡§ø‡§ú‡•á‡§§‡§æ‡§≤‡•á ‡•© ‡§≤‡§æ‡§ñ ‡•´‡•¶ ‡§π‡§ú‡§æ‡§∞ ‡§™‡§æ‡§â‡§®‡•á‡§õ ‡•§\n",
      "label:     ‡§µ‡§ø‡§ú‡•á‡§§‡§æ‡§≤‡•á ‡•© ‡§≤‡§æ‡§ñ ‡§∞ ‡§â‡§™‡§µ‡§ø‡§ú‡•á‡§§‡§æ‡§≤‡•á ‡•ß ‡§≤‡§æ‡§ñ ‡•´‡•¶ ‡§π‡§ú‡§æ‡§∞ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ó‡§∞‡•ç‡§®‡•á‡§õ‡§®‡•ç ‡•§\n",
      "---\n",
      "Original:  ‡§∞‡§æ‡§ú‡•ç‡§Ø ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ú‡§æ‡§® ‡§∏‡§ï‡•ç‡§¶‡•à‡§® ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§õ‡•à‡§®\n",
      "Corrected: ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ú‡§æ‡§® ‡§∏‡§ï‡•á‡§ï‡•ã ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§õ‡•à‡§®‡•§\n",
      "label:     ‡§∞‡§æ‡§ú‡•ç‡§Ø‡§ï‡•ã ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ú‡§æ‡§® ‡§∏‡§ï‡§ø‡§∞‡§π‡•á‡§ï‡•ã ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§õ‡•à‡§® ‡•§\n",
      "---\n",
      "Original:  ‡§™‡§∞‡•ç‡§Ø‡§ü‡§® ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä ‡§™‡§∞‡•ç‡§ü‡§ï‡§ï‡•ã ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§∏‡§Å‡§ó‡•à ‡§Ü‡§Æ ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å‡§¶‡•à ‡§â‡§®‡§≤ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï‡•Ä‡§Ø ‡§®‡§ó‡§∞‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§¨‡§®‡§æ‡§â‡§® ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§∞‡§π‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "Corrected: <extra_id_0> ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï‡•Ä‡§Ø ‡§®‡§ó‡§∞‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§¨‡§®‡§æ‡§â‡§® ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§∞‡§π‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å‡§¶‡•à ‡§â‡§®‡§≤‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï‡•Ä‡§Ø ‡§®‡§ó‡§∞‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§¨‡§®‡§æ‡§â‡§® ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§∞‡§π‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "label:     ‡§™‡§∞‡•ç‡§Ø‡§ü‡§® ‡§™‡•ç‡§∞‡§π‡§∞‡•Ä ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï‡§ï‡•ã ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ‡§∏‡§Å‡§ó‡•à ‡§Ü‡§Æ ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§∏‡•ç‡§•‡§æ‡§™‡§®‡§æ ‡§ó‡§∞‡§ø‡§è‡§ï‡•ã ‡§¨‡§§‡§æ‡§â‡§Å‡§¶‡•à ‡§â‡§®‡§≤‡•á ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï‡•Ä‡§Ø ‡§®‡§ó‡§∞‡•Ä ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§¨‡§®‡§æ‡§â‡§® ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§∞‡§π‡•á‡§ï‡•ã ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ‡§Æ‡§æ ‡§®‡§™‡§∞‡•á‡§ï‡•ã ‡§≠‡§∞‡•ç‡§®‡§æ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø‡§≤‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•à ‡§∂‡•à‡§≤‡•Ä‡§¨‡§æ‡§ü ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•ç‡§¶‡•à ‡§â‡§®‡§≤‡•á ‡§Ø‡§∏‡§≤‡•á ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ó‡§∞‡•ç‡§® ‡§®‡§∏‡§ï‡§ø‡§®‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "Corrected: <extra_id_0>‡§≤‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•à ‡§∂‡•à‡§≤‡•Ä‡§¨‡§æ‡§ü ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•ç‡§¶‡•à ‡§â‡§®‡§≤‡•á ‡§Ø‡§∏‡§≤‡•á ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ó‡§∞‡•ç‡§® ‡§®‡§∏‡§ï‡§ø‡§®‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "label:     ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§∏‡§∞‡§ï‡§æ‡§∞‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï‡§§‡§æ‡§Æ‡§æ ‡§®‡§™‡§∞‡•á‡§ï‡•ã ‡§≠‡§∞‡•ç‡§®‡§æ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø‡§≤‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•à ‡§∂‡•à‡§≤‡•Ä‡§¨‡§æ‡§ü ‡§∏‡•Å‡§∞‡•Å ‡§ó‡§∞‡•á‡§ï‡•ã ‡§≠‡§®‡•ç‡§¶‡•à ‡§â‡§®‡§≤‡•á ‡§Ø‡§∏‡§≤‡•á ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ‡§Æ‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ó‡§∞‡•ç‡§® ‡§®‡§∏‡§ï‡§ø‡§®‡•á ‡§¨‡§§‡§æ‡§è ‡•§\n",
      "---\n",
      "Original:  ‡§∏‡§Æ‡•ç‡§Æ‡•á‡§≤‡§® ‡§§‡§Ø‡§æ‡§∞‡•Ä‡§ï‡•ã ‡§≤‡§æ‡§ó‡§ø ‡§¶‡•á‡§ú‡§Æ‡•ã‡§≤‡•á ‡§Ø‡•ã ‡§´‡§æ‡§ó‡•Å‡§® ‡•≠ ‡§¶‡•á‡§ñ‡§ø ‡•®‡•ß ‡§∏‡§Æ‡•ç‡§Æ ‡§Æ‡•á‡§ö‡§ø ‡§Æ‡§π‡§æ‡§ï‡§æ‡§≤‡•Ä ‡§ú‡§®‡§ú‡§æ‡§ó‡§∞‡§£ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§ö‡§≤‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã\n",
      "Corrected: <extra_id_0>‡§≤‡•á ‡§Ø‡•ã ‡§´‡§æ‡§ó‡•Å‡§® ‡•≠ ‡§¶‡•á‡§ñ‡§ø ‡•®‡•ß ‡§ó‡§§‡•á ‡§Æ‡•á‡§ö‡§ø ‡§Æ‡§π‡§æ‡§ï‡§æ‡§≤‡•Ä ‡§ú‡§®‡§ú‡§æ‡§ó‡§∞‡§£ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§ö‡§≤‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§\n",
      "label:     ‡§∏‡§Æ‡•ç‡§Æ‡•á‡§≤‡§®‡§ï‡•ã ‡§§‡§Ø‡§æ‡§∞‡•Ä‡§ï‡§æ ‡§≤‡§æ‡§ó‡§ø ‡§¶‡•á‡§ú‡§Æ‡•ã‡§≤‡•á ‡§Ø‡§π‡•Ä ‡§´‡§æ‡§ó‡•Å‡§® ‡•≠ ‡§¶‡•á‡§ñ‡§ø ‡•®‡•ß ‡§ó‡§§‡•á ‡§∏‡§Æ‡•ç‡§Æ ‡§Æ‡•á‡§ö‡•Ä‡§Æ‡§π‡§æ‡§ï‡§æ‡§≤‡•Ä ‡§ú‡§® ‡§ú‡§æ‡§ó‡§∞‡§£ ‡§Ö‡§≠‡§ø‡§Ø‡§æ‡§® ‡§ö‡§≤‡§æ‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§Æ‡§æ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡§æ ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§¨‡§æ‡§ü ‡§ï‡•á ‡§ï‡§∏‡•ç‡§§‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡§ï‡•ã ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ó‡§∞‡•ç‡§® ‡§≠‡§®‡•ç‡§®‡•á ‡§µ‡§ø‡§∑‡§Ø‡§Æ‡§æ ‡§Æ‡§ø‡§∏‡§®‡§≤‡•á ‡§õ‡§≤‡§´‡§≤‡§ï‡•ã ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§æ ‡§∏‡§Æ‡•á‡§§ ‡§ó‡§∞‡•á‡§ï ‡§õ‡•§\n",
      "Corrected: <extra_id_0> ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§Æ‡§æ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡§æ ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§¨‡§æ‡§ü ‡§ï‡•á ‡§ï‡§∏‡•ç‡§§‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡§ï‡•ã ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ó‡§∞‡•ç‡§® ‡§≠‡§®‡•ç‡§®‡•á ‡§µ‡§ø‡§∑‡§Ø‡§Æ‡§æ ‡§Æ‡§ø‡§∏‡§®‡§≤‡•á ‡§õ‡§≤‡§´‡§≤‡§ï‡•ã ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§æ ‡§∏‡§Æ‡•á‡§§ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ‡•§\n",
      "label:     ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä‡§ï‡•ã ‡§≠‡•ç‡§∞‡§Æ‡§£‡§Æ‡§æ ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡§æ‡§Æ‡§æ ‡§∞‡§π‡•á‡§ï‡§æ ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø‡§¨‡§æ‡§ü ‡§ï‡•á ‡§ï‡§∏‡•ç‡§§‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡§ï‡•ã ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ó‡§∞‡•ç‡§®‡•á ‡§≠‡§®‡•ç‡§®‡•á ‡§µ‡§ø‡§∑‡§Ø‡§Æ‡§æ ‡§Æ‡§ø‡§∏‡§®‡§≤‡•á ‡§õ‡§≤‡§´‡§≤‡§ï‡•ã ‡§Ü‡§Ø‡•ã‡§ú‡§®‡§æ ‡§∏‡§Æ‡•á‡§§ ‡§ó‡§∞‡•á‡§ï‡•ã ‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§Ø‡§∏‡§∞‡•Ä ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡•Ä‡§≤ ‡§≠‡§è‡§∞ ‡§¨‡•ã‡§≤‡§æ‡§â‡§Å‡§õ ‡§Æ‡§≤‡§æ‡§à ‡§≤‡§æ‡§ó‡•ç‡§õ ‡§â‡§π‡§æ‡§Å ‡§™‡§®‡§ø ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§Æ‡§æ ‡§Ü‡§â‡§Å‡§õ\n",
      "Corrected: ‡§Ø‡§∏‡§∞‡•Ä ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡§ø‡§≤ ‡§≠‡§è‡§∞ ‡§¨‡•ã‡§≤‡§æ‡§â‡§Å‡§¶‡§æ ‡§Æ‡§≤‡§æ‡§à ‡§≤‡§æ‡§ó‡•ç‡§õ ‡§â‡§π‡§æ‡§Å ‡§™‡§®‡§ø ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§Æ‡§æ ‡§Ü‡§â‡§Å‡§õ‡•§\n",
      "label:     ‡§Ø‡§∏‡§∞‡•Ä ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§∏‡§Ç‡§µ‡•á‡§¶‡§®‡§∂‡§ø‡§≤ ‡§≠‡§è‡§∞ ‡§¨‡•ã‡§≤‡§æ‡§â‡§Å‡§¶‡§æ ‡§Æ‡§≤‡§æ‡§à ‡§≤‡§æ‡§ó‡•ç‡§õ ‡§â‡§π‡§æ‡§Å‡§π‡§∞‡•Å ‡§™‡§®‡§ø ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§Æ‡§æ ‡§Ü‡§â‡§®‡•Å‡§π‡•Å‡§®‡•ç‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡•ã ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡•ã ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ‡•á\n",
      "Corrected: ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§ï‡§∏‡•ç‡§§‡§æ ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡§æ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≤‡•ç‡§Ø‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ ?\n",
      "label:     ‡§®‡§ó‡§∞‡§™‡§æ‡§≤‡§ø‡§ï‡§æ‡§≤‡•á ‡§ï‡§∏‡•ç‡§§‡§æ ‡§ï‡§ø‡§∏‡§ø‡§Æ‡§ï‡§æ ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§≠‡§ø‡§§‡•ç‡§∞‡§æ‡§â‡§® ‡§∏‡§ï‡•ç‡§õ ?\n",
      "---\n",
      "Original:  ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§ï‡§æ‡§∞‡§ï‡•ã ‡§ó‡§†‡§® ‡§≠‡§è‡§™‡§õ‡§ø ‡§Ü‡§´‡•ç‡§®‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§Ö‡§®‡•Å‡§ï‡§≤‡§ï‡•ã ‡§µ‡§ø‡§ß‡§æ‡§®‡§π‡§∞‡•Ç ‡§∏‡•ç‡§µ‡•Ä‡§ï‡•É‡§§ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§≠‡§æ‡§≤‡•á ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡•§\n",
      "Corrected: <extra_id_0> ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ï‡•ã ‡§ó‡§†‡§® ‡§≠‡§è‡§™‡§õ‡§ø ‡§Ü‡§´‡•ç‡§®‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ï‡•ã ‡§µ‡§ø‡§ß‡§æ‡§®‡§π‡§∞‡•Ç ‡§∏‡•ç‡§µ‡•Ä‡§ï‡•É‡§§ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§≠‡§æ‡§≤‡•á ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡•§\n",
      "label:     ‡§™‡§¶‡•á‡§∂ ‡§∏‡§∞‡§ï‡§æ‡§∞‡§ï‡•ã ‡§ó‡§†‡§® ‡§≠‡§è‡§™‡§õ‡§ø ‡§Ü‡§´‡•ç‡§®‡§æ ‡§Ü‡§´‡•ç‡§®‡§æ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§ï‡•ã ‡§µ‡§ø‡§ß‡§æ‡§®‡§π‡§∞‡•Ç ‡§∏‡•ç‡§µ‡•Ä‡§ï‡•É‡§§ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§∏‡§≠‡§æ‡§≤‡•á ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ ‡§õ ‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡•à‡§≤‡•á ‡§¨‡§ø‡§π‡§æ‡§® ‡§ñ‡§æ‡§®‡§æ ‡§π‡•á‡§∞‡•á‡•§\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§® ‡§ñ‡§æ‡§®‡§æ ‡§π‡•á‡§∞‡•á‡•§\n",
      "label:     ‡§Æ‡•à‡§≤‡•á ‡§¨‡§ø‡§π‡§æ‡§® ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§è‡§Å‡•§\n",
      "---\n",
      "Original:  ‡§ä ‡§π‡§ø‡§ú‡•ã ‡§Ü‡§â‡§®‡•á‡§õ‡•§\n",
      "Corrected: ‡§ä ‡§π‡§ø‡§ú‡•ã ‡§Ü‡§â‡§®‡•á‡§õ‡•§\n",
      "label:     ‡§ä ‡§≠‡•ã‡§≤‡§ø ‡§Ü‡§â‡§®‡•á‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§Æ ‡§ñ‡§æ‡§®‡§æ ‡§™‡§ø‡§â‡§® ‡§ö‡§æ‡§π‡§®‡•ç‡§®\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§® ‡§ñ‡§æ‡§®‡§æ ‡§™‡§ø‡§â‡§® ‡§ö‡§æ‡§π‡§®‡•ç‡§®‡•§\n",
      "label:     ‡§Æ ‡§™‡§æ‡§®‡•Ä ‡§™‡§ø‡§â‡§® ‡§ö‡§æ‡§π‡§®‡•ç‡§®‡•§\n",
      "---\n",
      "Original:  ‡§¨‡§ø‡§∞‡•ç‡§ñ‡•á‡§≤‡•á ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§ñ‡§æ‡§Ø‡•ã‡•§\n",
      "Corrected: <extra_id_0>‡§≤‡•á ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§™‡§¢‡•ç‡§Ø‡•ã‡•§\n",
      "label:     ‡§¨‡§ø‡§∞‡•ç‡§ñ‡•á‡§≤‡•á ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§™‡§¢‡•ç‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§∏‡•Ç‡§∞‡•ç‡§Ø ‡§™‡§∂‡•ç‡§ö‡§ø‡§Æ‡§¨‡§æ‡§ü ‡§â‡§¶‡§æ‡§â‡§Å‡§õ‡•§\n",
      "Corrected: ‡§∏‡•Ç‡§∞‡•ç‡§Ø ‡§™‡•Ç‡§∞‡•ç‡§µ‡§¨‡§æ‡§ü ‡§â‡§¶‡§æ‡§â‡§Å‡§õ‡•§\n",
      "label:     ‡§∏‡•Ç‡§∞‡•ç‡§Ø ‡§™‡•Ç‡§∞‡•ç‡§µ‡§¨‡§æ‡§ü ‡§â‡§¶‡§æ‡§â‡§Å‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§Ü‡§ú ‡§Æ ‡§¨‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§®‡§ú‡§æ‡§®‡•á‡§õ‡•Å ‡§ï‡§ø‡§®‡§≠‡§®‡•á ‡§Æ ‡§ó‡§è‡§Å‡•§\n",
      "Corrected: ‡§¨‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§ó‡§è‡§Å‡•§\n",
      "label:     ‡§Ü‡§ú ‡§Æ ‡§¨‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§ó‡§è‡§Å‡•§\n",
      "---\n",
      "Original:  ‡§Æ ‡§ï‡•Å‡§ñ‡•Å‡§∞‡§æ‡§≤‡§æ‡§à ‡§¶‡•Ç‡§ß ‡§™‡§ø‡§≤‡§æ‡§è‡§Å‡•§\n",
      "Corrected: <extra_id_0> ‡§¶‡•Ç‡§ñ‡•Å‡§∞‡§æ‡§≤‡§æ‡§à ‡§¶‡•Ç‡§∞ ‡§™‡§ø‡§è‡§Å‡•§\n",
      "label:     ‡§Æ ‡§ï‡•Å‡§ñ‡•Å‡§∞‡§æ‡§≤‡§æ‡§à ‡§¶‡§æ‡§®‡§æ ‡§ñ‡•Å‡§µ‡§æ‡§è‡§Å‡•§\n",
      "---\n",
      "Original:  ‡§π‡§æ‡§µ‡§æ ‡§§‡§æ‡§§‡•ã ‡§ñ‡§æ‡§®‡•ç‡§õ‡•§\n",
      "Corrected: ‡§§‡§æ‡§§‡•ã ‡§ñ‡§æ‡§®‡•ç‡§õ‡•§\n",
      "label:     ‡§π‡§æ‡§µ‡§æ ‡§§‡§æ‡§§‡•ã ‡§π‡•Å‡§®‡•ç‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§ä ‡§ò‡§æ‡§Æ‡§Æ‡§æ ‡§®‡•Å‡§π‡§æ‡§â‡§Å‡§¶‡•à ‡§•‡§ø‡§Ø‡•ã‡•§\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§® ‡§ò‡§æ‡§Æ‡§Æ‡§æ ‡§®‡•Å‡§π‡§æ‡§â‡§Å‡§¶‡•à ‡§•‡§ø‡§Ø‡•ã‡•§\n",
      "label:     ‡§ä ‡§ò‡§æ‡§Æ‡§Æ‡§æ ‡§§‡§æ‡§§‡§ø‡§Å‡§¶‡•à ‡§•‡§ø‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§Æ‡•á‡§∞‡•ã ‡§´‡•ã‡§® ‡§¶‡•Å‡§ñ‡•ç‡§Ø‡•ã‡•§\n",
      "Corrected: <extra_id_0> ‡§¶‡•Å‡§ñ‡•ç‡§Ø‡•ã‡•§\n",
      "label:     ‡§Æ‡•á‡§∞‡•ã ‡§ò‡§æ‡§Å‡§ü‡•Ä ‡§¶‡•Å‡§ñ‡•ç‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§Æ ‡§ï‡§æ‡§ó‡§ú‡§Æ‡§æ ‡§∏‡•Å‡§§‡•ç‡§õ‡•Å‡•§\n",
      "Corrected: <extra_id_0> ‡§∏‡•Å‡§§‡•ç‡§õ‡•Å‡•§\n",
      "label:     ‡§Æ ‡§ì‡§õ‡•ç‡§Ø‡§æ‡§®‡§Æ‡§æ ‡§∏‡•Å‡§§‡•ç‡§õ‡•Å‡•§\n",
      "---\n",
      "Original:  ‡§™‡§æ‡§®‡•Ä‡§≤‡•á ‡§Ü‡§ó‡•ã ‡§ú‡§≤‡§æ‡§Ø‡•ã‡•§\n",
      "Corrected: ‡§™‡§æ‡§®‡•Ä‡§≤‡•á ‡§Ü‡§ó‡•ã ‡§ú‡§≤‡§æ‡§Ø‡•ã‡•§\n",
      "label:     ‡§™‡§æ‡§®‡•Ä‡§≤‡•á ‡§Ü‡§ó‡•ã ‡§®‡§ø‡§≠‡§æ‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§π‡§ú‡•Å‡§∞‡§Ü‡§Æ‡§æ‡§≤‡•á ‡§ü‡•á‡§≤‡§ø‡§≠‡§ø‡§ú‡§® ‡§∏‡•Å‡§®‡•á‡•§\n",
      "Corrected: <extra_id_0> ‡§π‡§ú‡•Å‡§∞‡§Ü‡§Æ‡§æ‡§≤‡•á ‡§ü‡•á‡§≤‡§ø‡§≠‡§ø‡§ú‡§® ‡§ö‡§≤‡§æ‡§â‡§®‡•á‡•§\n",
      "label:     ‡§π‡§ú‡•Å‡§∞‡§Ü‡§Æ‡§æ‡§≤‡•á ‡§ü‡•á‡§≤‡§ø‡§≠‡§ø‡§ú‡§® ‡§π‡•á‡§∞‡•á‡•§\n",
      "---\n",
      "Original:  ‡§ï‡•Å‡§∞‡•ç‡§∏‡•Ä‡§≤‡•á ‡§Æ‡§≤‡§æ‡§à ‡§π‡§ø‡§Å‡§°‡§æ‡§Ø‡•ã‡•§\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§® ‡§Æ‡§≤‡§æ‡§à ‡§π‡§ø‡§Å‡§ü‡§æ‡•§\n",
      "label:     ‡§Æ‡•à‡§≤‡•á ‡§ï‡•Å‡§∞‡•ç‡§∏‡•Ä ‡§∏‡§æ‡§∞‡•á‡§Ç‡•§\n",
      "---\n",
      "Original:  ‡§ï‡•Å‡§ï‡•Å‡§∞‡§≤‡•á ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§≤‡•á‡§ñ‡•ç‡§Ø‡•ã‡•§\n",
      "Corrected: <extra_id_0>‡•§\n",
      "label:     ‡§Æ‡§æ‡§®‡§ø‡§∏‡§≤‡•á ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§≤‡•á‡§ñ‡•ç‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§Ü‡§ï‡§æ‡§∂ ‡§≠‡•Å‡§á‡§Å‡§Æ‡§æ ‡§õ‡•§\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§®‡§ï‡•ã ‡§Ü‡§ï‡§æ‡§∂‡§Æ‡§æ ‡§õ‡•§\n",
      "label:     ‡§Ü‡§ï‡§æ‡§∂ ‡§Æ‡§æ‡§•‡§ø ‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§Æ ‡§™‡•á‡§®‡§≤‡•á ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§õ‡•Å‡•§\n",
      "Corrected: <extra_id_0> ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§õ‡•Å‡•§\n",
      "label:     ‡§Æ ‡§Æ‡•Å‡§ñ‡§≤‡•á ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§õ‡•Å‡•§\n",
      "---\n",
      "Original:  ‡§ä ‡§™‡§∞‡§æ‡§≤‡§Æ‡§æ ‡§™‡•å‡§°‡§ø‡§Ø‡•ã‡•§\n",
      "Corrected: ‡§ä ‡§™‡§∞‡§æ‡§≤‡§Æ‡§æ ‡§™‡•å‡§°‡§ø‡§Ø‡•ã‡•§\n",
      "label:     ‡§ä ‡§™‡§æ‡§®‡•Ä‡§Æ‡§æ ‡§™‡•å‡§°‡§ø‡§Ø‡•ã‡•§\n",
      "---\n",
      "Original:  ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡§ø‡§π‡§æ‡§® ‡§¨‡§®‡•ç‡§¶ ‡§π‡•Å‡§®‡•ç‡§õ‡•§\n",
      "Corrected: ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡§ø‡§π‡§æ‡§® ‡§ñ‡•Å‡§≤‡•ç‡§õ‡•§\n",
      "label:     ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§¨‡§ø‡§π‡§æ‡§® ‡§ñ‡•Å‡§≤‡•ç‡§õ‡•§\n",
      "---\n",
      "Original:  ‡§Æ ‡§π‡§ø‡§ú‡•ã ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å‡•§\n",
      "Corrected: ‡§¨‡§ø‡§π‡§æ‡§® ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å‡•§\n",
      "label:     ‡§Æ ‡§≠‡•ã‡§≤‡§ø ‡§ú‡§æ‡§®‡•ç‡§õ‡•Å‡•§\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def correct_batch(texts, batch_size=8):\n",
    "    \"\"\"\n",
    "    Correct grammar for multiple sentences\n",
    "    \"\"\"\n",
    "    corrected_texts = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # Add prefix to each text\n",
    "        input_texts = [f\"‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§∏‡•Å‡§ß‡§æ‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç: {text}\" for text in batch_texts]\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            input_texts,\n",
    "            return_tensors = \"pt\",\n",
    "            truncation = True,\n",
    "            padding=True\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generate correction\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs.input_ids,\n",
    "                # attention_mask=inputs.attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=5,\n",
    "                repetition_penalty=2.5\n",
    "            )\n",
    "            \n",
    "        # Decode batch\n",
    "        batch_corrected = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        corrected_texts.extend(batch_corrected)\n",
    "        \n",
    "    return corrected_texts\n",
    "        \n",
    "    \n",
    "test_sentences = small_dataset[\"train\"][\"incorrect_sentence\"][:]\n",
    "labels = small_dataset[\"train\"][\"correct_sentence\"][:]\n",
    "corrected_sentences = correct_batch(test_sentences)\n",
    "for orig, corr, lab in zip(test_sentences, corrected_sentences, labels):\n",
    "    print(f\"Original:  {orig}\")\n",
    "    print(f\"Corrected: {corr}\")\n",
    "    print(f\"label:     {lab}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0042d6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sample - Pred: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§ ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡§æ ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡•Ä ‡§ó‡•Å...' | Ref: '‡§Ø‡•Ä ‡§¶‡•Å‡§à ‡§π‡§æ‡§§‡§π‡§∞‡•Ç ‡§Æ‡§ø‡§≤‡•ç‡§¶‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§Æ‡•à ‡§∂‡§æ‡§®‡•ç‡§§‡§ø‡§ï‡•ã ‡§∏‡•Å‡§Æ‡§ß‡•Å‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø...' | Match: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.315693833959732,\n",
       " 'chrf': 62.606904147812315,\n",
       " 'correction_accuracy': np.float64(0.05),\n",
       " 'bertscore_f1': 0.8399195969104767}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics((corrected_sentences, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f608f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
