{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "97c1d673",
      "metadata": {
        "id": "97c1d673"
      },
      "source": [
        "Fine-tuning mt5 model with sumit aryal's nepali_grammatical_error_correction dataset in hugging face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758f7799",
      "metadata": {
        "id": "758f7799"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from transformers import MT5Tokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import random\n",
        "# Set all seeds for reproducibility\n",
        "random.seed(100)\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed_all(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c605006",
      "metadata": {
        "id": "9c605006"
      },
      "outputs": [],
      "source": [
        "\n",
        "ds = load_dataset(\"sumitaryal/nepali_grammatical_error_correction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccfe917b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccfe917b",
        "outputId": "932ba7ab-3ffb-47cf-b2fa-569282ddb271"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['incorrect_sentence', 'correct_sentence'],\n",
              "        num_rows: 7723971\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['incorrect_sentence', 'correct_sentence'],\n",
              "        num_rows: 406525\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741bb34d",
      "metadata": {
        "id": "741bb34d"
      },
      "outputs": [],
      "source": [
        "# Since only train and valid dataset is given we need to seperate train dataset to train and test\n",
        "# so we will have train, test and valid dataset with approximately equal test and valid data\n",
        "\n",
        "dataset = ds[\"train\"].train_test_split(test_size=0.05, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e343fd75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e343fd75",
        "outputId": "e810741f-bf41-4fcb-afa3-69b50e3b2486"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['incorrect_sentence', 'correct_sentence'],\n",
              "        num_rows: 7337772\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['incorrect_sentence', 'correct_sentence'],\n",
              "        num_rows: 386199\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aed26a1",
      "metadata": {
        "id": "7aed26a1"
      },
      "outputs": [],
      "source": [
        "dataset[\"valid\"] = ds[\"valid\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ac334f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7ac334f",
        "outputId": "36fd97bc-e4a1-4992-ac9c-7eda3b35e3e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['incorrect_sentence', 'correct_sentence'],\n",
              "        num_rows: 7337772\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['incorrect_sentence', 'correct_sentence'],\n",
              "        num_rows: 386199\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['incorrect_sentence', 'correct_sentence'],\n",
              "        num_rows: 406525\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db77f12a",
      "metadata": {
        "id": "db77f12a"
      },
      "outputs": [],
      "source": [
        "# # For each split, take 1% using train_test_split\n",
        "\n",
        "# from datasets import DatasetDict\n",
        "\n",
        "# dataset = DatasetDict({\n",
        "#     'train': dataset['train'].train_test_split(test_size=0.001, seed=42)['test'],\n",
        "#     'test': dataset['test'].train_test_split(test_size=0.001, seed=42)['test'],\n",
        "#     'valid': dataset['valid'].train_test_split(test_size=0.001, seed=42)['test']\n",
        "# })\n",
        "\n",
        "# print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483da6e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "483da6e0",
        "outputId": "ae56aad7-cab1-462e-c739-67632e421936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'incorrect_sentence': Value('string'), 'correct_sentence': Value('string')}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"].features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bfb7ad0",
      "metadata": {
        "id": "7bfb7ad0"
      },
      "source": [
        "Dataset Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "651eac84",
      "metadata": {
        "id": "651eac84"
      },
      "outputs": [],
      "source": [
        "# set dataset to dataframe because we can use high level apis for data visualization\n",
        "# dataset.set_format(type=\"pandas\")\n",
        "# df = dataset[\"train\"][:]\n",
        "# df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9b8f49",
      "metadata": {
        "id": "3b9b8f49"
      },
      "outputs": [],
      "source": [
        "# Count ALL duplicate occurrences (including first)\n",
        "# print(f\"All duplicate rows: {df['correct_sentence'].duplicated(keep=False).sum()}\")\n",
        "\n",
        "# # Count only the first occurrence of each duplicate group\n",
        "# unique_duplicates = df['correct_sentence'].duplicated().sum()\n",
        "# print(f\"Duplicate copies: {unique_duplicates}\")\n",
        "\n",
        "# # See which values are duplicated\n",
        "# duplicate_values = df[df['correct_sentence'].duplicated(keep=False)]['correct_sentence'].unique()\n",
        "# print(f\"Number of unique sentences that have duplicates: {len(duplicate_values)}\")\n",
        "\n",
        "# unique_correct_sentences = df['correct_sentence'].unique()\n",
        "# print(f\"Number of unique correct sentences: {len(unique_correct_sentences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c620ca22",
      "metadata": {
        "id": "c620ca22"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import pandas as pd\n",
        "\n",
        "# # Length distribution of incorrect vs correct sentences\n",
        "# incorrect_lengths = [len(sent.split()) for sent in df['incorrect_sentence']]\n",
        "# correct_lengths = [len(sent.split()) for sent in df['correct_sentence']]\n",
        "\n",
        "# plt.figure(figsize=(12, 4))\n",
        "\n",
        "# # Use histplot or kdeplot instead of barplot for distribution visualization\n",
        "# plt.subplot(1, 2, 1)\n",
        "# sns.histplot(incorrect_lengths, label='Incorrect', alpha=0.7, kde=True, color='red')\n",
        "# sns.histplot(correct_lengths, label='Correct', alpha=0.7, kde=True, color='blue')\n",
        "# plt.legend()\n",
        "# plt.title('Sentence Length Distribution')\n",
        "# plt.xlabel('Number of Words')\n",
        "# plt.ylabel('Frequency')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# sns.boxplot(data=[incorrect_lengths, correct_lengths])\n",
        "# plt.xticks([0, 1], ['Incorrect', 'Correct'])\n",
        "# plt.title('Sentence Length Boxplot')\n",
        "# plt.ylabel('Number of Words')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4650e71b",
      "metadata": {
        "id": "4650e71b"
      },
      "outputs": [],
      "source": [
        "# resetting dataset format since we don't need df format anymore\n",
        "# dataset.reset_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22198d1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22198d1a",
        "outputId": "ff56df9f-f6a6-4b0a-e0c7-09b872d7e078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3a0c63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e3a0c63",
        "outputId": "bab25228-990f-4903-bd76-7ac5848b0f6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "# Define tokenizer and model\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_ckpt = \"google/mt5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbfeb7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdbfeb7a",
        "outputId": "fe72f864-180c-484f-b459-43e22929daf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [12278, 43508, 1048, 2139, 13345, 19650, 39688, 4096, 1195, 259, 145610, 144308, 9941, 259, 68409, 157242, 259, 378, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['‚ñÅ‡§§‡•ç‡§Ø', '‡§∏‡•à', '‡§≤‡•á', '‚ñÅ‡§â', '‡§π‡§æ‡§Å', '‚ñÅ‡§Ø‡•ã', '‚ñÅ‡§Æ‡•Å‡§¶‡•ç', '‡§¶‡§æ', '‡§Æ‡§æ', '‚ñÅ', '‡§á‡§ú', '‡§≤‡§æ‡§∏', '‡§¨‡§æ‡§ü', '‚ñÅ', '‡§π‡§ü', '‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ', '‚ñÅ', '‡•§', '</s>']\n",
            "‡§§‡•ç‡§Ø‡§∏‡•à‡§≤‡•á ‡§â‡§π‡§æ‡§Å ‡§Ø‡•ã ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ‡§Æ‡§æ ‡§á‡§ú‡§≤‡§æ‡§∏‡§¨‡§æ‡§ü ‡§π‡§ü‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§</s>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "250100"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"‡§§‡•ç‡§Ø‡§∏‡•à‡§≤‡•á ‡§â‡§π‡§æ‡§Å ‡§Ø‡•ã ‡§Æ‡•Å‡§¶‡•ç‡§¶‡§æ‡§Æ‡§æ ‡§á‡§ú‡§≤‡§æ‡§∏‡§¨‡§æ‡§ü ‡§π‡§ü‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡•§\"\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)\n",
        "print(tokenizer.convert_tokens_to_string(tokens))\n",
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7533d39e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7533d39e",
        "outputId": "36f1f286-94e8-423d-dd5e-8662f8038197"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'incorrect_sentence': ['‡§Ü‡§´‡•ç‡§®‡•ã ‡§®‡§ø‡§∑‡•ç‡§†‡§æ ‡§®‡§õ‡•ã‡§°‡•Ä ‡•§',\n",
              "  '‡§´‡•à‡§≤‡§ø‡§Å‡§¶‡•ã ‡§ö‡§ø‡§Ø‡§æ ‡§ñ‡•á‡§§‡•Ä ‡§∞ ‡§ò‡§ü‡•ç‡§¶‡•ã ‡§ï‡§æ‡§Æ‡§¶‡§æ‡§∞‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§ñ‡•á‡§§‡•Ä‡§µ‡§æ‡§≤‡§æ‡§≤‡•á ‡§®‡•à‡§∏‡§¨‡•à ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•ç‡§® ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§ï‡•É‡§∑‡§ï‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§‡§§‡§æ ‡•ß‡•® ‡§Æ‡§π‡§ø‡§®‡§æ ‡§®‡•à ‡§â‡§∏‡•ç‡§§‡•à ‡§õ ‡•§'],\n",
              " 'correct_sentence': ['‡§Ü‡§´‡•ç‡§®‡•ã ‡§®‡§ø‡§∑‡•ç‡§†‡§æ ‡§®‡§õ‡•ã‡§°‡•Ä ‡§¨‡§∏‡•ç‡§®‡•Å‡§≠‡§Ø‡•ã ‡•§',\n",
              "  '‡§´‡•à‡§≤‡§ø‡§Å‡§¶‡•ã ‡§ö‡§ø‡§Ø‡§æ ‡§ñ‡•á‡§§‡•Ä ‡§∞ ‡§ò‡§ü‡•ç‡§¶‡•ã ‡§ï‡§æ‡§Æ‡§¶‡§æ‡§∞‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£ ‡§ñ‡•á‡§§‡•Ä‡§µ‡§æ‡§≤‡§æ‡§≤‡•á ‡§®‡•à‡§∏‡§¨‡•à ‡§ï‡§æ‡§Æ ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§®‡•á ‡§≠‡§è‡§ï‡§æ‡§≤‡•á ‡§ï‡•É‡§∑‡§ï‡§ï‡•ã ‡§µ‡•ç‡§Ø‡§∏‡•ç‡§§‡§§‡§æ ‡•ß‡•® ‡§Æ‡§π‡§ø‡§®‡§æ ‡§®‡•à ‡§â‡§∏‡•ç‡§§‡•à ‡§õ ‡•§']}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b3f6298",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b3f6298",
        "outputId": "85672475-7121-482a-e93e-ac19923df784"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [[943, 10430, 14656, 259, 145937, 33541, 259, 863, 225461, 11085, 259, 378, 1], [6389, 4439, 23717, 7929, 53069, 29847, 2075, 55208, 2376, 259, 996, 24981, 99474, 9780, 8520, 18413, 1770, 259, 13576, 55208, 2376, 38961, 1048, 259, 9357, 2312, 47161, 8520, 11435, 259, 15246, 68448, 67611, 111238, 91753, 13378, 1114, 259, 67522, 59051, 1437, 259, 9357, 2139, 62909, 2237, 259, 378, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[943, 10430, 14656, 259, 145937, 33541, 259, 863, 225461, 11085, 259, 208662, 68782, 259, 378, 1], [6389, 4439, 23717, 7929, 53069, 29847, 2075, 55208, 2376, 259, 996, 24981, 99474, 9780, 8520, 18413, 1770, 259, 13576, 55208, 2376, 38961, 1048, 259, 9357, 2312, 47161, 8520, 2661, 121003, 259, 15246, 68448, 67611, 111238, 91753, 13378, 1114, 259, 67522, 59051, 1437, 259, 9357, 2139, 62909, 2237, 259, 378, 1]]}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def tokenize(batch):\n",
        "    # tokenize input (incorrect)\n",
        "    input_encodings = tokenizer(\n",
        "        batch[\"incorrect_sentence\"],\n",
        "        padding=False,       # No padding during tokenization  # keep sentences at natural length\n",
        "        truncation=True,\n",
        "    )\n",
        "    # tokenize target (correct)\n",
        "    target_encodings = tokenizer(\n",
        "        batch[\"correct_sentence\"],\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    # set labels for seq2seq training                           # for seq2deq models, the \"labels\" are the token IDs of the target sequence\n",
        "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]\n",
        "\n",
        "    return input_encodings\n",
        "\n",
        "\n",
        "print(tokenize(dataset[\"train\"][:2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "333d584a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "359759b571b243b7b13cff29c54ecb3f",
            "e92c72a940104ce7b0271ecfa9011798",
            "571dfff6044b4624b40aba1afa7ad23c",
            "2455d20f04f345a9a48348a668f0475e",
            "2e1a59814ed14eb398cb876281f54038",
            "761fa926c6344af2a4628d23e42514a9",
            "78c9afd66a0b4121904d910ea7f8c01f",
            "4efd170bca2a4b7ca6eacf89fa90b045",
            "5072002b615b461cb281456489c9c707",
            "70c224ccc63c44739828db02c3853b4b",
            "8f198cfbfa504878b2c9d0be4e58ca99",
            "38c2f6b8c1944a3b8c1d6c435f479758",
            "30ed219336e34155a8bb4e5137b7410e",
            "f1226541983e48ac92bd99f52d012697",
            "ac1af4fed0e94bf0924d9dad4d98b101",
            "2b7df8136f8b473e966b9c30cef44e6d",
            "91030c35f86e49cfafe320cae795d40e",
            "53075c8c817d4229b77e1aba7d07d979",
            "c876c49ae71c4cc1a296a3a9b377ff32",
            "46fcc7e3dda24848b902b8535da79b1a",
            "d68684a5ca5a46b0b9f3cc6d7dc2d1b9",
            "6c1e9a0abf224d90a643244d2bcf4c67",
            "f66252285e2d4830bc2a028508177fe8",
            "4521e0c4323f4a4ba60ce95dd92b8bf9",
            "d768fda3b49943b9a0192695d9d37974",
            "d6f3de837df84e3cbcc6fef0e3db2cfb",
            "78ac7830c76e457c98a3aceb4c3011c2",
            "80eccb80c7fb460287ea437b5f345353",
            "e1cf5c4262384bf2bc06ae17a045afeb",
            "ee76d922c64741b284eeeb4890db164a",
            "844ec81fa2144032a09d7985117aac90",
            "755daf6c0eb945b296a80feda6117162",
            "42754588627a4d4cae282a41e3754290"
          ]
        },
        "id": "333d584a",
        "outputId": "7980da26-7a35-46eb-b33e-a33473149e02"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "359759b571b243b7b13cff29c54ecb3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7337772 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38c2f6b8c1944a3b8c1d6c435f479758",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/386199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f66252285e2d4830bc2a028508177fe8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/406525 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# apply tokenize function across all the splits in corpus\n",
        "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2253b587",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2253b587",
        "outputId": "0aaddbef-8f54-473f-fe0e-610986b0e64b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['incorrect_sentence',\n",
              " 'correct_sentence',\n",
              " 'input_ids',\n",
              " 'attention_mask',\n",
              " 'labels']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_encoded[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9ac2e4",
      "metadata": {
        "id": "8c9ac2e4"
      },
      "outputs": [],
      "source": [
        "# Pytorch expects input in tensor format\n",
        "# enables parallel computation on GPU, Optmize storage and operations, automatic differentiation\n",
        "dataset_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baab3891",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baab3891",
        "outputId": "41a26c4e-0101-4da6-8456-c20cc18c72e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49af2327",
      "metadata": {
        "id": "49af2327"
      },
      "outputs": [],
      "source": [
        "# # ! pip install wandb\n",
        "# import wandb\n",
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6XrFttHR2bhm",
      "metadata": {
        "id": "6XrFttHR2bhm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ! pip install evaluate\n",
        "# ! pip install sacrebleu\n",
        "# ! pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc9ca94",
      "metadata": {
        "id": "abc9ca94"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "# Load metrics once\n",
        "bleu_metric = evaluate.load(\"sacrebleu\")\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "gleu_metric = evaluate.load(\"google_bleu\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # 1Ô∏è‚É£ Convert logits ‚Üí predicted token IDs (if logits provided)\n",
        "    if predictions.ndim == 3:\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    # 2Ô∏è‚É£ Align sequence lengths if needed\n",
        "    min_len = min(predictions.shape[1], labels.shape[1])\n",
        "    predictions = predictions[:, :min_len]\n",
        "    labels = labels[:, :min_len]\n",
        "\n",
        "    # 3Ô∏è‚É£ Replace -100 with pad token ID (for decoding)\n",
        "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # 4Ô∏è‚É£ Decode to text\n",
        "    pred_texts = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    label_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # DEBUG: Show sample outputs\n",
        "    print(f\"Sample predictions and labels:\")\n",
        "    for i in range(min(3, len(pred_texts))):\n",
        "        print(f\"Pred {i}: '{pred_texts[i]}'\")\n",
        "        print(f\"Label {i}: '{label_texts[i]}'\")\n",
        "        print(f\"Pred length: {len(pred_texts[i])}, Label length: {len(label_texts[i])}\")\n",
        "        print(\"---\")\n",
        "\n",
        "    # 5Ô∏è‚É£ Token accuracy (ignoring -100s)\n",
        "    mask = labels != tokenizer.pad_token_id\n",
        "    correct_tokens = np.sum((predictions == labels) & mask)\n",
        "    total_tokens = np.sum(mask)\n",
        "    token_accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0.0\n",
        "\n",
        "    # 6Ô∏è‚É£ Remove empty pairs for text metrics\n",
        "    non_empty_pairs = [(p.strip(), l.strip()) for p, l in zip(pred_texts, label_texts) if p.strip() and l.strip()]\n",
        "\n",
        "    metrics = {\"eval_token_accuracy\": token_accuracy}\n",
        "\n",
        "    if non_empty_pairs:\n",
        "        preds, refs = zip(*non_empty_pairs)\n",
        "\n",
        "        try:\n",
        "            bleu = bleu_metric.compute(predictions=preds, references=[[r] for r in refs])\n",
        "            metrics[\"eval_BLEU\"] = bleu[\"score\"]\n",
        "        except Exception as e:\n",
        "            print(f\"BLEU error: {e}\")\n",
        "            metrics[\"eval_BLEU\"] = 0.0\n",
        "        try:\n",
        "            gleu = gleu_metric.compute(predictions=preds, references=[[r] for r in refs])\n",
        "            metrics[\"eval_GLEU\"] = gleu[\"google_bleu\"]\n",
        "        except Exception as e:\n",
        "            print(f\"GLEU error: {e}\")\n",
        "            metrics[\"eval_GLEU\"] = 0.0\n",
        "\n",
        "        try:\n",
        "            rouge = rouge_metric.compute(predictions=preds, references=refs)\n",
        "            metrics[\"eval_ROUGE-L\"] = rouge[\"rougeL\"]\n",
        "        except Exception as e:\n",
        "            print(f\"ROUGE error: {e}\")\n",
        "            metrics[\"eval_ROUGE-L\"] = 0.0\n",
        "    else:\n",
        "        metrics.update({\"eval_BLEU\": 0.0, \"eval_ROUGE-L\": 0.0})\n",
        "\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e026c48a",
      "metadata": {
        "id": "e026c48a"
      },
      "outputs": [],
      "source": [
        "#  when we prepare our batch, we set up the decoder inputs by shifting the labels to\n",
        "#  the right by one. After that, we make sure the padding tokens in the labels are ignored\n",
        "#  by the loss function by setting them to ‚Äì100. We actually don‚Äôt have to do this manually,\n",
        "#  though, since the DataCollatorForSeq2Seq comes to the rescue and takes care\n",
        "#  of all these steps for us\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True) # dynamic padding to longest in batch\n",
        "# no need to pad during tokenization it will only waste memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74418ea2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "74418ea2",
        "outputId": "72d539fa-9b2f-4ebd-bb90-114b52bfbb23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">mt5-nepali</strong> at: <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/wzldhhuc' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/wzldhhuc</a><br> View project at: <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251023_133003-wzldhhuc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251023_133252-sezlfher</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/sezlfher' target=\"_blank\">mt5-nepali</a></strong> to <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/sezlfher' target=\"_blank\">https://wandb.ai/lsumit008-khwopa-college-of-engineering/nepali-grammar-correction/runs/sezlfher</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback, TrainerCallback\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "wandb.init(project=\"nepali-grammar-correction\", name=\"mt5-nepali\")\n",
        "\n",
        "batch_size = 16\n",
        "num_train_epochs = 5\n",
        "gradient_accumulation_steps = 2\n",
        "learning_rate = 5e-5\n",
        "weight_decay = 0.01\n",
        "lr_scheduler_type = \"linear\"\n",
        "steps_per_epoch = len(dataset_encoded[\"train\"]) // (batch_size * gradient_accumulation_steps)     # no. of steps per epoch # log once per epoch\n",
        "logging_steps = max(1, steps_per_epoch // 20)                                                     # Log 20 times per epoch\n",
        "num_training_steps = steps_per_epoch * num_train_epochs\n",
        "warmup_steps = int(0.05 * num_training_steps)\n",
        "\n",
        "\n",
        "model_name = f\"{model_ckpt}-finetuned-gec\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(f\"../outputs/checkpoints/{model_name}\", exist_ok=True)\n",
        "os.makedirs(\"../outputs/best_model\", exist_ok=True)\n",
        "os.makedirs(\"../outputs/logs\", exist_ok=True)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(output_dir=f\"../outputs/checkpoints/{model_name}\",\n",
        "                                         num_train_epochs=num_train_epochs,\n",
        "\n",
        "                                         # Memory Optimization:\n",
        "                                         per_device_train_batch_size=batch_size,\n",
        "                                         per_device_eval_batch_size=batch_size,\n",
        "                                         gradient_accumulation_steps=gradient_accumulation_steps,  # Simulate larger batch size eg: 8 * 2 = 16\n",
        "                                         fp16=False,                                                # Use mixed precision if GPU supports it\n",
        "\n",
        "                                         # Logging & Saving:\n",
        "                                         logging_dir=\"../outputs/logs\",\n",
        "                                         logging_steps=10,    # log the training loss and metrics every X steps\n",
        "                                         eval_strategy=\"epochs\",          # performs evaluation per epoch\n",
        "                                        #  eval_steps=10000,\n",
        "                                         save_strategy=\"epochs\",          # saves model checkpoint per epoch\n",
        "                                        #  save_steps=230000,\n",
        "                                         save_total_limit=3,             # keep last 3 checkpoints\n",
        "                                         overwrite_output_dir=True,      # Overwrite previous runs\n",
        "\n",
        "                                         # Best Model saving:\n",
        "                                         load_best_model_at_end=True,        # Load the best model at the end\n",
        "                                         metric_for_best_model=\"eval_loss\",   # Use eval_loss to determine best model\n",
        "                                         greater_is_better=False,            # Lower eval_loss is better\n",
        "\n",
        "                                         # performance\n",
        "                                         warmup_steps=warmup_steps,             # Gradually increases LR at start\n",
        "                                         learning_rate=learning_rate,\n",
        "                                         weight_decay=weight_decay,             # L2 regularization\n",
        "                                         lr_scheduler_type=lr_scheduler_type,\n",
        "\n",
        "\n",
        "                                         # Seq2seq specific:\n",
        "                                         predict_with_generate=True,    # essential for seq2seq , If not set then metrics will be computed on meaningless logits\n",
        "                                         generation_max_length=128,      # Max output length\n",
        "                                         generation_num_beams=1,        # 1=greedy, 4=beam search (slower but better)\n",
        "\n",
        "                                         report_to=\"wandb\",          # This enables automatic logging\n",
        "                                         run_name=\"mt5-nepali\",\n",
        "                                         push_to_hub=False                       # save the model to HF\n",
        "                                         )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343f9233",
      "metadata": {
        "id": "343f9233"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class CustomLoggingCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.best_metric = float('inf')\n",
        "        self.logs_file = \"../outputs/training_logs.csv\"\n",
        "        self._create_logs_file()\n",
        "\n",
        "    def _create_logs_file(self):\n",
        "        \"\"\"Create CSV file with headers\"\"\"\n",
        "        if not os.path.exists(self.logs_file):\n",
        "            df = pd.DataFrame(columns=[\n",
        "                'step', 'epoch', 'train_loss', 'eval_loss',\n",
        "                'token_accuracy', 'BLEU','GLEU', 'ROUGE-L'\n",
        "            ])\n",
        "            df.to_csv(self.logs_file, index=False)\n",
        "\n",
        "    def _append_to_csv(self, data):\n",
        "        \"\"\"Append new row to CSV\"\"\"\n",
        "        df = pd.DataFrame([data])\n",
        "        df.to_csv(self.logs_file, mode='a', header=False, index=False)\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"Capture training logs\"\"\"\n",
        "        if logs and 'loss' in logs and state.epoch is not None:\n",
        "            log_data = {\n",
        "                'step': state.global_step,\n",
        "                'epoch': state.epoch,\n",
        "                'train_loss': logs.get('loss'),\n",
        "                'eval_loss': None,  # Will be filled during evaluation\n",
        "                'token_accuracy': None,\n",
        "                'BLEU': None,\n",
        "                'GLEU': None,\n",
        "                'ROUGE-L': None\n",
        "            }\n",
        "            self._append_to_csv(log_data)\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        \"\"\"Capture evaluation metrics and save best model\"\"\"\n",
        "        if metrics:\n",
        "            # Update CSV with evaluation results\n",
        "            eval_data = {\n",
        "                'step': state.global_step,\n",
        "                'epoch': state.epoch,\n",
        "                'train_loss': None,\n",
        "                'eval_loss': metrics.get('eval_loss'),\n",
        "                'token_accuracy': metrics.get('eval_token_accuracy'),\n",
        "                'BLEU': metrics.get('eval_BLEU'),\n",
        "                'GLEU': metrics.get('eval_GLEU'),\n",
        "                'ROUGE-L': metrics.get('eval_ROUGE-L')\n",
        "            }\n",
        "            self._append_to_csv(eval_data)\n",
        "\n",
        "            # Save best model immediately\n",
        "            current_eval_loss = metrics.get('eval_loss', float('inf'))\n",
        "            if current_eval_loss < self.best_metric:\n",
        "                self.best_metric = current_eval_loss\n",
        "                print(f\"üéâ New best model! Eval loss: {current_eval_loss:.4f} at step {state.global_step}\")\n",
        "\n",
        "                # Save best model\n",
        "                best_model_path = \"../outputs/best_model\"\n",
        "                trainer.model.save_pretrained(best_model_path)\n",
        "                trainer.tokenizer.save_pretrained(best_model_path)\n",
        "\n",
        "                # Save best model info\n",
        "                best_model_info = {\n",
        "                    \"best_eval_loss\": current_eval_loss,\n",
        "                    \"step\": state.global_step,\n",
        "                    \"epoch\": state.epoch,\n",
        "                    \"all_metrics\": metrics\n",
        "                }\n",
        "                with open(os.path.join(best_model_path, \"best_model_info.json\"), \"w\") as f:\n",
        "                    json.dump(best_model_info, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f62827e",
      "metadata": {
        "id": "0f62827e"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_encoded[\"train\"],\n",
        "    eval_dataset=dataset_encoded[\"valid\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=seq2seq_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[CustomLoggingCallback(),\n",
        "               EarlyStoppingCallback(early_stopping_patience=3)  # Stop if no improvement for 3 evals\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf8f4d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "2cf8f4d2",
        "outputId": "53601e07-f918-44d4-f8bc-b2ed5263906b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10001' max='1146530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  10001/1146530 2:14:30 < 254:49:40, 1.24 it/s, Epoch 0.04/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2748' max='25408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 2748/25408 50:16 < 6:54:39, 0.91 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # Instead of waiting hours into training to discover issues, test everythings fist with evaluate()\n",
        "\n",
        "\n",
        "# # Complete safety check\n",
        "# def safe_training_check(trainer):\n",
        "#     \"\"\"Comprehensive pre-training safety check\"\"\"\n",
        "#     print(\" Running pre-training safety checks...\")\n",
        "\n",
        "#     # 1. Check model is on correct device\n",
        "#     print(f\"Model device: {next(trainer.model.parameters()).device}\")\n",
        "\n",
        "#     # 2. Check dataset sizes\n",
        "#     print(f\"Train dataset size: {len(trainer.train_dataset)}\")\n",
        "#     print(f\"Eval dataset size: {len(trainer.eval_dataset)}\")\n",
        "\n",
        "#     # 3. Test data loading\n",
        "#     try:\n",
        "#         sample_batch = next(iter(trainer.get_train_dataloader()))\n",
        "#         print(\" Data loading works\")\n",
        "#         # print(f\"Batch keys: {sample_batch.keys()}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\" Data loading failed: {e}\")\n",
        "#         return False\n",
        "\n",
        "#     # 4. Test evaluation\n",
        "#     try:\n",
        "#         trainer.model.eval()    # Set to evaluation mode\n",
        "#         print(\" Performing evaluation check...\")\n",
        "#         # eval_results = trainer.evaluate()\n",
        "#         print(\" Evaluation successful\")\n",
        "#         print(f\"Initial metrics: {eval_results}\")\n",
        "#         return True\n",
        "#     except Exception as e:\n",
        "#         print(f\" Evaluation failed: {e}\")\n",
        "#         return False\n",
        "\n",
        "# # Usage\n",
        "# if safe_training_check(trainer):\n",
        "#     print(\" All checks passed! Starting training...\")\n",
        "#     trainer.train()\n",
        "# else:\n",
        "#     print(\" Fix issues before training!\")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb40c1bd",
      "metadata": {
        "id": "cb40c1bd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2455d20f04f345a9a48348a668f0475e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c224ccc63c44739828db02c3853b4b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f198cfbfa504878b2c9d0be4e58ca99",
            "value": "‚Äá7337772/7337772‚Äá[27:39&lt;00:00,‚Äá5270.36‚Äáexamples/s]"
          }
        },
        "2b7df8136f8b473e966b9c30cef44e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e1a59814ed14eb398cb876281f54038": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ed219336e34155a8bb4e5137b7410e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91030c35f86e49cfafe320cae795d40e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_53075c8c817d4229b77e1aba7d07d979",
            "value": "Map:‚Äá100%"
          }
        },
        "359759b571b243b7b13cff29c54ecb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e92c72a940104ce7b0271ecfa9011798",
              "IPY_MODEL_571dfff6044b4624b40aba1afa7ad23c",
              "IPY_MODEL_2455d20f04f345a9a48348a668f0475e"
            ],
            "layout": "IPY_MODEL_2e1a59814ed14eb398cb876281f54038"
          }
        },
        "38c2f6b8c1944a3b8c1d6c435f479758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30ed219336e34155a8bb4e5137b7410e",
              "IPY_MODEL_f1226541983e48ac92bd99f52d012697",
              "IPY_MODEL_ac1af4fed0e94bf0924d9dad4d98b101"
            ],
            "layout": "IPY_MODEL_2b7df8136f8b473e966b9c30cef44e6d"
          }
        },
        "42754588627a4d4cae282a41e3754290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4521e0c4323f4a4ba60ce95dd92b8bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80eccb80c7fb460287ea437b5f345353",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e1cf5c4262384bf2bc06ae17a045afeb",
            "value": "Map:‚Äá100%"
          }
        },
        "46fcc7e3dda24848b902b8535da79b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4efd170bca2a4b7ca6eacf89fa90b045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5072002b615b461cb281456489c9c707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53075c8c817d4229b77e1aba7d07d979": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "571dfff6044b4624b40aba1afa7ad23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4efd170bca2a4b7ca6eacf89fa90b045",
            "max": 7337772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5072002b615b461cb281456489c9c707",
            "value": 7337772
          }
        },
        "6c1e9a0abf224d90a643244d2bcf4c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c224ccc63c44739828db02c3853b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755daf6c0eb945b296a80feda6117162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "761fa926c6344af2a4628d23e42514a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78ac7830c76e457c98a3aceb4c3011c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c9afd66a0b4121904d910ea7f8c01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80eccb80c7fb460287ea437b5f345353": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844ec81fa2144032a09d7985117aac90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f198cfbfa504878b2c9d0be4e58ca99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91030c35f86e49cfafe320cae795d40e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac1af4fed0e94bf0924d9dad4d98b101": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d68684a5ca5a46b0b9f3cc6d7dc2d1b9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6c1e9a0abf224d90a643244d2bcf4c67",
            "value": "‚Äá386199/386199‚Äá[01:59&lt;00:00,‚Äá5018.41‚Äáexamples/s]"
          }
        },
        "c876c49ae71c4cc1a296a3a9b377ff32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68684a5ca5a46b0b9f3cc6d7dc2d1b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f3de837df84e3cbcc6fef0e3db2cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_755daf6c0eb945b296a80feda6117162",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_42754588627a4d4cae282a41e3754290",
            "value": "‚Äá406525/406525‚Äá[01:24&lt;00:00,‚Äá5644.32‚Äáexamples/s]"
          }
        },
        "d768fda3b49943b9a0192695d9d37974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee76d922c64741b284eeeb4890db164a",
            "max": 406525,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_844ec81fa2144032a09d7985117aac90",
            "value": 406525
          }
        },
        "e1cf5c4262384bf2bc06ae17a045afeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e92c72a940104ce7b0271ecfa9011798": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761fa926c6344af2a4628d23e42514a9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_78c9afd66a0b4121904d910ea7f8c01f",
            "value": "Map:‚Äá100%"
          }
        },
        "ee76d922c64741b284eeeb4890db164a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1226541983e48ac92bd99f52d012697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c876c49ae71c4cc1a296a3a9b377ff32",
            "max": 386199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46fcc7e3dda24848b902b8535da79b1a",
            "value": 386199
          }
        },
        "f66252285e2d4830bc2a028508177fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4521e0c4323f4a4ba60ce95dd92b8bf9",
              "IPY_MODEL_d768fda3b49943b9a0192695d9d37974",
              "IPY_MODEL_d6f3de837df84e3cbcc6fef0e3db2cfb"
            ],
            "layout": "IPY_MODEL_78ac7830c76e457c98a3aceb4c3011c2"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
