
üìö Loading dataset: sumitaryal/nepali_grammatical_error_correction
  Using 15 samples
  Train: 12 samples
  Valid: 3 samples

 Lodaing model: google/mt5-small
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
 Using LoRA + 8-bit quantization
trainable params: 1,769,472 || all params: 301,946,240 || trainable%: 0.5860

‚öôÔ∏è  Preprocessing dataset...
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 67.78 examples/s]
  ‚úÖ Preprocessing complete

üìä Training plan:
  Steps per epoch: 1
  Total steps: 5
  Warmup steps: 0

 Running pre-training safety checks...
Model device: cuda:0
Train dataset size: 12
Eval dataset size: 3
 Data loading works
 Performing evaluation check...
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.95s/it]
üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False
 Evaluation successful
Initial metrics: {'eval_loss': 15.911977767944336, 'eval_model_preparation_time': 0.0019, 'eval_bleu': 0.8508564639341064, 'eval_chrf': 0.08999280057595392, 'eval_correction_accuracy': 0.0, 'eval_bertscore_f1': 0.4488728940486908, 'eval_gleu': 0.00980392156862745, 'eval_runtime': 54.322, 'eval_samples_per_second': 0.055, 'eval_steps_per_second': 0.018}

============================================================
üèãÔ∏è  Starting training...
============================================================
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [08:34<00:00, 102.87s/it]
                                                                                                                               
üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False
{'eval_loss': 15.69729232788086, 'eval_model_preparation_time': 0.0019, 'eval_bleu': 1.0118445607564956, 'eval_chrf': 0.17998560115190784, 'eval_correction_accuracy': 0.0, 'eval_bertscore_f1': 0.4422174294789632, 'eval_gleu': 0.00980392156862745, 'eval_runtime': 50.5122, 'eval_samples_per_second': 0.059, 'eval_steps_per_second': 0.02, 'epoch': 1.0}
üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False
{'eval_loss': 15.735795974731445, 'eval_model_preparation_time': 0.0019, 'eval_bleu': 0.8508564639341064, 'eval_chrf': 0.08999280057595392, 'eval_correction_accuracy': 0.0, 'eval_bertscore_f1': 0.4488728940486908, 'eval_gleu': 0.00980392156862745, 'eval_runtime': 49.9592, 'eval_samples_per_second': 0.06, 'eval_steps_per_second': 0.02, 'epoch': 2.0}
üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False
{'eval_loss': 14.108699798583984, 'eval_model_preparation_time': 0.0019, 'eval_bleu': 1.0118445607564956, 'eval_chrf': 0.17998560115190784, 'eval_correction_accuracy': 0.0, 'eval_bertscore_f1': 0.4422174294789632, 'eval_gleu': 0.00980392156862745, 'eval_runtime': 50.29, 'eval_samples_per_second': 0.06, 'eval_steps_per_second': 0.02, 'epoch': 3.0}
üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False
{'eval_loss': 15.402384757995605, 'eval_model_preparation_time': 0.0019, 'eval_bleu': 1.0118445607564956, 'eval_chrf': 0.17998560115190784, 'eval_correction_accuracy': 0.0, 'eval_bertscore_f1': 0.4422174294789632, 'eval_gleu': 0.00980392156862745, 'eval_runtime': 54.3517, 'eval_samples_per_second': 0.055, 'eval_steps_per_second': 0.018, 'epoch': 4.0}
üîç Sample - Pred: '<extra_id_0>...' | Ref: '‡§´‡§∞‡•ç‡§ï‡§®‡•á ‡§π‡•ã ‡§â‡§§‡•à?...' | Match: False
{'eval_loss': 14.305315971374512, 'eval_model_preparation_time': 0.0019, 'eval_bleu': 1.0118445607564956, 'eval_chrf': 0.17998560115190784, 'eval_correction_accuracy': 0.0, 'eval_bertscore_f1': 0.4422174294789632, 'eval_gleu': 0.00980392156862745, 'eval_runtime': 52.1499, 'eval_samples_per_second': 0.058, 'eval_steps_per_second': 0.019, 'epoch': 5.0}
{'train_runtime': 514.3322, 'train_samples_per_second': 0.117, 'train_steps_per_second': 0.01, 'train_loss': 21.77441864013672, 'epoch': 5.0}

‚úÖ Training complete!

üíæ Saving model to ../outputs/best_model...
  ‚úÖ LoRA adapter saved
  ‚úÖ Tokenizer saved

üéâ All done! Model saved to ../outputs/best_model
